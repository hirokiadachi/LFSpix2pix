{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1 [0/2000 (0%)] | D loss (A): 0.878328 | D loss (B): 0.572918 | G loss: 19.443069 | Consistency: 1.311555 |\n",
      "Training epoch: 1 [100/2000 (5%)] | D loss (A): 0.122086 | D loss (B): 0.312253 | G loss: 3.762844 | Consistency: 0.297104 |\n",
      "Training epoch: 1 [200/2000 (10%)] | D loss (A): 0.216540 | D loss (B): 0.206244 | G loss: 4.162448 | Consistency: 0.327086 |\n",
      "Training epoch: 1 [300/2000 (15%)] | D loss (A): 0.199673 | D loss (B): 0.162043 | G loss: 3.291887 | Consistency: 0.222593 |\n",
      "Training epoch: 1 [400/2000 (20%)] | D loss (A): 0.124540 | D loss (B): 0.244573 | G loss: 5.320621 | Consistency: 0.454168 |\n",
      "Training epoch: 1 [500/2000 (25%)] | D loss (A): 0.173469 | D loss (B): 0.186490 | G loss: 6.645848 | Consistency: 0.527969 |\n",
      "Training epoch: 1 [600/2000 (30%)] | D loss (A): 0.085492 | D loss (B): 0.091554 | G loss: 5.467244 | Consistency: 0.452941 |\n",
      "Training epoch: 1 [700/2000 (35%)] | D loss (A): 0.167641 | D loss (B): 0.454992 | G loss: 4.570864 | Consistency: 0.377828 |\n",
      "Training epoch: 1 [800/2000 (40%)] | D loss (A): 0.130462 | D loss (B): 0.124155 | G loss: 4.831857 | Consistency: 0.260314 |\n",
      "Training epoch: 1 [900/2000 (45%)] | D loss (A): 0.030866 | D loss (B): 0.100642 | G loss: 3.178586 | Consistency: 0.195612 |\n",
      "Training epoch: 1 [1000/2000 (50%)] | D loss (A): 0.107665 | D loss (B): 0.292457 | G loss: 3.993184 | Consistency: 0.302446 |\n",
      "Training epoch: 1 [1100/2000 (55%)] | D loss (A): 0.218165 | D loss (B): 0.034062 | G loss: 5.531083 | Consistency: 0.307060 |\n",
      "Training epoch: 1 [1200/2000 (60%)] | D loss (A): 0.083287 | D loss (B): 0.074258 | G loss: 4.916233 | Consistency: 0.366925 |\n",
      "Training epoch: 1 [1300/2000 (65%)] | D loss (A): 0.081123 | D loss (B): 0.026120 | G loss: 4.360090 | Consistency: 0.275571 |\n",
      "Training epoch: 1 [1400/2000 (70%)] | D loss (A): 0.361452 | D loss (B): 0.152412 | G loss: 3.135002 | Consistency: 0.245007 |\n",
      "Training epoch: 1 [1500/2000 (75%)] | D loss (A): 0.315455 | D loss (B): 0.131436 | G loss: 3.878810 | Consistency: 0.232506 |\n",
      "Training epoch: 1 [1600/2000 (80%)] | D loss (A): 0.148117 | D loss (B): 0.053287 | G loss: 4.206738 | Consistency: 0.293855 |\n",
      "Training epoch: 1 [1700/2000 (85%)] | D loss (A): 0.134089 | D loss (B): 0.072158 | G loss: 4.635966 | Consistency: 0.290231 |\n",
      "Training epoch: 1 [1800/2000 (90%)] | D loss (A): 0.172651 | D loss (B): 0.147875 | G loss: 3.805786 | Consistency: 0.297471 |\n",
      "Training epoch: 1 [1900/2000 (95%)] | D loss (A): 0.146874 | D loss (B): 0.200804 | G loss: 3.327157 | Consistency: 0.245127 |\n",
      "Training epoch: 2 [0/2000 (0%)] | D loss (A): 0.232131 | D loss (B): 0.109497 | G loss: 3.731364 | Consistency: 0.301125 |\n",
      "Training epoch: 2 [100/2000 (5%)] | D loss (A): 0.275640 | D loss (B): 0.141133 | G loss: 3.900232 | Consistency: 0.194608 |\n",
      "Training epoch: 2 [200/2000 (10%)] | D loss (A): 0.293219 | D loss (B): 0.374117 | G loss: 3.668785 | Consistency: 0.164037 |\n",
      "Training epoch: 2 [300/2000 (15%)] | D loss (A): 0.163160 | D loss (B): 0.155266 | G loss: 2.711322 | Consistency: 0.172907 |\n",
      "Training epoch: 2 [400/2000 (20%)] | D loss (A): 0.092216 | D loss (B): 0.045538 | G loss: 3.358072 | Consistency: 0.251482 |\n",
      "Training epoch: 2 [500/2000 (25%)] | D loss (A): 0.140914 | D loss (B): 0.103939 | G loss: 4.275958 | Consistency: 0.248324 |\n",
      "Training epoch: 2 [600/2000 (30%)] | D loss (A): 0.170045 | D loss (B): 0.239716 | G loss: 3.834170 | Consistency: 0.268929 |\n",
      "Training epoch: 2 [700/2000 (35%)] | D loss (A): 0.315838 | D loss (B): 0.132954 | G loss: 4.710341 | Consistency: 0.423708 |\n",
      "Training epoch: 2 [800/2000 (40%)] | D loss (A): 0.071465 | D loss (B): 0.089287 | G loss: 2.275551 | Consistency: 0.199891 |\n",
      "Training epoch: 2 [900/2000 (45%)] | D loss (A): 0.196858 | D loss (B): 0.195403 | G loss: 4.078036 | Consistency: 0.261907 |\n",
      "Training epoch: 2 [1000/2000 (50%)] | D loss (A): 0.070236 | D loss (B): 0.038928 | G loss: 4.151253 | Consistency: 0.292969 |\n",
      "Training epoch: 2 [1100/2000 (55%)] | D loss (A): 0.070026 | D loss (B): 0.108738 | G loss: 2.423228 | Consistency: 0.165384 |\n",
      "Training epoch: 2 [1200/2000 (60%)] | D loss (A): 0.136393 | D loss (B): 0.100646 | G loss: 3.753768 | Consistency: 0.259378 |\n",
      "Training epoch: 2 [1300/2000 (65%)] | D loss (A): 0.130611 | D loss (B): 0.101417 | G loss: 3.503368 | Consistency: 0.203046 |\n",
      "Training epoch: 2 [1400/2000 (70%)] | D loss (A): 0.184366 | D loss (B): 0.130164 | G loss: 3.012423 | Consistency: 0.202817 |\n",
      "Training epoch: 2 [1500/2000 (75%)] | D loss (A): 0.172987 | D loss (B): 0.103467 | G loss: 3.883469 | Consistency: 0.279591 |\n",
      "Training epoch: 2 [1600/2000 (80%)] | D loss (A): 0.072876 | D loss (B): 0.041470 | G loss: 3.919108 | Consistency: 0.288155 |\n",
      "Training epoch: 2 [1700/2000 (85%)] | D loss (A): 0.127273 | D loss (B): 0.117605 | G loss: 3.678908 | Consistency: 0.289048 |\n",
      "Training epoch: 2 [1800/2000 (90%)] | D loss (A): 0.114533 | D loss (B): 0.199115 | G loss: 2.504285 | Consistency: 0.190886 |\n",
      "Training epoch: 2 [1900/2000 (95%)] | D loss (A): 0.294448 | D loss (B): 0.061580 | G loss: 2.848017 | Consistency: 0.227670 |\n",
      "Training epoch: 3 [0/2000 (0%)] | D loss (A): 0.520820 | D loss (B): 0.084723 | G loss: 3.615624 | Consistency: 0.248618 |\n",
      "Training epoch: 3 [100/2000 (5%)] | D loss (A): 0.172599 | D loss (B): 0.055777 | G loss: 2.538398 | Consistency: 0.176619 |\n",
      "Training epoch: 3 [200/2000 (10%)] | D loss (A): 0.203642 | D loss (B): 0.069531 | G loss: 4.621675 | Consistency: 0.305322 |\n",
      "Training epoch: 3 [300/2000 (15%)] | D loss (A): 0.197508 | D loss (B): 0.074756 | G loss: 2.957122 | Consistency: 0.219871 |\n",
      "Training epoch: 3 [400/2000 (20%)] | D loss (A): 0.053589 | D loss (B): 0.115118 | G loss: 2.817853 | Consistency: 0.172710 |\n",
      "Training epoch: 3 [500/2000 (25%)] | D loss (A): 0.100703 | D loss (B): 0.212351 | G loss: 3.394394 | Consistency: 0.197201 |\n",
      "Training epoch: 3 [600/2000 (30%)] | D loss (A): 0.148805 | D loss (B): 0.207960 | G loss: 3.069453 | Consistency: 0.261549 |\n",
      "Training epoch: 3 [700/2000 (35%)] | D loss (A): 0.178753 | D loss (B): 0.183437 | G loss: 3.061085 | Consistency: 0.207107 |\n",
      "Training epoch: 3 [800/2000 (40%)] | D loss (A): 0.084006 | D loss (B): 0.185292 | G loss: 2.954904 | Consistency: 0.175514 |\n",
      "Training epoch: 3 [900/2000 (45%)] | D loss (A): 0.169606 | D loss (B): 0.072034 | G loss: 3.650876 | Consistency: 0.258932 |\n",
      "Training epoch: 3 [1000/2000 (50%)] | D loss (A): 0.217593 | D loss (B): 0.071647 | G loss: 4.197159 | Consistency: 0.291755 |\n",
      "Training epoch: 3 [1100/2000 (55%)] | D loss (A): 0.256055 | D loss (B): 0.082203 | G loss: 3.491621 | Consistency: 0.250091 |\n",
      "Training epoch: 3 [1200/2000 (60%)] | D loss (A): 0.206274 | D loss (B): 0.067743 | G loss: 2.550840 | Consistency: 0.213408 |\n",
      "Training epoch: 3 [1300/2000 (65%)] | D loss (A): 0.269112 | D loss (B): 0.045666 | G loss: 2.459888 | Consistency: 0.176099 |\n",
      "Training epoch: 3 [1400/2000 (70%)] | D loss (A): 0.202007 | D loss (B): 0.208312 | G loss: 3.322535 | Consistency: 0.215735 |\n",
      "Training epoch: 3 [1500/2000 (75%)] | D loss (A): 0.239204 | D loss (B): 0.122882 | G loss: 2.403283 | Consistency: 0.156351 |\n",
      "Training epoch: 3 [1600/2000 (80%)] | D loss (A): 0.249552 | D loss (B): 0.247252 | G loss: 2.825309 | Consistency: 0.175800 |\n",
      "Training epoch: 3 [1700/2000 (85%)] | D loss (A): 0.215122 | D loss (B): 0.026759 | G loss: 3.903359 | Consistency: 0.329357 |\n",
      "Training epoch: 3 [1800/2000 (90%)] | D loss (A): 0.246039 | D loss (B): 0.188098 | G loss: 2.222768 | Consistency: 0.143149 |\n",
      "Training epoch: 3 [1900/2000 (95%)] | D loss (A): 0.215941 | D loss (B): 0.207450 | G loss: 3.232928 | Consistency: 0.191662 |\n",
      "Training epoch: 4 [0/2000 (0%)] | D loss (A): 0.257354 | D loss (B): 0.169609 | G loss: 3.144540 | Consistency: 0.209621 |\n",
      "Training epoch: 4 [100/2000 (5%)] | D loss (A): 0.273253 | D loss (B): 0.038936 | G loss: 3.064685 | Consistency: 0.247080 |\n",
      "Training epoch: 4 [200/2000 (10%)] | D loss (A): 0.220389 | D loss (B): 0.171792 | G loss: 3.495438 | Consistency: 0.270139 |\n",
      "Training epoch: 4 [300/2000 (15%)] | D loss (A): 0.250628 | D loss (B): 0.156228 | G loss: 1.890778 | Consistency: 0.126761 |\n",
      "Training epoch: 4 [400/2000 (20%)] | D loss (A): 0.211468 | D loss (B): 0.152452 | G loss: 3.016630 | Consistency: 0.191718 |\n",
      "Training epoch: 4 [500/2000 (25%)] | D loss (A): 0.106148 | D loss (B): 0.074075 | G loss: 5.603163 | Consistency: 0.407512 |\n",
      "Training epoch: 4 [600/2000 (30%)] | D loss (A): 0.167433 | D loss (B): 0.051724 | G loss: 3.814866 | Consistency: 0.272863 |\n",
      "Training epoch: 4 [700/2000 (35%)] | D loss (A): 0.233431 | D loss (B): 0.155069 | G loss: 2.061929 | Consistency: 0.157753 |\n",
      "Training epoch: 4 [800/2000 (40%)] | D loss (A): 0.263234 | D loss (B): 0.136841 | G loss: 3.214544 | Consistency: 0.248978 |\n",
      "Training epoch: 4 [900/2000 (45%)] | D loss (A): 0.148340 | D loss (B): 0.199900 | G loss: 2.315372 | Consistency: 0.172231 |\n",
      "Training epoch: 4 [1000/2000 (50%)] | D loss (A): 0.204566 | D loss (B): 0.229529 | G loss: 2.670320 | Consistency: 0.172336 |\n",
      "Training epoch: 4 [1100/2000 (55%)] | D loss (A): 0.242706 | D loss (B): 0.068376 | G loss: 2.255997 | Consistency: 0.157373 |\n",
      "Training epoch: 4 [1200/2000 (60%)] | D loss (A): 0.241812 | D loss (B): 0.124782 | G loss: 2.360346 | Consistency: 0.171184 |\n",
      "Training epoch: 4 [1300/2000 (65%)] | D loss (A): 0.171785 | D loss (B): 0.046762 | G loss: 2.706603 | Consistency: 0.160389 |\n",
      "Training epoch: 4 [1400/2000 (70%)] | D loss (A): 0.147475 | D loss (B): 0.063011 | G loss: 2.833143 | Consistency: 0.243418 |\n",
      "Training epoch: 4 [1500/2000 (75%)] | D loss (A): 0.108535 | D loss (B): 0.175899 | G loss: 2.738801 | Consistency: 0.211818 |\n",
      "Training epoch: 4 [1600/2000 (80%)] | D loss (A): 0.144879 | D loss (B): 0.205113 | G loss: 3.045560 | Consistency: 0.176397 |\n",
      "Training epoch: 4 [1700/2000 (85%)] | D loss (A): 0.184139 | D loss (B): 0.122498 | G loss: 3.116087 | Consistency: 0.189843 |\n",
      "Training epoch: 4 [1800/2000 (90%)] | D loss (A): 0.265120 | D loss (B): 0.198517 | G loss: 3.250399 | Consistency: 0.177059 |\n",
      "Training epoch: 4 [1900/2000 (95%)] | D loss (A): 0.244730 | D loss (B): 0.318644 | G loss: 2.441795 | Consistency: 0.147339 |\n",
      "Training epoch: 5 [0/2000 (0%)] | D loss (A): 0.047322 | D loss (B): 0.266060 | G loss: 2.421647 | Consistency: 0.200330 |\n",
      "Training epoch: 5 [100/2000 (5%)] | D loss (A): 0.248981 | D loss (B): 0.215692 | G loss: 3.057647 | Consistency: 0.192785 |\n",
      "Training epoch: 5 [200/2000 (10%)] | D loss (A): 0.025225 | D loss (B): 0.093138 | G loss: 2.644804 | Consistency: 0.166888 |\n",
      "Training epoch: 5 [300/2000 (15%)] | D loss (A): 0.114590 | D loss (B): 0.117946 | G loss: 4.321761 | Consistency: 0.298500 |\n",
      "Training epoch: 5 [400/2000 (20%)] | D loss (A): 0.201799 | D loss (B): 0.379110 | G loss: 2.629210 | Consistency: 0.184642 |\n",
      "Training epoch: 5 [500/2000 (25%)] | D loss (A): 0.102503 | D loss (B): 0.127508 | G loss: 1.507970 | Consistency: 0.117259 |\n",
      "Training epoch: 5 [600/2000 (30%)] | D loss (A): 0.166316 | D loss (B): 0.089463 | G loss: 2.477277 | Consistency: 0.133741 |\n",
      "Training epoch: 5 [700/2000 (35%)] | D loss (A): 0.413450 | D loss (B): 0.062370 | G loss: 4.582925 | Consistency: 0.323095 |\n",
      "Training epoch: 5 [800/2000 (40%)] | D loss (A): 0.112836 | D loss (B): 0.191437 | G loss: 4.277046 | Consistency: 0.301216 |\n",
      "Training epoch: 5 [900/2000 (45%)] | D loss (A): 0.256495 | D loss (B): 0.054272 | G loss: 2.667794 | Consistency: 0.194748 |\n",
      "Training epoch: 5 [1000/2000 (50%)] | D loss (A): 0.208771 | D loss (B): 0.170978 | G loss: 3.744171 | Consistency: 0.231338 |\n",
      "Training epoch: 5 [1100/2000 (55%)] | D loss (A): 0.162489 | D loss (B): 0.057680 | G loss: 4.564458 | Consistency: 0.288906 |\n",
      "Training epoch: 5 [1200/2000 (60%)] | D loss (A): 0.218262 | D loss (B): 0.094514 | G loss: 2.765852 | Consistency: 0.149437 |\n",
      "Training epoch: 5 [1300/2000 (65%)] | D loss (A): 0.187745 | D loss (B): 0.064503 | G loss: 2.328216 | Consistency: 0.190007 |\n",
      "Training epoch: 5 [1400/2000 (70%)] | D loss (A): 0.050679 | D loss (B): 0.149325 | G loss: 2.761184 | Consistency: 0.181500 |\n",
      "Training epoch: 5 [1500/2000 (75%)] | D loss (A): 0.166537 | D loss (B): 0.025939 | G loss: 3.595215 | Consistency: 0.177264 |\n",
      "Training epoch: 5 [1600/2000 (80%)] | D loss (A): 0.135936 | D loss (B): 0.030430 | G loss: 2.807737 | Consistency: 0.195408 |\n",
      "Training epoch: 5 [1700/2000 (85%)] | D loss (A): 0.172292 | D loss (B): 0.089717 | G loss: 3.556101 | Consistency: 0.217173 |\n",
      "Training epoch: 5 [1800/2000 (90%)] | D loss (A): 0.222702 | D loss (B): 0.117590 | G loss: 2.738149 | Consistency: 0.192708 |\n",
      "Training epoch: 5 [1900/2000 (95%)] | D loss (A): 0.087232 | D loss (B): 0.035674 | G loss: 1.986733 | Consistency: 0.132813 |\n",
      "Training epoch: 6 [0/2000 (0%)] | D loss (A): 0.205085 | D loss (B): 0.049460 | G loss: 2.747145 | Consistency: 0.157664 |\n",
      "Training epoch: 6 [100/2000 (5%)] | D loss (A): 0.265035 | D loss (B): 0.041036 | G loss: 3.449708 | Consistency: 0.197808 |\n",
      "Training epoch: 6 [200/2000 (10%)] | D loss (A): 0.157337 | D loss (B): 0.027728 | G loss: 3.080723 | Consistency: 0.227190 |\n",
      "Training epoch: 6 [300/2000 (15%)] | D loss (A): 0.406124 | D loss (B): 0.031356 | G loss: 4.362088 | Consistency: 0.297867 |\n",
      "Training epoch: 6 [400/2000 (20%)] | D loss (A): 0.093066 | D loss (B): 0.077156 | G loss: 3.284360 | Consistency: 0.169948 |\n",
      "Training epoch: 6 [500/2000 (25%)] | D loss (A): 0.153720 | D loss (B): 0.052392 | G loss: 3.635333 | Consistency: 0.200947 |\n",
      "Training epoch: 6 [600/2000 (30%)] | D loss (A): 0.379085 | D loss (B): 0.025877 | G loss: 3.823505 | Consistency: 0.212640 |\n",
      "Training epoch: 6 [700/2000 (35%)] | D loss (A): 0.061136 | D loss (B): 0.044349 | G loss: 3.083062 | Consistency: 0.194749 |\n",
      "Training epoch: 6 [800/2000 (40%)] | D loss (A): 0.281682 | D loss (B): 0.152298 | G loss: 3.238286 | Consistency: 0.184791 |\n",
      "Training epoch: 6 [900/2000 (45%)] | D loss (A): 0.237032 | D loss (B): 0.064250 | G loss: 3.060135 | Consistency: 0.185459 |\n",
      "Training epoch: 6 [1000/2000 (50%)] | D loss (A): 0.186728 | D loss (B): 0.086784 | G loss: 2.923225 | Consistency: 0.170247 |\n",
      "Training epoch: 6 [1100/2000 (55%)] | D loss (A): 0.146154 | D loss (B): 0.167751 | G loss: 2.383888 | Consistency: 0.155617 |\n",
      "Training epoch: 6 [1200/2000 (60%)] | D loss (A): 0.316910 | D loss (B): 0.082911 | G loss: 3.093156 | Consistency: 0.154309 |\n",
      "Training epoch: 6 [1300/2000 (65%)] | D loss (A): 0.134759 | D loss (B): 0.065219 | G loss: 2.911095 | Consistency: 0.226718 |\n",
      "Training epoch: 6 [1400/2000 (70%)] | D loss (A): 0.273082 | D loss (B): 0.099226 | G loss: 3.255092 | Consistency: 0.243669 |\n",
      "Training epoch: 6 [1500/2000 (75%)] | D loss (A): 0.202013 | D loss (B): 0.426275 | G loss: 3.374241 | Consistency: 0.169548 |\n",
      "Training epoch: 6 [1600/2000 (80%)] | D loss (A): 0.187736 | D loss (B): 0.085042 | G loss: 2.662619 | Consistency: 0.180275 |\n",
      "Training epoch: 6 [1700/2000 (85%)] | D loss (A): 0.110596 | D loss (B): 0.062756 | G loss: 3.694395 | Consistency: 0.259624 |\n",
      "Training epoch: 6 [1800/2000 (90%)] | D loss (A): 0.197169 | D loss (B): 0.221529 | G loss: 4.620516 | Consistency: 0.342370 |\n",
      "Training epoch: 6 [1900/2000 (95%)] | D loss (A): 0.126378 | D loss (B): 0.188313 | G loss: 4.221487 | Consistency: 0.277408 |\n",
      "Training epoch: 7 [0/2000 (0%)] | D loss (A): 0.032938 | D loss (B): 0.144837 | G loss: 2.271842 | Consistency: 0.163470 |\n",
      "Training epoch: 7 [100/2000 (5%)] | D loss (A): 0.267940 | D loss (B): 0.248335 | G loss: 2.550858 | Consistency: 0.188565 |\n",
      "Training epoch: 7 [200/2000 (10%)] | D loss (A): 0.145922 | D loss (B): 0.238484 | G loss: 2.969625 | Consistency: 0.195825 |\n",
      "Training epoch: 7 [300/2000 (15%)] | D loss (A): 0.174883 | D loss (B): 0.170733 | G loss: 2.176585 | Consistency: 0.132446 |\n",
      "Training epoch: 7 [400/2000 (20%)] | D loss (A): 0.267596 | D loss (B): 0.134898 | G loss: 2.808102 | Consistency: 0.179004 |\n",
      "Training epoch: 7 [500/2000 (25%)] | D loss (A): 0.150716 | D loss (B): 0.226049 | G loss: 2.561523 | Consistency: 0.192510 |\n",
      "Training epoch: 7 [600/2000 (30%)] | D loss (A): 0.153826 | D loss (B): 0.377124 | G loss: 2.838468 | Consistency: 0.174925 |\n",
      "Training epoch: 7 [700/2000 (35%)] | D loss (A): 0.122745 | D loss (B): 0.138905 | G loss: 2.511672 | Consistency: 0.161396 |\n",
      "Training epoch: 7 [800/2000 (40%)] | D loss (A): 0.120946 | D loss (B): 0.311842 | G loss: 2.535120 | Consistency: 0.159090 |\n",
      "Training epoch: 7 [900/2000 (45%)] | D loss (A): 0.197872 | D loss (B): 0.225139 | G loss: 2.866903 | Consistency: 0.159713 |\n",
      "Training epoch: 7 [1000/2000 (50%)] | D loss (A): 0.166656 | D loss (B): 0.192428 | G loss: 2.243693 | Consistency: 0.144193 |\n",
      "Training epoch: 7 [1100/2000 (55%)] | D loss (A): 0.102025 | D loss (B): 0.272338 | G loss: 2.930342 | Consistency: 0.231321 |\n",
      "Training epoch: 7 [1200/2000 (60%)] | D loss (A): 0.170338 | D loss (B): 0.266990 | G loss: 2.575536 | Consistency: 0.132457 |\n",
      "Training epoch: 7 [1300/2000 (65%)] | D loss (A): 0.218291 | D loss (B): 0.259741 | G loss: 2.484189 | Consistency: 0.146539 |\n",
      "Training epoch: 7 [1400/2000 (70%)] | D loss (A): 0.098179 | D loss (B): 0.233333 | G loss: 2.854168 | Consistency: 0.221727 |\n",
      "Training epoch: 7 [1500/2000 (75%)] | D loss (A): 0.261784 | D loss (B): 0.279223 | G loss: 1.909189 | Consistency: 0.145736 |\n",
      "Training epoch: 7 [1600/2000 (80%)] | D loss (A): 0.129796 | D loss (B): 0.233403 | G loss: 3.434647 | Consistency: 0.247080 |\n",
      "Training epoch: 7 [1700/2000 (85%)] | D loss (A): 0.077020 | D loss (B): 0.052610 | G loss: 2.536580 | Consistency: 0.201136 |\n",
      "Training epoch: 7 [1800/2000 (90%)] | D loss (A): 0.267343 | D loss (B): 0.172524 | G loss: 2.951216 | Consistency: 0.183170 |\n",
      "Training epoch: 7 [1900/2000 (95%)] | D loss (A): 0.175653 | D loss (B): 0.096476 | G loss: 3.139268 | Consistency: 0.155066 |\n",
      "Training epoch: 8 [0/2000 (0%)] | D loss (A): 0.135512 | D loss (B): 0.057406 | G loss: 2.763094 | Consistency: 0.148480 |\n",
      "Training epoch: 8 [100/2000 (5%)] | D loss (A): 0.171026 | D loss (B): 0.085997 | G loss: 2.498374 | Consistency: 0.154046 |\n",
      "Training epoch: 8 [200/2000 (10%)] | D loss (A): 0.177211 | D loss (B): 0.173093 | G loss: 2.543176 | Consistency: 0.186107 |\n",
      "Training epoch: 8 [300/2000 (15%)] | D loss (A): 0.074447 | D loss (B): 0.182382 | G loss: 3.543949 | Consistency: 0.216021 |\n",
      "Training epoch: 8 [400/2000 (20%)] | D loss (A): 4.557693 | D loss (B): 0.177666 | G loss: 7.797188 | Consistency: 0.316841 |\n",
      "Training epoch: 8 [500/2000 (25%)] | D loss (A): 0.243717 | D loss (B): 0.149303 | G loss: 3.023858 | Consistency: 0.213713 |\n",
      "Training epoch: 8 [600/2000 (30%)] | D loss (A): 0.259189 | D loss (B): 0.056672 | G loss: 1.749470 | Consistency: 0.127819 |\n",
      "Training epoch: 8 [700/2000 (35%)] | D loss (A): 0.243938 | D loss (B): 0.077863 | G loss: 2.182799 | Consistency: 0.143789 |\n",
      "Training epoch: 8 [800/2000 (40%)] | D loss (A): 0.239120 | D loss (B): 0.283591 | G loss: 2.464109 | Consistency: 0.209498 |\n",
      "Training epoch: 8 [900/2000 (45%)] | D loss (A): 0.233384 | D loss (B): 0.249137 | G loss: 1.844677 | Consistency: 0.118787 |\n",
      "Training epoch: 8 [1000/2000 (50%)] | D loss (A): 0.247485 | D loss (B): 0.137847 | G loss: 2.406813 | Consistency: 0.165640 |\n",
      "Training epoch: 8 [1100/2000 (55%)] | D loss (A): 0.256559 | D loss (B): 0.094824 | G loss: 1.933120 | Consistency: 0.153439 |\n",
      "Training epoch: 8 [1200/2000 (60%)] | D loss (A): 0.225119 | D loss (B): 0.177734 | G loss: 2.850260 | Consistency: 0.196469 |\n",
      "Training epoch: 8 [1300/2000 (65%)] | D loss (A): 0.307504 | D loss (B): 0.092743 | G loss: 2.205049 | Consistency: 0.157060 |\n",
      "Training epoch: 8 [1400/2000 (70%)] | D loss (A): 0.272774 | D loss (B): 0.057184 | G loss: 2.288759 | Consistency: 0.161443 |\n",
      "Training epoch: 8 [1500/2000 (75%)] | D loss (A): 0.325280 | D loss (B): 0.192710 | G loss: 2.276076 | Consistency: 0.152094 |\n",
      "Training epoch: 8 [1600/2000 (80%)] | D loss (A): 0.200190 | D loss (B): 0.080663 | G loss: 2.558917 | Consistency: 0.155910 |\n",
      "Training epoch: 8 [1700/2000 (85%)] | D loss (A): 0.226325 | D loss (B): 0.130064 | G loss: 2.228240 | Consistency: 0.150362 |\n",
      "Training epoch: 8 [1800/2000 (90%)] | D loss (A): 0.266785 | D loss (B): 0.065956 | G loss: 2.040436 | Consistency: 0.142146 |\n",
      "Training epoch: 8 [1900/2000 (95%)] | D loss (A): 0.282545 | D loss (B): 0.241335 | G loss: 2.470793 | Consistency: 0.182655 |\n",
      "Training epoch: 9 [0/2000 (0%)] | D loss (A): 0.247841 | D loss (B): 0.143141 | G loss: 2.554550 | Consistency: 0.199995 |\n",
      "Training epoch: 9 [100/2000 (5%)] | D loss (A): 0.191528 | D loss (B): 0.221014 | G loss: 3.082721 | Consistency: 0.243593 |\n",
      "Training epoch: 9 [200/2000 (10%)] | D loss (A): 0.272740 | D loss (B): 0.214496 | G loss: 2.463775 | Consistency: 0.180481 |\n",
      "Training epoch: 9 [300/2000 (15%)] | D loss (A): 0.225942 | D loss (B): 0.196913 | G loss: 2.466795 | Consistency: 0.147665 |\n",
      "Training epoch: 9 [400/2000 (20%)] | D loss (A): 0.244321 | D loss (B): 0.278540 | G loss: 1.939384 | Consistency: 0.132037 |\n",
      "Training epoch: 9 [500/2000 (25%)] | D loss (A): 0.193827 | D loss (B): 0.236234 | G loss: 1.919292 | Consistency: 0.160717 |\n",
      "Training epoch: 9 [600/2000 (30%)] | D loss (A): 0.202774 | D loss (B): 0.160083 | G loss: 2.241516 | Consistency: 0.131923 |\n",
      "Training epoch: 9 [700/2000 (35%)] | D loss (A): 0.180385 | D loss (B): 0.189633 | G loss: 2.234149 | Consistency: 0.128888 |\n",
      "Training epoch: 9 [800/2000 (40%)] | D loss (A): 0.174548 | D loss (B): 0.145310 | G loss: 2.219497 | Consistency: 0.139180 |\n",
      "Training epoch: 9 [900/2000 (45%)] | D loss (A): 0.193338 | D loss (B): 0.181995 | G loss: 2.638689 | Consistency: 0.161146 |\n",
      "Training epoch: 9 [1000/2000 (50%)] | D loss (A): 0.260576 | D loss (B): 0.152192 | G loss: 2.774673 | Consistency: 0.195929 |\n",
      "Training epoch: 9 [1100/2000 (55%)] | D loss (A): 0.182552 | D loss (B): 0.310041 | G loss: 2.158817 | Consistency: 0.125659 |\n",
      "Training epoch: 9 [1200/2000 (60%)] | D loss (A): 0.204801 | D loss (B): 0.157838 | G loss: 2.159345 | Consistency: 0.134298 |\n",
      "Training epoch: 9 [1300/2000 (65%)] | D loss (A): 0.182845 | D loss (B): 0.159793 | G loss: 2.820589 | Consistency: 0.162285 |\n",
      "Training epoch: 9 [1400/2000 (70%)] | D loss (A): 0.251549 | D loss (B): 0.131890 | G loss: 2.644488 | Consistency: 0.200775 |\n",
      "Training epoch: 9 [1500/2000 (75%)] | D loss (A): 0.130745 | D loss (B): 0.047167 | G loss: 3.882410 | Consistency: 0.188993 |\n",
      "Training epoch: 9 [1600/2000 (80%)] | D loss (A): 0.065306 | D loss (B): 0.066813 | G loss: 2.210935 | Consistency: 0.189474 |\n",
      "Training epoch: 9 [1700/2000 (85%)] | D loss (A): 0.064014 | D loss (B): 0.167349 | G loss: 2.682816 | Consistency: 0.167981 |\n",
      "Training epoch: 9 [1800/2000 (90%)] | D loss (A): 0.131853 | D loss (B): 0.342858 | G loss: 2.946613 | Consistency: 0.202851 |\n",
      "Training epoch: 9 [1900/2000 (95%)] | D loss (A): 0.080952 | D loss (B): 0.132977 | G loss: 3.694446 | Consistency: 0.257130 |\n",
      "Training epoch: 10 [0/2000 (0%)] | D loss (A): 0.068922 | D loss (B): 0.151425 | G loss: 3.238492 | Consistency: 0.194235 |\n",
      "Training epoch: 10 [100/2000 (5%)] | D loss (A): 0.179783 | D loss (B): 0.036363 | G loss: 2.079043 | Consistency: 0.132339 |\n",
      "Training epoch: 10 [200/2000 (10%)] | D loss (A): 0.219339 | D loss (B): 0.112348 | G loss: 1.860017 | Consistency: 0.155697 |\n",
      "Training epoch: 10 [300/2000 (15%)] | D loss (A): 0.222792 | D loss (B): 0.234364 | G loss: 2.277577 | Consistency: 0.132636 |\n",
      "Training epoch: 10 [400/2000 (20%)] | D loss (A): 0.122772 | D loss (B): 0.165964 | G loss: 2.876345 | Consistency: 0.203172 |\n",
      "Training epoch: 10 [500/2000 (25%)] | D loss (A): 0.190631 | D loss (B): 0.205640 | G loss: 1.856983 | Consistency: 0.138014 |\n",
      "Training epoch: 10 [600/2000 (30%)] | D loss (A): 0.134990 | D loss (B): 0.258213 | G loss: 2.023699 | Consistency: 0.166989 |\n",
      "Training epoch: 10 [700/2000 (35%)] | D loss (A): 0.167199 | D loss (B): 0.250180 | G loss: 2.030518 | Consistency: 0.121716 |\n",
      "Training epoch: 10 [800/2000 (40%)] | D loss (A): 0.089957 | D loss (B): 0.270788 | G loss: 2.182613 | Consistency: 0.179869 |\n",
      "Training epoch: 10 [900/2000 (45%)] | D loss (A): 0.109260 | D loss (B): 0.223527 | G loss: 2.243546 | Consistency: 0.137393 |\n",
      "Training epoch: 10 [1000/2000 (50%)] | D loss (A): 0.174448 | D loss (B): 0.295424 | G loss: 2.766608 | Consistency: 0.189620 |\n",
      "Training epoch: 10 [1100/2000 (55%)] | D loss (A): 0.155954 | D loss (B): 0.313967 | G loss: 2.294571 | Consistency: 0.164478 |\n",
      "Training epoch: 10 [1200/2000 (60%)] | D loss (A): 0.078205 | D loss (B): 0.278786 | G loss: 1.968665 | Consistency: 0.134484 |\n",
      "Training epoch: 10 [1300/2000 (65%)] | D loss (A): 0.191276 | D loss (B): 0.204985 | G loss: 1.723914 | Consistency: 0.105052 |\n",
      "Training epoch: 10 [1400/2000 (70%)] | D loss (A): 0.094630 | D loss (B): 0.249837 | G loss: 3.046518 | Consistency: 0.240964 |\n",
      "Training epoch: 10 [1500/2000 (75%)] | D loss (A): 0.186315 | D loss (B): 0.176434 | G loss: 1.990912 | Consistency: 0.130306 |\n",
      "Training epoch: 10 [1600/2000 (80%)] | D loss (A): 0.514058 | D loss (B): 0.167581 | G loss: 2.430644 | Consistency: 0.120883 |\n",
      "Training epoch: 10 [1700/2000 (85%)] | D loss (A): 0.047173 | D loss (B): 0.172360 | G loss: 1.808779 | Consistency: 0.122216 |\n",
      "Training epoch: 10 [1800/2000 (90%)] | D loss (A): 0.105788 | D loss (B): 0.121947 | G loss: 1.785406 | Consistency: 0.139005 |\n",
      "Training epoch: 10 [1900/2000 (95%)] | D loss (A): 0.104670 | D loss (B): 0.173731 | G loss: 1.573680 | Consistency: 0.120461 |\n",
      "Training epoch: 11 [0/2000 (0%)] | D loss (A): 0.229353 | D loss (B): 0.170245 | G loss: 2.760024 | Consistency: 0.157481 |\n",
      "Training epoch: 11 [100/2000 (5%)] | D loss (A): 0.088027 | D loss (B): 0.157972 | G loss: 3.390808 | Consistency: 0.225291 |\n",
      "Training epoch: 11 [200/2000 (10%)] | D loss (A): 0.119921 | D loss (B): 0.253147 | G loss: 2.488756 | Consistency: 0.118723 |\n",
      "Training epoch: 11 [300/2000 (15%)] | D loss (A): 0.123902 | D loss (B): 0.170190 | G loss: 3.069476 | Consistency: 0.185312 |\n",
      "Training epoch: 11 [400/2000 (20%)] | D loss (A): 0.202027 | D loss (B): 0.325866 | G loss: 2.257719 | Consistency: 0.134815 |\n",
      "Training epoch: 11 [500/2000 (25%)] | D loss (A): 0.141250 | D loss (B): 0.206161 | G loss: 2.918756 | Consistency: 0.161110 |\n",
      "Training epoch: 11 [600/2000 (30%)] | D loss (A): 0.251821 | D loss (B): 0.197131 | G loss: 3.057081 | Consistency: 0.151862 |\n",
      "Training epoch: 11 [700/2000 (35%)] | D loss (A): 0.107830 | D loss (B): 0.214026 | G loss: 2.460959 | Consistency: 0.128928 |\n",
      "Training epoch: 11 [800/2000 (40%)] | D loss (A): 0.122957 | D loss (B): 0.093767 | G loss: 2.313000 | Consistency: 0.125844 |\n",
      "Training epoch: 11 [900/2000 (45%)] | D loss (A): 0.268032 | D loss (B): 0.171975 | G loss: 2.851866 | Consistency: 0.187432 |\n",
      "Training epoch: 11 [1000/2000 (50%)] | D loss (A): 0.231625 | D loss (B): 0.194762 | G loss: 2.748580 | Consistency: 0.162764 |\n",
      "Training epoch: 11 [1100/2000 (55%)] | D loss (A): 0.229028 | D loss (B): 0.082933 | G loss: 3.249387 | Consistency: 0.182287 |\n",
      "Training epoch: 11 [1200/2000 (60%)] | D loss (A): 0.174672 | D loss (B): 0.212926 | G loss: 3.025306 | Consistency: 0.242203 |\n",
      "Training epoch: 11 [1300/2000 (65%)] | D loss (A): 0.137909 | D loss (B): 0.223874 | G loss: 2.444124 | Consistency: 0.187691 |\n",
      "Training epoch: 11 [1400/2000 (70%)] | D loss (A): 0.157652 | D loss (B): 0.125398 | G loss: 2.426226 | Consistency: 0.161427 |\n",
      "Training epoch: 11 [1500/2000 (75%)] | D loss (A): 0.194175 | D loss (B): 0.169472 | G loss: 2.018137 | Consistency: 0.128649 |\n",
      "Training epoch: 11 [1600/2000 (80%)] | D loss (A): 0.406861 | D loss (B): 0.251026 | G loss: 1.980489 | Consistency: 0.158484 |\n",
      "Training epoch: 11 [1700/2000 (85%)] | D loss (A): 1.157614 | D loss (B): 0.202219 | G loss: 4.746765 | Consistency: 0.378159 |\n",
      "Training epoch: 11 [1800/2000 (90%)] | D loss (A): 0.222343 | D loss (B): 0.207694 | G loss: 2.368620 | Consistency: 0.177563 |\n",
      "Training epoch: 11 [1900/2000 (95%)] | D loss (A): 0.267858 | D loss (B): 0.111902 | G loss: 1.842085 | Consistency: 0.137177 |\n",
      "Training epoch: 12 [0/2000 (0%)] | D loss (A): 0.265353 | D loss (B): 0.242020 | G loss: 1.960890 | Consistency: 0.131451 |\n",
      "Training epoch: 12 [100/2000 (5%)] | D loss (A): 0.227118 | D loss (B): 0.076129 | G loss: 2.209670 | Consistency: 0.159285 |\n",
      "Training epoch: 12 [200/2000 (10%)] | D loss (A): 0.261518 | D loss (B): 0.167825 | G loss: 2.321493 | Consistency: 0.166531 |\n",
      "Training epoch: 12 [300/2000 (15%)] | D loss (A): 0.211623 | D loss (B): 0.202899 | G loss: 1.776169 | Consistency: 0.121410 |\n",
      "Training epoch: 12 [400/2000 (20%)] | D loss (A): 0.234304 | D loss (B): 0.163610 | G loss: 1.731521 | Consistency: 0.120132 |\n",
      "Training epoch: 12 [500/2000 (25%)] | D loss (A): 0.207010 | D loss (B): 0.119623 | G loss: 2.267827 | Consistency: 0.140082 |\n",
      "Training epoch: 12 [600/2000 (30%)] | D loss (A): 0.219802 | D loss (B): 0.162054 | G loss: 1.874848 | Consistency: 0.106057 |\n",
      "Training epoch: 12 [700/2000 (35%)] | D loss (A): 0.236139 | D loss (B): 0.050843 | G loss: 2.170200 | Consistency: 0.120802 |\n",
      "Training epoch: 12 [800/2000 (40%)] | D loss (A): 0.254389 | D loss (B): 0.153886 | G loss: 2.400959 | Consistency: 0.160657 |\n",
      "Training epoch: 12 [900/2000 (45%)] | D loss (A): 0.240959 | D loss (B): 0.062093 | G loss: 2.096531 | Consistency: 0.131629 |\n",
      "Training epoch: 12 [1000/2000 (50%)] | D loss (A): 0.261022 | D loss (B): 0.213929 | G loss: 1.992617 | Consistency: 0.119217 |\n",
      "Training epoch: 12 [1100/2000 (55%)] | D loss (A): 0.283794 | D loss (B): 0.252349 | G loss: 1.906332 | Consistency: 0.133952 |\n",
      "Training epoch: 12 [1200/2000 (60%)] | D loss (A): 0.208892 | D loss (B): 0.155090 | G loss: 1.527624 | Consistency: 0.102568 |\n",
      "Training epoch: 12 [1300/2000 (65%)] | D loss (A): 0.206246 | D loss (B): 0.314818 | G loss: 1.666699 | Consistency: 0.114635 |\n",
      "Training epoch: 12 [1400/2000 (70%)] | D loss (A): 0.224738 | D loss (B): 0.149157 | G loss: 2.639072 | Consistency: 0.177738 |\n",
      "Training epoch: 12 [1500/2000 (75%)] | D loss (A): 0.252634 | D loss (B): 0.160885 | G loss: 2.000340 | Consistency: 0.113977 |\n",
      "Training epoch: 12 [1600/2000 (80%)] | D loss (A): 0.245699 | D loss (B): 0.180484 | G loss: 1.521029 | Consistency: 0.114239 |\n",
      "Training epoch: 12 [1700/2000 (85%)] | D loss (A): 0.295995 | D loss (B): 0.205993 | G loss: 1.933115 | Consistency: 0.103064 |\n",
      "Training epoch: 12 [1800/2000 (90%)] | D loss (A): 0.215529 | D loss (B): 0.174892 | G loss: 3.175955 | Consistency: 0.174557 |\n",
      "Training epoch: 12 [1900/2000 (95%)] | D loss (A): 0.302982 | D loss (B): 0.232702 | G loss: 2.555310 | Consistency: 0.171508 |\n",
      "Training epoch: 13 [0/2000 (0%)] | D loss (A): 0.298112 | D loss (B): 0.176523 | G loss: 2.153490 | Consistency: 0.154108 |\n",
      "Training epoch: 13 [100/2000 (5%)] | D loss (A): 0.231253 | D loss (B): 0.167883 | G loss: 1.666571 | Consistency: 0.114305 |\n",
      "Training epoch: 13 [200/2000 (10%)] | D loss (A): 0.276432 | D loss (B): 0.128554 | G loss: 1.820376 | Consistency: 0.108854 |\n",
      "Training epoch: 13 [300/2000 (15%)] | D loss (A): 0.208570 | D loss (B): 0.094652 | G loss: 1.579007 | Consistency: 0.121757 |\n",
      "Training epoch: 13 [400/2000 (20%)] | D loss (A): 0.224847 | D loss (B): 0.126668 | G loss: 2.047561 | Consistency: 0.136903 |\n",
      "Training epoch: 13 [500/2000 (25%)] | D loss (A): 0.233555 | D loss (B): 0.153336 | G loss: 2.016961 | Consistency: 0.130424 |\n",
      "Training epoch: 13 [600/2000 (30%)] | D loss (A): 0.241077 | D loss (B): 0.075707 | G loss: 1.374002 | Consistency: 0.091729 |\n",
      "Training epoch: 13 [700/2000 (35%)] | D loss (A): 0.186703 | D loss (B): 0.057455 | G loss: 1.698331 | Consistency: 0.102947 |\n",
      "Training epoch: 13 [800/2000 (40%)] | D loss (A): 0.171786 | D loss (B): 0.190552 | G loss: 3.210251 | Consistency: 0.209160 |\n",
      "Training epoch: 13 [900/2000 (45%)] | D loss (A): 0.150021 | D loss (B): 0.271309 | G loss: 2.047771 | Consistency: 0.143745 |\n",
      "Training epoch: 13 [1000/2000 (50%)] | D loss (A): 0.220180 | D loss (B): 0.092554 | G loss: 2.562410 | Consistency: 0.170396 |\n",
      "Training epoch: 13 [1100/2000 (55%)] | D loss (A): 0.267521 | D loss (B): 0.126114 | G loss: 2.866609 | Consistency: 0.163515 |\n",
      "Training epoch: 13 [1200/2000 (60%)] | D loss (A): 0.132729 | D loss (B): 0.164337 | G loss: 2.471458 | Consistency: 0.179215 |\n",
      "Training epoch: 13 [1300/2000 (65%)] | D loss (A): 0.368843 | D loss (B): 0.195439 | G loss: 2.227715 | Consistency: 0.130150 |\n",
      "Training epoch: 13 [1400/2000 (70%)] | D loss (A): 0.273129 | D loss (B): 0.094070 | G loss: 2.642559 | Consistency: 0.149496 |\n",
      "Training epoch: 13 [1500/2000 (75%)] | D loss (A): 0.325109 | D loss (B): 0.158433 | G loss: 1.668516 | Consistency: 0.125705 |\n",
      "Training epoch: 13 [1600/2000 (80%)] | D loss (A): 0.293313 | D loss (B): 0.205219 | G loss: 2.001492 | Consistency: 0.119875 |\n",
      "Training epoch: 13 [1700/2000 (85%)] | D loss (A): 0.217760 | D loss (B): 0.108709 | G loss: 2.704865 | Consistency: 0.144747 |\n",
      "Training epoch: 13 [1800/2000 (90%)] | D loss (A): 0.216966 | D loss (B): 0.144044 | G loss: 2.280508 | Consistency: 0.132747 |\n",
      "Training epoch: 13 [1900/2000 (95%)] | D loss (A): 0.240652 | D loss (B): 0.148614 | G loss: 2.622246 | Consistency: 0.132342 |\n",
      "Training epoch: 14 [0/2000 (0%)] | D loss (A): 0.242984 | D loss (B): 0.180934 | G loss: 2.971903 | Consistency: 0.185421 |\n",
      "Training epoch: 14 [100/2000 (5%)] | D loss (A): 0.207398 | D loss (B): 0.092570 | G loss: 2.329681 | Consistency: 0.129649 |\n",
      "Training epoch: 14 [200/2000 (10%)] | D loss (A): 0.257627 | D loss (B): 0.269285 | G loss: 2.317649 | Consistency: 0.143785 |\n",
      "Training epoch: 14 [300/2000 (15%)] | D loss (A): 0.240021 | D loss (B): 0.201705 | G loss: 2.360900 | Consistency: 0.146594 |\n",
      "Training epoch: 14 [400/2000 (20%)] | D loss (A): 0.315956 | D loss (B): 0.084908 | G loss: 1.631204 | Consistency: 0.123787 |\n",
      "Training epoch: 14 [500/2000 (25%)] | D loss (A): 0.164839 | D loss (B): 0.070776 | G loss: 1.695878 | Consistency: 0.127586 |\n",
      "Training epoch: 14 [600/2000 (30%)] | D loss (A): 0.214581 | D loss (B): 0.051382 | G loss: 2.012752 | Consistency: 0.134106 |\n",
      "Training epoch: 14 [700/2000 (35%)] | D loss (A): 0.252971 | D loss (B): 0.060734 | G loss: 2.745475 | Consistency: 0.153339 |\n",
      "Training epoch: 14 [800/2000 (40%)] | D loss (A): 0.222296 | D loss (B): 0.082443 | G loss: 3.064216 | Consistency: 0.171801 |\n",
      "Training epoch: 14 [900/2000 (45%)] | D loss (A): 0.258121 | D loss (B): 0.065288 | G loss: 2.053957 | Consistency: 0.146970 |\n",
      "Training epoch: 14 [1000/2000 (50%)] | D loss (A): 0.141770 | D loss (B): 0.210242 | G loss: 2.535126 | Consistency: 0.131838 |\n",
      "Training epoch: 14 [1100/2000 (55%)] | D loss (A): 0.173485 | D loss (B): 0.205471 | G loss: 3.594593 | Consistency: 0.217899 |\n",
      "Training epoch: 14 [1200/2000 (60%)] | D loss (A): 0.062636 | D loss (B): 0.132597 | G loss: 2.640130 | Consistency: 0.166158 |\n",
      "Training epoch: 14 [1300/2000 (65%)] | D loss (A): 0.130433 | D loss (B): 0.056263 | G loss: 3.100344 | Consistency: 0.163303 |\n",
      "Training epoch: 14 [1400/2000 (70%)] | D loss (A): 0.075628 | D loss (B): 0.182885 | G loss: 2.526435 | Consistency: 0.164444 |\n",
      "Training epoch: 14 [1500/2000 (75%)] | D loss (A): 0.266933 | D loss (B): 0.123105 | G loss: 2.427967 | Consistency: 0.158212 |\n",
      "Training epoch: 14 [1600/2000 (80%)] | D loss (A): 0.159495 | D loss (B): 0.115985 | G loss: 1.932797 | Consistency: 0.128636 |\n",
      "Training epoch: 14 [1700/2000 (85%)] | D loss (A): 0.140245 | D loss (B): 0.158281 | G loss: 2.174984 | Consistency: 0.104664 |\n",
      "Training epoch: 14 [1800/2000 (90%)] | D loss (A): 0.239682 | D loss (B): 0.135243 | G loss: 2.415335 | Consistency: 0.127754 |\n",
      "Training epoch: 14 [1900/2000 (95%)] | D loss (A): 0.105206 | D loss (B): 0.102398 | G loss: 2.217496 | Consistency: 0.130038 |\n",
      "Training epoch: 15 [0/2000 (0%)] | D loss (A): 0.126846 | D loss (B): 0.085444 | G loss: 2.188525 | Consistency: 0.146142 |\n",
      "Training epoch: 15 [100/2000 (5%)] | D loss (A): 0.239284 | D loss (B): 0.065314 | G loss: 2.357392 | Consistency: 0.113673 |\n",
      "Training epoch: 15 [200/2000 (10%)] | D loss (A): 0.257541 | D loss (B): 0.138563 | G loss: 2.440120 | Consistency: 0.140984 |\n",
      "Training epoch: 15 [300/2000 (15%)] | D loss (A): 0.115877 | D loss (B): 0.104835 | G loss: 2.520107 | Consistency: 0.152584 |\n",
      "Training epoch: 15 [400/2000 (20%)] | D loss (A): 0.091742 | D loss (B): 0.050648 | G loss: 2.426339 | Consistency: 0.187167 |\n",
      "Training epoch: 15 [500/2000 (25%)] | D loss (A): 0.118982 | D loss (B): 0.351783 | G loss: 2.378718 | Consistency: 0.143922 |\n",
      "Training epoch: 15 [600/2000 (30%)] | D loss (A): 0.133321 | D loss (B): 0.257222 | G loss: 1.851153 | Consistency: 0.100662 |\n",
      "Training epoch: 15 [700/2000 (35%)] | D loss (A): 0.165584 | D loss (B): 0.116156 | G loss: 2.651443 | Consistency: 0.134421 |\n",
      "Training epoch: 15 [800/2000 (40%)] | D loss (A): 0.192867 | D loss (B): 0.044714 | G loss: 2.669886 | Consistency: 0.169536 |\n",
      "Training epoch: 15 [900/2000 (45%)] | D loss (A): 0.259283 | D loss (B): 0.073413 | G loss: 2.388586 | Consistency: 0.130055 |\n",
      "Training epoch: 15 [1000/2000 (50%)] | D loss (A): 0.050031 | D loss (B): 0.102836 | G loss: 2.606167 | Consistency: 0.153359 |\n",
      "Training epoch: 15 [1100/2000 (55%)] | D loss (A): 0.199835 | D loss (B): 0.097148 | G loss: 3.292845 | Consistency: 0.212453 |\n",
      "Training epoch: 15 [1200/2000 (60%)] | D loss (A): 0.092108 | D loss (B): 0.284185 | G loss: 2.202506 | Consistency: 0.099178 |\n",
      "Training epoch: 15 [1300/2000 (65%)] | D loss (A): 0.189968 | D loss (B): 0.157637 | G loss: 2.558344 | Consistency: 0.112071 |\n",
      "Training epoch: 15 [1400/2000 (70%)] | D loss (A): 0.180685 | D loss (B): 0.164207 | G loss: 3.042514 | Consistency: 0.185068 |\n",
      "Training epoch: 15 [1500/2000 (75%)] | D loss (A): 0.144195 | D loss (B): 0.131764 | G loss: 1.873328 | Consistency: 0.126233 |\n",
      "Training epoch: 15 [1600/2000 (80%)] | D loss (A): 0.315643 | D loss (B): 0.143026 | G loss: 2.296803 | Consistency: 0.150690 |\n",
      "Training epoch: 15 [1700/2000 (85%)] | D loss (A): 0.127552 | D loss (B): 0.068064 | G loss: 2.452986 | Consistency: 0.152378 |\n",
      "Training epoch: 15 [1800/2000 (90%)] | D loss (A): 0.289237 | D loss (B): 0.070554 | G loss: 3.197375 | Consistency: 0.185136 |\n",
      "Training epoch: 15 [1900/2000 (95%)] | D loss (A): 0.274859 | D loss (B): 0.183384 | G loss: 2.040872 | Consistency: 0.120849 |\n",
      "Training epoch: 16 [0/2000 (0%)] | D loss (A): 0.253239 | D loss (B): 0.073322 | G loss: 1.923227 | Consistency: 0.135213 |\n",
      "Training epoch: 16 [100/2000 (5%)] | D loss (A): 0.240291 | D loss (B): 0.289202 | G loss: 1.765023 | Consistency: 0.108565 |\n",
      "Training epoch: 16 [200/2000 (10%)] | D loss (A): 0.240578 | D loss (B): 0.187096 | G loss: 2.303188 | Consistency: 0.145617 |\n",
      "Training epoch: 16 [300/2000 (15%)] | D loss (A): 0.272276 | D loss (B): 0.129455 | G loss: 1.362174 | Consistency: 0.099713 |\n",
      "Training epoch: 16 [400/2000 (20%)] | D loss (A): 0.262397 | D loss (B): 0.078272 | G loss: 2.480949 | Consistency: 0.136018 |\n",
      "Training epoch: 16 [500/2000 (25%)] | D loss (A): 0.238143 | D loss (B): 0.091668 | G loss: 2.365817 | Consistency: 0.155901 |\n",
      "Training epoch: 16 [600/2000 (30%)] | D loss (A): 0.238609 | D loss (B): 0.281959 | G loss: 1.865071 | Consistency: 0.107222 |\n",
      "Training epoch: 16 [700/2000 (35%)] | D loss (A): 0.226730 | D loss (B): 0.266295 | G loss: 2.567989 | Consistency: 0.153005 |\n",
      "Training epoch: 16 [800/2000 (40%)] | D loss (A): 0.302431 | D loss (B): 0.081944 | G loss: 1.754735 | Consistency: 0.128647 |\n",
      "Training epoch: 16 [900/2000 (45%)] | D loss (A): 0.293170 | D loss (B): 0.072955 | G loss: 1.947397 | Consistency: 0.097600 |\n",
      "Training epoch: 16 [1000/2000 (50%)] | D loss (A): 0.231450 | D loss (B): 0.175042 | G loss: 1.721590 | Consistency: 0.116204 |\n",
      "Training epoch: 16 [1100/2000 (55%)] | D loss (A): 0.239283 | D loss (B): 0.186250 | G loss: 1.732888 | Consistency: 0.115847 |\n",
      "Training epoch: 16 [1200/2000 (60%)] | D loss (A): 0.235133 | D loss (B): 0.059028 | G loss: 2.395573 | Consistency: 0.164191 |\n",
      "Training epoch: 16 [1300/2000 (65%)] | D loss (A): 0.265822 | D loss (B): 0.120178 | G loss: 2.139194 | Consistency: 0.153929 |\n",
      "Training epoch: 16 [1400/2000 (70%)] | D loss (A): 0.243430 | D loss (B): 0.128254 | G loss: 2.592505 | Consistency: 0.143949 |\n",
      "Training epoch: 16 [1500/2000 (75%)] | D loss (A): 0.227964 | D loss (B): 0.135363 | G loss: 2.456822 | Consistency: 0.103926 |\n",
      "Training epoch: 16 [1600/2000 (80%)] | D loss (A): 0.196501 | D loss (B): 0.138482 | G loss: 1.942856 | Consistency: 0.136657 |\n",
      "Training epoch: 16 [1700/2000 (85%)] | D loss (A): 0.301367 | D loss (B): 0.131992 | G loss: 2.511629 | Consistency: 0.140329 |\n",
      "Training epoch: 16 [1800/2000 (90%)] | D loss (A): 0.207417 | D loss (B): 0.179671 | G loss: 1.632020 | Consistency: 0.095701 |\n",
      "Training epoch: 16 [1900/2000 (95%)] | D loss (A): 0.272280 | D loss (B): 0.154944 | G loss: 2.715019 | Consistency: 0.177937 |\n",
      "Training epoch: 17 [0/2000 (0%)] | D loss (A): 0.183092 | D loss (B): 0.056148 | G loss: 2.668334 | Consistency: 0.177537 |\n",
      "Training epoch: 17 [100/2000 (5%)] | D loss (A): 0.164743 | D loss (B): 0.299347 | G loss: 2.917369 | Consistency: 0.234465 |\n",
      "Training epoch: 17 [200/2000 (10%)] | D loss (A): 0.180425 | D loss (B): 0.255834 | G loss: 2.361961 | Consistency: 0.197225 |\n",
      "Training epoch: 17 [300/2000 (15%)] | D loss (A): 0.226813 | D loss (B): 0.228721 | G loss: 1.830261 | Consistency: 0.123227 |\n",
      "Training epoch: 17 [400/2000 (20%)] | D loss (A): 0.103964 | D loss (B): 0.241522 | G loss: 2.853462 | Consistency: 0.223523 |\n",
      "Training epoch: 17 [500/2000 (25%)] | D loss (A): 0.259526 | D loss (B): 0.225149 | G loss: 2.158969 | Consistency: 0.136016 |\n",
      "Training epoch: 17 [600/2000 (30%)] | D loss (A): 0.128678 | D loss (B): 0.253484 | G loss: 2.025441 | Consistency: 0.141404 |\n",
      "Training epoch: 17 [700/2000 (35%)] | D loss (A): 0.145826 | D loss (B): 0.244650 | G loss: 2.110876 | Consistency: 0.123481 |\n",
      "Training epoch: 17 [800/2000 (40%)] | D loss (A): 0.198760 | D loss (B): 0.275084 | G loss: 2.041211 | Consistency: 0.134473 |\n",
      "Training epoch: 17 [900/2000 (45%)] | D loss (A): 0.151010 | D loss (B): 0.237001 | G loss: 1.647605 | Consistency: 0.120274 |\n",
      "Training epoch: 17 [1000/2000 (50%)] | D loss (A): 0.185426 | D loss (B): 0.205109 | G loss: 3.078537 | Consistency: 0.215231 |\n",
      "Training epoch: 17 [1100/2000 (55%)] | D loss (A): 0.099856 | D loss (B): 0.233122 | G loss: 1.799001 | Consistency: 0.145827 |\n",
      "Training epoch: 17 [1200/2000 (60%)] | D loss (A): 0.210416 | D loss (B): 0.266272 | G loss: 1.983736 | Consistency: 0.152306 |\n",
      "Training epoch: 17 [1300/2000 (65%)] | D loss (A): 0.160547 | D loss (B): 0.197441 | G loss: 1.689511 | Consistency: 0.120037 |\n",
      "Training epoch: 17 [1400/2000 (70%)] | D loss (A): 0.249328 | D loss (B): 0.230928 | G loss: 1.900599 | Consistency: 0.127154 |\n",
      "Training epoch: 17 [1500/2000 (75%)] | D loss (A): 0.190664 | D loss (B): 0.216058 | G loss: 2.130998 | Consistency: 0.123583 |\n",
      "Training epoch: 17 [1600/2000 (80%)] | D loss (A): 0.124181 | D loss (B): 0.221342 | G loss: 3.262644 | Consistency: 0.170417 |\n",
      "Training epoch: 17 [1700/2000 (85%)] | D loss (A): 0.114052 | D loss (B): 0.279761 | G loss: 2.306694 | Consistency: 0.150861 |\n",
      "Training epoch: 17 [1800/2000 (90%)] | D loss (A): 0.188427 | D loss (B): 0.241877 | G loss: 2.985781 | Consistency: 0.171738 |\n",
      "Training epoch: 17 [1900/2000 (95%)] | D loss (A): 0.232625 | D loss (B): 0.218108 | G loss: 1.932567 | Consistency: 0.128649 |\n",
      "Training epoch: 18 [0/2000 (0%)] | D loss (A): 0.288389 | D loss (B): 0.105541 | G loss: 1.861694 | Consistency: 0.121141 |\n",
      "Training epoch: 18 [100/2000 (5%)] | D loss (A): 0.160875 | D loss (B): 0.228365 | G loss: 2.163993 | Consistency: 0.118673 |\n",
      "Training epoch: 18 [200/2000 (10%)] | D loss (A): 0.040044 | D loss (B): 0.123438 | G loss: 2.780473 | Consistency: 0.177149 |\n",
      "Training epoch: 18 [300/2000 (15%)] | D loss (A): 0.148526 | D loss (B): 0.138534 | G loss: 2.236305 | Consistency: 0.137178 |\n",
      "Training epoch: 18 [400/2000 (20%)] | D loss (A): 0.213506 | D loss (B): 0.176987 | G loss: 2.478603 | Consistency: 0.124122 |\n",
      "Training epoch: 18 [500/2000 (25%)] | D loss (A): 0.084290 | D loss (B): 0.267342 | G loss: 1.896804 | Consistency: 0.148435 |\n",
      "Training epoch: 18 [600/2000 (30%)] | D loss (A): 0.152704 | D loss (B): 0.142042 | G loss: 2.918965 | Consistency: 0.167515 |\n",
      "Training epoch: 18 [700/2000 (35%)] | D loss (A): 0.065310 | D loss (B): 0.272722 | G loss: 2.498561 | Consistency: 0.144700 |\n",
      "Training epoch: 18 [800/2000 (40%)] | D loss (A): 0.130761 | D loss (B): 0.114641 | G loss: 3.079559 | Consistency: 0.172241 |\n",
      "Training epoch: 18 [900/2000 (45%)] | D loss (A): 0.185388 | D loss (B): 0.237829 | G loss: 2.669935 | Consistency: 0.151549 |\n",
      "Training epoch: 18 [1000/2000 (50%)] | D loss (A): 0.148082 | D loss (B): 0.067676 | G loss: 2.260846 | Consistency: 0.144028 |\n",
      "Training epoch: 18 [1100/2000 (55%)] | D loss (A): 0.225098 | D loss (B): 0.102545 | G loss: 1.684410 | Consistency: 0.099264 |\n",
      "Training epoch: 18 [1200/2000 (60%)] | D loss (A): 0.171839 | D loss (B): 0.089263 | G loss: 2.645499 | Consistency: 0.181016 |\n",
      "Training epoch: 18 [1300/2000 (65%)] | D loss (A): 0.111843 | D loss (B): 0.182479 | G loss: 1.867191 | Consistency: 0.109151 |\n",
      "Training epoch: 18 [1400/2000 (70%)] | D loss (A): 0.250814 | D loss (B): 0.153504 | G loss: 2.016500 | Consistency: 0.130397 |\n",
      "Training epoch: 18 [1500/2000 (75%)] | D loss (A): 0.182758 | D loss (B): 0.059174 | G loss: 1.972355 | Consistency: 0.148777 |\n",
      "Training epoch: 18 [1600/2000 (80%)] | D loss (A): 0.448453 | D loss (B): 0.260800 | G loss: 2.261350 | Consistency: 0.135828 |\n",
      "Training epoch: 18 [1700/2000 (85%)] | D loss (A): 0.376697 | D loss (B): 0.173741 | G loss: 1.888311 | Consistency: 0.120218 |\n",
      "Training epoch: 18 [1800/2000 (90%)] | D loss (A): 0.416385 | D loss (B): 0.111322 | G loss: 3.509165 | Consistency: 0.150456 |\n",
      "Training epoch: 18 [1900/2000 (95%)] | D loss (A): 0.211536 | D loss (B): 0.113339 | G loss: 1.701238 | Consistency: 0.120069 |\n",
      "Training epoch: 19 [0/2000 (0%)] | D loss (A): 0.158570 | D loss (B): 0.148426 | G loss: 2.123826 | Consistency: 0.120728 |\n",
      "Training epoch: 19 [100/2000 (5%)] | D loss (A): 0.087640 | D loss (B): 0.290393 | G loss: 2.103311 | Consistency: 0.142633 |\n",
      "Training epoch: 19 [200/2000 (10%)] | D loss (A): 0.295814 | D loss (B): 0.248815 | G loss: 2.623793 | Consistency: 0.134909 |\n",
      "Training epoch: 19 [300/2000 (15%)] | D loss (A): 0.215935 | D loss (B): 0.073962 | G loss: 2.677109 | Consistency: 0.122499 |\n",
      "Training epoch: 19 [400/2000 (20%)] | D loss (A): 0.174056 | D loss (B): 0.156259 | G loss: 2.009069 | Consistency: 0.121937 |\n",
      "Training epoch: 19 [500/2000 (25%)] | D loss (A): 0.106518 | D loss (B): 0.130860 | G loss: 2.718258 | Consistency: 0.191888 |\n",
      "Training epoch: 19 [600/2000 (30%)] | D loss (A): 0.232275 | D loss (B): 0.136237 | G loss: 2.330928 | Consistency: 0.135562 |\n",
      "Training epoch: 19 [700/2000 (35%)] | D loss (A): 0.217417 | D loss (B): 0.215004 | G loss: 2.250848 | Consistency: 0.152396 |\n",
      "Training epoch: 19 [800/2000 (40%)] | D loss (A): 0.146219 | D loss (B): 0.164704 | G loss: 2.481658 | Consistency: 0.159844 |\n",
      "Training epoch: 19 [900/2000 (45%)] | D loss (A): 0.032592 | D loss (B): 0.104424 | G loss: 3.931003 | Consistency: 0.178894 |\n",
      "Training epoch: 19 [1000/2000 (50%)] | D loss (A): 0.300707 | D loss (B): 0.221861 | G loss: 2.227168 | Consistency: 0.126168 |\n",
      "Training epoch: 19 [1100/2000 (55%)] | D loss (A): 0.207548 | D loss (B): 0.104068 | G loss: 1.973441 | Consistency: 0.134800 |\n",
      "Training epoch: 19 [1200/2000 (60%)] | D loss (A): 0.214574 | D loss (B): 0.118928 | G loss: 2.147197 | Consistency: 0.158826 |\n",
      "Training epoch: 19 [1300/2000 (65%)] | D loss (A): 0.231523 | D loss (B): 0.115404 | G loss: 1.832088 | Consistency: 0.132239 |\n",
      "Training epoch: 19 [1400/2000 (70%)] | D loss (A): 0.172543 | D loss (B): 0.069780 | G loss: 1.748179 | Consistency: 0.131644 |\n",
      "Training epoch: 19 [1500/2000 (75%)] | D loss (A): 0.227021 | D loss (B): 0.302988 | G loss: 2.151922 | Consistency: 0.127785 |\n",
      "Training epoch: 19 [1600/2000 (80%)] | D loss (A): 0.232589 | D loss (B): 0.128754 | G loss: 2.512900 | Consistency: 0.131551 |\n",
      "Training epoch: 19 [1700/2000 (85%)] | D loss (A): 0.167914 | D loss (B): 0.170081 | G loss: 1.906234 | Consistency: 0.108636 |\n",
      "Training epoch: 19 [1800/2000 (90%)] | D loss (A): 0.361054 | D loss (B): 0.156800 | G loss: 2.364017 | Consistency: 0.116427 |\n",
      "Training epoch: 19 [1900/2000 (95%)] | D loss (A): 0.102760 | D loss (B): 0.119897 | G loss: 2.353549 | Consistency: 0.183128 |\n",
      "Training epoch: 20 [0/2000 (0%)] | D loss (A): 0.165608 | D loss (B): 0.170130 | G loss: 2.855205 | Consistency: 0.201823 |\n",
      "Training epoch: 20 [100/2000 (5%)] | D loss (A): 0.106611 | D loss (B): 0.272245 | G loss: 1.770568 | Consistency: 0.123584 |\n",
      "Training epoch: 20 [200/2000 (10%)] | D loss (A): 0.154041 | D loss (B): 0.061146 | G loss: 2.464364 | Consistency: 0.127878 |\n",
      "Training epoch: 20 [300/2000 (15%)] | D loss (A): 0.177029 | D loss (B): 0.287873 | G loss: 2.399400 | Consistency: 0.122024 |\n",
      "Training epoch: 20 [400/2000 (20%)] | D loss (A): 0.167379 | D loss (B): 0.255227 | G loss: 2.503825 | Consistency: 0.146638 |\n",
      "Training epoch: 20 [500/2000 (25%)] | D loss (A): 0.103776 | D loss (B): 0.110099 | G loss: 2.246738 | Consistency: 0.131213 |\n",
      "Training epoch: 20 [600/2000 (30%)] | D loss (A): 0.036990 | D loss (B): 0.118335 | G loss: 2.860035 | Consistency: 0.131530 |\n",
      "Training epoch: 20 [700/2000 (35%)] | D loss (A): 0.115826 | D loss (B): 0.068380 | G loss: 1.924181 | Consistency: 0.115362 |\n",
      "Training epoch: 20 [800/2000 (40%)] | D loss (A): 0.306202 | D loss (B): 0.046726 | G loss: 2.226794 | Consistency: 0.138833 |\n",
      "Training epoch: 20 [900/2000 (45%)] | D loss (A): 0.121180 | D loss (B): 0.076026 | G loss: 3.224545 | Consistency: 0.167932 |\n",
      "Training epoch: 20 [1000/2000 (50%)] | D loss (A): 0.032881 | D loss (B): 0.120912 | G loss: 1.939867 | Consistency: 0.114941 |\n",
      "Training epoch: 20 [1100/2000 (55%)] | D loss (A): 0.210120 | D loss (B): 0.212107 | G loss: 2.235965 | Consistency: 0.122914 |\n",
      "Training epoch: 20 [1200/2000 (60%)] | D loss (A): 0.075774 | D loss (B): 0.124629 | G loss: 1.712255 | Consistency: 0.112821 |\n",
      "Training epoch: 20 [1300/2000 (65%)] | D loss (A): 0.090952 | D loss (B): 0.102967 | G loss: 1.806369 | Consistency: 0.118441 |\n",
      "Training epoch: 20 [1400/2000 (70%)] | D loss (A): 0.077258 | D loss (B): 0.172673 | G loss: 1.934896 | Consistency: 0.103376 |\n",
      "Training epoch: 20 [1500/2000 (75%)] | D loss (A): 0.200694 | D loss (B): 0.234535 | G loss: 2.527877 | Consistency: 0.141898 |\n",
      "Training epoch: 20 [1600/2000 (80%)] | D loss (A): 0.140134 | D loss (B): 0.189254 | G loss: 2.702599 | Consistency: 0.137793 |\n",
      "Training epoch: 20 [1700/2000 (85%)] | D loss (A): 0.160979 | D loss (B): 0.073607 | G loss: 3.395789 | Consistency: 0.167111 |\n",
      "Training epoch: 20 [1800/2000 (90%)] | D loss (A): 0.243839 | D loss (B): 0.260994 | G loss: 2.253115 | Consistency: 0.134704 |\n",
      "Training epoch: 20 [1900/2000 (95%)] | D loss (A): 0.092818 | D loss (B): 0.046921 | G loss: 2.992644 | Consistency: 0.174395 |\n",
      "Training epoch: 21 [0/2000 (0%)] | D loss (A): 0.137045 | D loss (B): 0.086530 | G loss: 2.431438 | Consistency: 0.125373 |\n",
      "Training epoch: 21 [100/2000 (5%)] | D loss (A): 0.194431 | D loss (B): 0.088353 | G loss: 2.600583 | Consistency: 0.151940 |\n",
      "Training epoch: 21 [200/2000 (10%)] | D loss (A): 0.106177 | D loss (B): 0.174039 | G loss: 3.028867 | Consistency: 0.160028 |\n",
      "Training epoch: 21 [300/2000 (15%)] | D loss (A): 0.194600 | D loss (B): 0.227867 | G loss: 3.150501 | Consistency: 0.160654 |\n",
      "Training epoch: 21 [400/2000 (20%)] | D loss (A): 0.255609 | D loss (B): 0.124777 | G loss: 2.242360 | Consistency: 0.122963 |\n",
      "Training epoch: 21 [500/2000 (25%)] | D loss (A): 0.261328 | D loss (B): 0.075810 | G loss: 1.459391 | Consistency: 0.103409 |\n",
      "Training epoch: 21 [600/2000 (30%)] | D loss (A): 0.243853 | D loss (B): 0.147290 | G loss: 2.151412 | Consistency: 0.107351 |\n",
      "Training epoch: 21 [700/2000 (35%)] | D loss (A): 0.206348 | D loss (B): 0.049308 | G loss: 1.516164 | Consistency: 0.089475 |\n",
      "Training epoch: 21 [800/2000 (40%)] | D loss (A): 0.277273 | D loss (B): 0.229214 | G loss: 1.682181 | Consistency: 0.096483 |\n",
      "Training epoch: 21 [900/2000 (45%)] | D loss (A): 0.287610 | D loss (B): 0.279919 | G loss: 1.717893 | Consistency: 0.100944 |\n",
      "Training epoch: 21 [1000/2000 (50%)] | D loss (A): 0.251625 | D loss (B): 0.095384 | G loss: 2.324217 | Consistency: 0.172860 |\n",
      "Training epoch: 21 [1100/2000 (55%)] | D loss (A): 0.224381 | D loss (B): 0.131092 | G loss: 2.142744 | Consistency: 0.113904 |\n",
      "Training epoch: 21 [1200/2000 (60%)] | D loss (A): 0.264749 | D loss (B): 0.248187 | G loss: 1.779338 | Consistency: 0.106022 |\n",
      "Training epoch: 21 [1300/2000 (65%)] | D loss (A): 0.346783 | D loss (B): 0.145848 | G loss: 1.802883 | Consistency: 0.125134 |\n",
      "Training epoch: 21 [1400/2000 (70%)] | D loss (A): 0.268260 | D loss (B): 0.189562 | G loss: 1.551931 | Consistency: 0.099118 |\n",
      "Training epoch: 21 [1500/2000 (75%)] | D loss (A): 0.344103 | D loss (B): 0.219196 | G loss: 2.146527 | Consistency: 0.102034 |\n",
      "Training epoch: 21 [1600/2000 (80%)] | D loss (A): 0.298464 | D loss (B): 0.216089 | G loss: 1.863410 | Consistency: 0.112964 |\n",
      "Training epoch: 21 [1700/2000 (85%)] | D loss (A): 0.250043 | D loss (B): 0.056560 | G loss: 2.075430 | Consistency: 0.139735 |\n",
      "Training epoch: 21 [1800/2000 (90%)] | D loss (A): 0.231721 | D loss (B): 0.131278 | G loss: 2.153987 | Consistency: 0.151634 |\n",
      "Training epoch: 21 [1900/2000 (95%)] | D loss (A): 0.203669 | D loss (B): 0.139629 | G loss: 2.934074 | Consistency: 0.153425 |\n",
      "Training epoch: 22 [0/2000 (0%)] | D loss (A): 0.234342 | D loss (B): 0.109941 | G loss: 1.687938 | Consistency: 0.095564 |\n",
      "Training epoch: 22 [100/2000 (5%)] | D loss (A): 0.219757 | D loss (B): 0.074422 | G loss: 3.504495 | Consistency: 0.227842 |\n",
      "Training epoch: 22 [200/2000 (10%)] | D loss (A): 0.247622 | D loss (B): 0.094004 | G loss: 1.705096 | Consistency: 0.111359 |\n",
      "Training epoch: 22 [300/2000 (15%)] | D loss (A): 0.225409 | D loss (B): 0.167781 | G loss: 1.917797 | Consistency: 0.118533 |\n",
      "Training epoch: 22 [400/2000 (20%)] | D loss (A): 0.280949 | D loss (B): 0.292899 | G loss: 1.954400 | Consistency: 0.116432 |\n",
      "Training epoch: 22 [500/2000 (25%)] | D loss (A): 0.248650 | D loss (B): 0.169956 | G loss: 1.986112 | Consistency: 0.109424 |\n",
      "Training epoch: 22 [600/2000 (30%)] | D loss (A): 0.187429 | D loss (B): 0.380663 | G loss: 1.511170 | Consistency: 0.100473 |\n",
      "Training epoch: 22 [700/2000 (35%)] | D loss (A): 0.225923 | D loss (B): 0.046078 | G loss: 1.946414 | Consistency: 0.121948 |\n",
      "Training epoch: 22 [800/2000 (40%)] | D loss (A): 0.330288 | D loss (B): 0.091074 | G loss: 1.357959 | Consistency: 0.106863 |\n",
      "Training epoch: 22 [900/2000 (45%)] | D loss (A): 0.199053 | D loss (B): 0.101136 | G loss: 1.761765 | Consistency: 0.111315 |\n",
      "Training epoch: 22 [1000/2000 (50%)] | D loss (A): 0.231266 | D loss (B): 0.230609 | G loss: 2.131173 | Consistency: 0.108339 |\n",
      "Training epoch: 22 [1100/2000 (55%)] | D loss (A): 0.241405 | D loss (B): 0.175267 | G loss: 1.494102 | Consistency: 0.107772 |\n",
      "Training epoch: 22 [1200/2000 (60%)] | D loss (A): 0.287508 | D loss (B): 0.107306 | G loss: 1.812800 | Consistency: 0.132114 |\n",
      "Training epoch: 22 [1300/2000 (65%)] | D loss (A): 0.164447 | D loss (B): 0.066297 | G loss: 1.278398 | Consistency: 0.096440 |\n",
      "Training epoch: 22 [1400/2000 (70%)] | D loss (A): 0.155123 | D loss (B): 0.100979 | G loss: 2.746861 | Consistency: 0.143163 |\n",
      "Training epoch: 22 [1500/2000 (75%)] | D loss (A): 0.184562 | D loss (B): 0.145543 | G loss: 1.902637 | Consistency: 0.111505 |\n",
      "Training epoch: 22 [1600/2000 (80%)] | D loss (A): 0.151744 | D loss (B): 0.437800 | G loss: 2.132055 | Consistency: 0.109904 |\n",
      "Training epoch: 22 [1700/2000 (85%)] | D loss (A): 0.192476 | D loss (B): 0.205883 | G loss: 2.152399 | Consistency: 0.103583 |\n",
      "Training epoch: 22 [1800/2000 (90%)] | D loss (A): 0.082927 | D loss (B): 0.093854 | G loss: 4.281146 | Consistency: 0.198019 |\n",
      "Training epoch: 22 [1900/2000 (95%)] | D loss (A): 0.153939 | D loss (B): 0.089788 | G loss: 2.920974 | Consistency: 0.168314 |\n",
      "Training epoch: 23 [0/2000 (0%)] | D loss (A): 0.053155 | D loss (B): 0.107357 | G loss: 3.514014 | Consistency: 0.232238 |\n",
      "Training epoch: 23 [100/2000 (5%)] | D loss (A): 0.113764 | D loss (B): 0.067149 | G loss: 3.387527 | Consistency: 0.226487 |\n",
      "Training epoch: 23 [200/2000 (10%)] | D loss (A): 0.039645 | D loss (B): 0.024554 | G loss: 3.611921 | Consistency: 0.200701 |\n",
      "Training epoch: 23 [300/2000 (15%)] | D loss (A): 0.358827 | D loss (B): 0.035174 | G loss: 3.431470 | Consistency: 0.163226 |\n",
      "Training epoch: 23 [400/2000 (20%)] | D loss (A): 0.087855 | D loss (B): 0.113601 | G loss: 3.217285 | Consistency: 0.177779 |\n",
      "Training epoch: 23 [500/2000 (25%)] | D loss (A): 0.082508 | D loss (B): 0.017770 | G loss: 2.912455 | Consistency: 0.147778 |\n",
      "Training epoch: 23 [600/2000 (30%)] | D loss (A): 0.155771 | D loss (B): 0.040012 | G loss: 3.261174 | Consistency: 0.164655 |\n",
      "Training epoch: 23 [700/2000 (35%)] | D loss (A): 0.154146 | D loss (B): 0.017901 | G loss: 3.104379 | Consistency: 0.204539 |\n",
      "Training epoch: 23 [800/2000 (40%)] | D loss (A): 0.030715 | D loss (B): 0.052258 | G loss: 2.777751 | Consistency: 0.172753 |\n",
      "Training epoch: 23 [900/2000 (45%)] | D loss (A): 0.346610 | D loss (B): 0.070348 | G loss: 2.477516 | Consistency: 0.129685 |\n",
      "Training epoch: 23 [1000/2000 (50%)] | D loss (A): 0.163366 | D loss (B): 0.068514 | G loss: 2.650346 | Consistency: 0.128924 |\n",
      "Training epoch: 23 [1100/2000 (55%)] | D loss (A): 0.143875 | D loss (B): 0.057707 | G loss: 2.011573 | Consistency: 0.119982 |\n",
      "Training epoch: 23 [1200/2000 (60%)] | D loss (A): 0.036119 | D loss (B): 0.052126 | G loss: 3.517905 | Consistency: 0.193008 |\n",
      "Training epoch: 23 [1300/2000 (65%)] | D loss (A): 0.101685 | D loss (B): 0.194651 | G loss: 2.461815 | Consistency: 0.121802 |\n",
      "Training epoch: 23 [1400/2000 (70%)] | D loss (A): 0.156431 | D loss (B): 0.053723 | G loss: 1.787462 | Consistency: 0.130803 |\n",
      "Training epoch: 23 [1500/2000 (75%)] | D loss (A): 0.114017 | D loss (B): 0.086892 | G loss: 2.555600 | Consistency: 0.146028 |\n",
      "Training epoch: 23 [1600/2000 (80%)] | D loss (A): 0.083939 | D loss (B): 0.041472 | G loss: 3.667923 | Consistency: 0.151730 |\n",
      "Training epoch: 23 [1700/2000 (85%)] | D loss (A): 0.106271 | D loss (B): 0.040640 | G loss: 2.121940 | Consistency: 0.140119 |\n",
      "Training epoch: 23 [1800/2000 (90%)] | D loss (A): 0.100208 | D loss (B): 0.064912 | G loss: 2.884573 | Consistency: 0.146203 |\n",
      "Training epoch: 23 [1900/2000 (95%)] | D loss (A): 0.095590 | D loss (B): 0.157034 | G loss: 1.895807 | Consistency: 0.134593 |\n",
      "Training epoch: 24 [0/2000 (0%)] | D loss (A): 0.131675 | D loss (B): 0.264196 | G loss: 2.531237 | Consistency: 0.124860 |\n",
      "Training epoch: 24 [100/2000 (5%)] | D loss (A): 0.085723 | D loss (B): 0.044930 | G loss: 2.040738 | Consistency: 0.114286 |\n",
      "Training epoch: 24 [200/2000 (10%)] | D loss (A): 0.246083 | D loss (B): 0.066866 | G loss: 2.889096 | Consistency: 0.180477 |\n",
      "Training epoch: 24 [300/2000 (15%)] | D loss (A): 0.147711 | D loss (B): 0.148635 | G loss: 2.181126 | Consistency: 0.126106 |\n",
      "Training epoch: 24 [400/2000 (20%)] | D loss (A): 0.304057 | D loss (B): 0.062998 | G loss: 2.219062 | Consistency: 0.124877 |\n",
      "Training epoch: 24 [500/2000 (25%)] | D loss (A): 0.233843 | D loss (B): 0.169756 | G loss: 2.589593 | Consistency: 0.168158 |\n",
      "Training epoch: 24 [600/2000 (30%)] | D loss (A): 0.260798 | D loss (B): 0.137119 | G loss: 2.883247 | Consistency: 0.174922 |\n",
      "Training epoch: 24 [700/2000 (35%)] | D loss (A): 0.218850 | D loss (B): 0.123803 | G loss: 1.915706 | Consistency: 0.131211 |\n",
      "Training epoch: 24 [800/2000 (40%)] | D loss (A): 0.237646 | D loss (B): 0.235095 | G loss: 2.205058 | Consistency: 0.129841 |\n",
      "Training epoch: 24 [900/2000 (45%)] | D loss (A): 0.233783 | D loss (B): 0.051713 | G loss: 1.848242 | Consistency: 0.122515 |\n",
      "Training epoch: 24 [1000/2000 (50%)] | D loss (A): 0.251121 | D loss (B): 0.117301 | G loss: 1.938530 | Consistency: 0.149530 |\n",
      "Training epoch: 24 [1100/2000 (55%)] | D loss (A): 0.237755 | D loss (B): 0.091187 | G loss: 2.889163 | Consistency: 0.156007 |\n",
      "Training epoch: 24 [1200/2000 (60%)] | D loss (A): 0.258391 | D loss (B): 0.071768 | G loss: 2.268985 | Consistency: 0.123376 |\n",
      "Training epoch: 24 [1300/2000 (65%)] | D loss (A): 0.239376 | D loss (B): 0.031076 | G loss: 2.348412 | Consistency: 0.115068 |\n",
      "Training epoch: 24 [1400/2000 (70%)] | D loss (A): 0.306397 | D loss (B): 0.036275 | G loss: 2.525189 | Consistency: 0.156640 |\n",
      "Training epoch: 24 [1500/2000 (75%)] | D loss (A): 0.279630 | D loss (B): 0.057477 | G loss: 2.541100 | Consistency: 0.110365 |\n",
      "Training epoch: 24 [1600/2000 (80%)] | D loss (A): 0.256445 | D loss (B): 0.359269 | G loss: 2.164666 | Consistency: 0.128590 |\n",
      "Training epoch: 24 [1700/2000 (85%)] | D loss (A): 0.224386 | D loss (B): 0.181604 | G loss: 1.882457 | Consistency: 0.130349 |\n",
      "Training epoch: 24 [1800/2000 (90%)] | D loss (A): 0.242944 | D loss (B): 0.041689 | G loss: 1.759649 | Consistency: 0.094797 |\n",
      "Training epoch: 24 [1900/2000 (95%)] | D loss (A): 0.270880 | D loss (B): 0.087855 | G loss: 2.263309 | Consistency: 0.087155 |\n",
      "Training epoch: 25 [0/2000 (0%)] | D loss (A): 0.218917 | D loss (B): 0.097469 | G loss: 2.193532 | Consistency: 0.116252 |\n",
      "Training epoch: 25 [100/2000 (5%)] | D loss (A): 0.151292 | D loss (B): 0.095679 | G loss: 1.871135 | Consistency: 0.096906 |\n",
      "Training epoch: 25 [200/2000 (10%)] | D loss (A): 0.308233 | D loss (B): 0.089364 | G loss: 2.814611 | Consistency: 0.132792 |\n",
      "Training epoch: 25 [300/2000 (15%)] | D loss (A): 0.267038 | D loss (B): 0.110151 | G loss: 2.150357 | Consistency: 0.127744 |\n",
      "Training epoch: 25 [400/2000 (20%)] | D loss (A): 0.188209 | D loss (B): 0.094183 | G loss: 1.751858 | Consistency: 0.098385 |\n",
      "Training epoch: 25 [500/2000 (25%)] | D loss (A): 0.303288 | D loss (B): 0.054025 | G loss: 2.261848 | Consistency: 0.138838 |\n",
      "Training epoch: 25 [600/2000 (30%)] | D loss (A): 0.298460 | D loss (B): 0.255014 | G loss: 1.797761 | Consistency: 0.080823 |\n",
      "Training epoch: 25 [700/2000 (35%)] | D loss (A): 0.210857 | D loss (B): 0.096860 | G loss: 1.346400 | Consistency: 0.104322 |\n",
      "Training epoch: 25 [800/2000 (40%)] | D loss (A): 0.275228 | D loss (B): 0.160392 | G loss: 1.880974 | Consistency: 0.119486 |\n",
      "Training epoch: 25 [900/2000 (45%)] | D loss (A): 0.240787 | D loss (B): 0.141604 | G loss: 1.578269 | Consistency: 0.122913 |\n",
      "Training epoch: 25 [1000/2000 (50%)] | D loss (A): 0.130938 | D loss (B): 0.194561 | G loss: 1.983550 | Consistency: 0.105998 |\n",
      "Training epoch: 25 [1100/2000 (55%)] | D loss (A): 0.306464 | D loss (B): 0.272806 | G loss: 1.821581 | Consistency: 0.130360 |\n",
      "Training epoch: 25 [1200/2000 (60%)] | D loss (A): 0.178269 | D loss (B): 0.147972 | G loss: 2.325845 | Consistency: 0.123029 |\n",
      "Training epoch: 25 [1300/2000 (65%)] | D loss (A): 0.193330 | D loss (B): 0.350541 | G loss: 1.392444 | Consistency: 0.101052 |\n",
      "Training epoch: 25 [1400/2000 (70%)] | D loss (A): 0.276566 | D loss (B): 0.212719 | G loss: 1.949020 | Consistency: 0.118971 |\n",
      "Training epoch: 25 [1500/2000 (75%)] | D loss (A): 0.081090 | D loss (B): 0.156893 | G loss: 2.286922 | Consistency: 0.117954 |\n",
      "Training epoch: 25 [1600/2000 (80%)] | D loss (A): 0.214292 | D loss (B): 0.186094 | G loss: 2.160497 | Consistency: 0.109728 |\n",
      "Training epoch: 25 [1700/2000 (85%)] | D loss (A): 0.220756 | D loss (B): 0.145695 | G loss: 1.937542 | Consistency: 0.110283 |\n",
      "Training epoch: 25 [1800/2000 (90%)] | D loss (A): 0.266995 | D loss (B): 0.117254 | G loss: 1.986623 | Consistency: 0.084264 |\n",
      "Training epoch: 25 [1900/2000 (95%)] | D loss (A): 0.040845 | D loss (B): 0.150462 | G loss: 2.115439 | Consistency: 0.106717 |\n",
      "Training epoch: 26 [0/2000 (0%)] | D loss (A): 0.146451 | D loss (B): 0.182947 | G loss: 2.367093 | Consistency: 0.102969 |\n",
      "Training epoch: 26 [100/2000 (5%)] | D loss (A): 0.151916 | D loss (B): 0.090531 | G loss: 2.914082 | Consistency: 0.165887 |\n",
      "Training epoch: 26 [200/2000 (10%)] | D loss (A): 0.235009 | D loss (B): 0.104062 | G loss: 1.576057 | Consistency: 0.085407 |\n",
      "Training epoch: 26 [300/2000 (15%)] | D loss (A): 0.410333 | D loss (B): 0.157933 | G loss: 1.786575 | Consistency: 0.113382 |\n",
      "Training epoch: 26 [400/2000 (20%)] | D loss (A): 0.117120 | D loss (B): 0.104285 | G loss: 2.080336 | Consistency: 0.133210 |\n",
      "Training epoch: 26 [500/2000 (25%)] | D loss (A): 0.236914 | D loss (B): 0.146063 | G loss: 2.246840 | Consistency: 0.120907 |\n",
      "Training epoch: 26 [600/2000 (30%)] | D loss (A): 0.122875 | D loss (B): 0.287195 | G loss: 2.092738 | Consistency: 0.129272 |\n",
      "Training epoch: 26 [700/2000 (35%)] | D loss (A): 0.202052 | D loss (B): 0.027931 | G loss: 1.910190 | Consistency: 0.103238 |\n",
      "Training epoch: 26 [800/2000 (40%)] | D loss (A): 0.113155 | D loss (B): 0.089753 | G loss: 2.974897 | Consistency: 0.142578 |\n",
      "Training epoch: 26 [900/2000 (45%)] | D loss (A): 0.187414 | D loss (B): 0.100279 | G loss: 2.364323 | Consistency: 0.177812 |\n",
      "Training epoch: 26 [1000/2000 (50%)] | D loss (A): 0.135694 | D loss (B): 0.045337 | G loss: 2.249141 | Consistency: 0.152090 |\n",
      "Training epoch: 26 [1100/2000 (55%)] | D loss (A): 0.155074 | D loss (B): 0.157020 | G loss: 2.270674 | Consistency: 0.102716 |\n",
      "Training epoch: 26 [1200/2000 (60%)] | D loss (A): 0.121170 | D loss (B): 0.090675 | G loss: 2.887676 | Consistency: 0.151773 |\n",
      "Training epoch: 26 [1300/2000 (65%)] | D loss (A): 0.123188 | D loss (B): 0.077605 | G loss: 1.807599 | Consistency: 0.098287 |\n",
      "Training epoch: 26 [1400/2000 (70%)] | D loss (A): 0.283129 | D loss (B): 0.155619 | G loss: 2.154585 | Consistency: 0.117140 |\n",
      "Training epoch: 26 [1500/2000 (75%)] | D loss (A): 0.208145 | D loss (B): 0.296171 | G loss: 2.386390 | Consistency: 0.121400 |\n",
      "Training epoch: 26 [1600/2000 (80%)] | D loss (A): 0.133378 | D loss (B): 0.073253 | G loss: 2.213869 | Consistency: 0.123376 |\n",
      "Training epoch: 26 [1700/2000 (85%)] | D loss (A): 0.245672 | D loss (B): 0.073200 | G loss: 1.854989 | Consistency: 0.118156 |\n",
      "Training epoch: 26 [1800/2000 (90%)] | D loss (A): 0.173029 | D loss (B): 0.211217 | G loss: 3.144881 | Consistency: 0.165160 |\n",
      "Training epoch: 26 [1900/2000 (95%)] | D loss (A): 0.129823 | D loss (B): 0.108368 | G loss: 1.670378 | Consistency: 0.118967 |\n",
      "Training epoch: 27 [0/2000 (0%)] | D loss (A): 0.188681 | D loss (B): 0.111565 | G loss: 3.198584 | Consistency: 0.170232 |\n",
      "Training epoch: 27 [100/2000 (5%)] | D loss (A): 0.326117 | D loss (B): 0.129514 | G loss: 2.262712 | Consistency: 0.124602 |\n",
      "Training epoch: 27 [200/2000 (10%)] | D loss (A): 0.143319 | D loss (B): 0.083338 | G loss: 1.784877 | Consistency: 0.137697 |\n",
      "Training epoch: 27 [300/2000 (15%)] | D loss (A): 0.128565 | D loss (B): 0.086639 | G loss: 2.211154 | Consistency: 0.094797 |\n",
      "Training epoch: 27 [400/2000 (20%)] | D loss (A): 0.121852 | D loss (B): 0.195705 | G loss: 1.637074 | Consistency: 0.087442 |\n",
      "Training epoch: 27 [500/2000 (25%)] | D loss (A): 0.100810 | D loss (B): 0.143922 | G loss: 1.795030 | Consistency: 0.107309 |\n",
      "Training epoch: 27 [600/2000 (30%)] | D loss (A): 0.095721 | D loss (B): 0.151814 | G loss: 1.633531 | Consistency: 0.110964 |\n",
      "Training epoch: 27 [700/2000 (35%)] | D loss (A): 0.360061 | D loss (B): 0.222279 | G loss: 2.206795 | Consistency: 0.117232 |\n",
      "Training epoch: 27 [800/2000 (40%)] | D loss (A): 0.185564 | D loss (B): 0.069513 | G loss: 1.912294 | Consistency: 0.110652 |\n",
      "Training epoch: 27 [900/2000 (45%)] | D loss (A): 0.125006 | D loss (B): 0.116336 | G loss: 2.250844 | Consistency: 0.132089 |\n",
      "Training epoch: 27 [1000/2000 (50%)] | D loss (A): 0.399094 | D loss (B): 0.066769 | G loss: 2.604500 | Consistency: 0.095835 |\n",
      "Training epoch: 27 [1100/2000 (55%)] | D loss (A): 0.214813 | D loss (B): 0.103029 | G loss: 2.369717 | Consistency: 0.116773 |\n",
      "Training epoch: 27 [1200/2000 (60%)] | D loss (A): 0.261847 | D loss (B): 0.092121 | G loss: 1.833149 | Consistency: 0.101438 |\n",
      "Training epoch: 27 [1300/2000 (65%)] | D loss (A): 0.059250 | D loss (B): 0.042912 | G loss: 2.184301 | Consistency: 0.153426 |\n",
      "Training epoch: 27 [1400/2000 (70%)] | D loss (A): 0.284530 | D loss (B): 0.151081 | G loss: 1.596328 | Consistency: 0.085233 |\n",
      "Training epoch: 27 [1500/2000 (75%)] | D loss (A): 0.121220 | D loss (B): 0.111269 | G loss: 2.044955 | Consistency: 0.112636 |\n",
      "Training epoch: 27 [1600/2000 (80%)] | D loss (A): 0.184262 | D loss (B): 0.094990 | G loss: 2.321824 | Consistency: 0.134359 |\n",
      "Training epoch: 27 [1700/2000 (85%)] | D loss (A): 0.109033 | D loss (B): 21.232166 | G loss: 11.321092 | Consistency: 0.336880 |\n",
      "Training epoch: 27 [1800/2000 (90%)] | D loss (A): 0.100604 | D loss (B): 0.156498 | G loss: 3.514032 | Consistency: 0.251690 |\n",
      "Training epoch: 27 [1900/2000 (95%)] | D loss (A): 0.102107 | D loss (B): 0.136254 | G loss: 3.392540 | Consistency: 0.199768 |\n",
      "Training epoch: 28 [0/2000 (0%)] | D loss (A): 0.112284 | D loss (B): 0.073378 | G loss: 2.326338 | Consistency: 0.158791 |\n",
      "Training epoch: 28 [100/2000 (5%)] | D loss (A): 0.093428 | D loss (B): 0.124067 | G loss: 2.147378 | Consistency: 0.165321 |\n",
      "Training epoch: 28 [200/2000 (10%)] | D loss (A): 0.177963 | D loss (B): 0.141172 | G loss: 2.151812 | Consistency: 0.120571 |\n",
      "Training epoch: 28 [300/2000 (15%)] | D loss (A): 0.102414 | D loss (B): 0.132951 | G loss: 2.847468 | Consistency: 0.172081 |\n",
      "Training epoch: 28 [400/2000 (20%)] | D loss (A): 0.105347 | D loss (B): 0.219002 | G loss: 3.118609 | Consistency: 0.204002 |\n",
      "Training epoch: 28 [500/2000 (25%)] | D loss (A): 0.030357 | D loss (B): 0.265520 | G loss: 2.342550 | Consistency: 0.160234 |\n",
      "Training epoch: 28 [600/2000 (30%)] | D loss (A): 0.060574 | D loss (B): 0.183708 | G loss: 3.361974 | Consistency: 0.196996 |\n",
      "Training epoch: 28 [700/2000 (35%)] | D loss (A): 0.097446 | D loss (B): 0.181559 | G loss: 3.007349 | Consistency: 0.240528 |\n",
      "Training epoch: 28 [800/2000 (40%)] | D loss (A): 0.219607 | D loss (B): 0.336259 | G loss: 2.125907 | Consistency: 0.134486 |\n",
      "Training epoch: 28 [900/2000 (45%)] | D loss (A): 0.138366 | D loss (B): 0.172693 | G loss: 2.148179 | Consistency: 0.128293 |\n",
      "Training epoch: 28 [1000/2000 (50%)] | D loss (A): 0.148989 | D loss (B): 0.215803 | G loss: 2.871769 | Consistency: 0.153852 |\n",
      "Training epoch: 28 [1100/2000 (55%)] | D loss (A): 0.111067 | D loss (B): 0.224392 | G loss: 1.355351 | Consistency: 0.086134 |\n",
      "Training epoch: 28 [1200/2000 (60%)] | D loss (A): 0.165732 | D loss (B): 0.288694 | G loss: 2.197594 | Consistency: 0.141400 |\n",
      "Training epoch: 28 [1300/2000 (65%)] | D loss (A): 0.121164 | D loss (B): 0.233462 | G loss: 1.976534 | Consistency: 0.104781 |\n",
      "Training epoch: 28 [1400/2000 (70%)] | D loss (A): 0.128635 | D loss (B): 0.252493 | G loss: 2.037393 | Consistency: 0.113668 |\n",
      "Training epoch: 28 [1500/2000 (75%)] | D loss (A): 0.089764 | D loss (B): 0.193170 | G loss: 2.057087 | Consistency: 0.136645 |\n",
      "Training epoch: 28 [1600/2000 (80%)] | D loss (A): 0.124276 | D loss (B): 0.234274 | G loss: 2.282598 | Consistency: 0.151734 |\n",
      "Training epoch: 28 [1700/2000 (85%)] | D loss (A): 0.132458 | D loss (B): 0.219740 | G loss: 1.997332 | Consistency: 0.105103 |\n",
      "Training epoch: 28 [1800/2000 (90%)] | D loss (A): 0.046840 | D loss (B): 0.275343 | G loss: 1.620089 | Consistency: 0.092881 |\n",
      "Training epoch: 28 [1900/2000 (95%)] | D loss (A): 0.252034 | D loss (B): 0.248711 | G loss: 1.300260 | Consistency: 0.085795 |\n",
      "Training epoch: 29 [0/2000 (0%)] | D loss (A): 0.224388 | D loss (B): 0.270358 | G loss: 2.112397 | Consistency: 0.141634 |\n",
      "Training epoch: 29 [100/2000 (5%)] | D loss (A): 0.083954 | D loss (B): 0.266472 | G loss: 1.684580 | Consistency: 0.102682 |\n",
      "Training epoch: 29 [200/2000 (10%)] | D loss (A): 0.164489 | D loss (B): 0.242772 | G loss: 2.355473 | Consistency: 0.155513 |\n",
      "Training epoch: 29 [300/2000 (15%)] | D loss (A): 0.270698 | D loss (B): 0.253721 | G loss: 1.841217 | Consistency: 0.106323 |\n",
      "Training epoch: 29 [400/2000 (20%)] | D loss (A): 0.232730 | D loss (B): 0.249154 | G loss: 1.614761 | Consistency: 0.124821 |\n",
      "Training epoch: 29 [500/2000 (25%)] | D loss (A): 0.025782 | D loss (B): 0.170762 | G loss: 2.290459 | Consistency: 0.141930 |\n",
      "Training epoch: 29 [600/2000 (30%)] | D loss (A): 0.220368 | D loss (B): 0.190907 | G loss: 2.133969 | Consistency: 0.125819 |\n",
      "Training epoch: 29 [700/2000 (35%)] | D loss (A): 0.065164 | D loss (B): 0.295940 | G loss: 1.806084 | Consistency: 0.112205 |\n",
      "Training epoch: 29 [800/2000 (40%)] | D loss (A): 0.300684 | D loss (B): 0.229302 | G loss: 1.864261 | Consistency: 0.100473 |\n",
      "Training epoch: 29 [900/2000 (45%)] | D loss (A): 0.125363 | D loss (B): 0.224537 | G loss: 1.610240 | Consistency: 0.116124 |\n",
      "Training epoch: 29 [1000/2000 (50%)] | D loss (A): 0.140726 | D loss (B): 0.167587 | G loss: 2.244367 | Consistency: 0.147560 |\n",
      "Training epoch: 29 [1100/2000 (55%)] | D loss (A): 0.388665 | D loss (B): 0.181816 | G loss: 2.355895 | Consistency: 0.139320 |\n",
      "Training epoch: 29 [1200/2000 (60%)] | D loss (A): 0.276128 | D loss (B): 0.102101 | G loss: 1.865811 | Consistency: 0.128351 |\n",
      "Training epoch: 29 [1300/2000 (65%)] | D loss (A): 0.185267 | D loss (B): 0.167072 | G loss: 1.887982 | Consistency: 0.092008 |\n",
      "Training epoch: 29 [1400/2000 (70%)] | D loss (A): 0.161015 | D loss (B): 0.177540 | G loss: 1.758666 | Consistency: 0.119592 |\n",
      "Training epoch: 29 [1500/2000 (75%)] | D loss (A): 0.157930 | D loss (B): 0.074421 | G loss: 1.360717 | Consistency: 0.098231 |\n",
      "Training epoch: 29 [1600/2000 (80%)] | D loss (A): 0.194672 | D loss (B): 0.094327 | G loss: 1.762577 | Consistency: 0.111420 |\n",
      "Training epoch: 29 [1700/2000 (85%)] | D loss (A): 0.146088 | D loss (B): 0.280300 | G loss: 1.791272 | Consistency: 0.099111 |\n",
      "Training epoch: 29 [1800/2000 (90%)] | D loss (A): 0.139543 | D loss (B): 0.139082 | G loss: 2.535801 | Consistency: 0.162760 |\n",
      "Training epoch: 29 [1900/2000 (95%)] | D loss (A): 0.211195 | D loss (B): 0.165306 | G loss: 2.199596 | Consistency: 0.141218 |\n",
      "Training epoch: 30 [0/2000 (0%)] | D loss (A): 0.123544 | D loss (B): 0.135636 | G loss: 2.572291 | Consistency: 0.125124 |\n",
      "Training epoch: 30 [100/2000 (5%)] | D loss (A): 0.153115 | D loss (B): 0.262451 | G loss: 1.514986 | Consistency: 0.102264 |\n",
      "Training epoch: 30 [200/2000 (10%)] | D loss (A): 0.212792 | D loss (B): 0.035428 | G loss: 2.421520 | Consistency: 0.148533 |\n",
      "Training epoch: 30 [300/2000 (15%)] | D loss (A): 0.126121 | D loss (B): 0.178738 | G loss: 2.370110 | Consistency: 0.147612 |\n",
      "Training epoch: 30 [400/2000 (20%)] | D loss (A): 0.157003 | D loss (B): 0.094183 | G loss: 3.003715 | Consistency: 0.196349 |\n",
      "Training epoch: 30 [500/2000 (25%)] | D loss (A): 0.179456 | D loss (B): 0.134589 | G loss: 2.741935 | Consistency: 0.133596 |\n",
      "Training epoch: 30 [600/2000 (30%)] | D loss (A): 0.071551 | D loss (B): 0.099037 | G loss: 1.741650 | Consistency: 0.116743 |\n",
      "Training epoch: 30 [700/2000 (35%)] | D loss (A): 0.143042 | D loss (B): 0.123672 | G loss: 2.542554 | Consistency: 0.160629 |\n",
      "Training epoch: 30 [800/2000 (40%)] | D loss (A): 0.177985 | D loss (B): 0.223275 | G loss: 1.970199 | Consistency: 0.112260 |\n",
      "Training epoch: 30 [900/2000 (45%)] | D loss (A): 0.340332 | D loss (B): 0.114906 | G loss: 1.912508 | Consistency: 0.126534 |\n",
      "Training epoch: 30 [1000/2000 (50%)] | D loss (A): 0.246904 | D loss (B): 0.155059 | G loss: 2.593803 | Consistency: 0.126792 |\n",
      "Training epoch: 30 [1100/2000 (55%)] | D loss (A): 0.114648 | D loss (B): 0.207095 | G loss: 1.834198 | Consistency: 0.097887 |\n",
      "Training epoch: 30 [1200/2000 (60%)] | D loss (A): 0.144254 | D loss (B): 0.167430 | G loss: 1.695077 | Consistency: 0.107718 |\n",
      "Training epoch: 30 [1300/2000 (65%)] | D loss (A): 0.211432 | D loss (B): 0.145195 | G loss: 3.479978 | Consistency: 0.193410 |\n",
      "Training epoch: 30 [1400/2000 (70%)] | D loss (A): 0.067400 | D loss (B): 0.211293 | G loss: 2.338643 | Consistency: 0.143547 |\n",
      "Training epoch: 30 [1500/2000 (75%)] | D loss (A): 0.128112 | D loss (B): 0.113942 | G loss: 1.864074 | Consistency: 0.090074 |\n",
      "Training epoch: 30 [1600/2000 (80%)] | D loss (A): 0.087416 | D loss (B): 0.095789 | G loss: 2.272519 | Consistency: 0.128876 |\n",
      "Training epoch: 30 [1700/2000 (85%)] | D loss (A): 0.093578 | D loss (B): 0.067725 | G loss: 2.594346 | Consistency: 0.149247 |\n",
      "Training epoch: 30 [1800/2000 (90%)] | D loss (A): 0.196615 | D loss (B): 0.142620 | G loss: 2.572751 | Consistency: 0.122900 |\n",
      "Training epoch: 30 [1900/2000 (95%)] | D loss (A): 0.214230 | D loss (B): 0.086765 | G loss: 2.779570 | Consistency: 0.141363 |\n",
      "Training epoch: 31 [0/2000 (0%)] | D loss (A): 0.095729 | D loss (B): 0.050970 | G loss: 1.339477 | Consistency: 0.086256 |\n",
      "Training epoch: 31 [100/2000 (5%)] | D loss (A): 0.258224 | D loss (B): 0.061046 | G loss: 2.158403 | Consistency: 0.112868 |\n",
      "Training epoch: 31 [200/2000 (10%)] | D loss (A): 0.207005 | D loss (B): 0.098771 | G loss: 2.790272 | Consistency: 0.150934 |\n",
      "Training epoch: 31 [300/2000 (15%)] | D loss (A): 0.161549 | D loss (B): 0.154443 | G loss: 2.254327 | Consistency: 0.121760 |\n",
      "Training epoch: 31 [400/2000 (20%)] | D loss (A): 0.284082 | D loss (B): 0.102902 | G loss: 1.725025 | Consistency: 0.104288 |\n",
      "Training epoch: 31 [500/2000 (25%)] | D loss (A): 0.254399 | D loss (B): 0.149951 | G loss: 1.466677 | Consistency: 0.101308 |\n",
      "Training epoch: 31 [600/2000 (30%)] | D loss (A): 0.270531 | D loss (B): 0.096360 | G loss: 1.385014 | Consistency: 0.092781 |\n",
      "Training epoch: 31 [700/2000 (35%)] | D loss (A): 0.242844 | D loss (B): 0.261940 | G loss: 1.880633 | Consistency: 0.108522 |\n",
      "Training epoch: 31 [800/2000 (40%)] | D loss (A): 0.218193 | D loss (B): 0.062361 | G loss: 2.486786 | Consistency: 0.121604 |\n",
      "Training epoch: 31 [900/2000 (45%)] | D loss (A): 0.277414 | D loss (B): 0.076730 | G loss: 2.167011 | Consistency: 0.136913 |\n",
      "Training epoch: 31 [1000/2000 (50%)] | D loss (A): 0.163482 | D loss (B): 0.259847 | G loss: 2.173032 | Consistency: 0.117717 |\n",
      "Training epoch: 31 [1100/2000 (55%)] | D loss (A): 0.210047 | D loss (B): 0.321785 | G loss: 1.977607 | Consistency: 0.127055 |\n",
      "Training epoch: 31 [1200/2000 (60%)] | D loss (A): 0.224338 | D loss (B): 0.119900 | G loss: 2.853372 | Consistency: 0.174515 |\n",
      "Training epoch: 31 [1300/2000 (65%)] | D loss (A): 0.191705 | D loss (B): 0.305149 | G loss: 1.543896 | Consistency: 0.096177 |\n",
      "Training epoch: 31 [1400/2000 (70%)] | D loss (A): 0.280308 | D loss (B): 0.238677 | G loss: 1.793524 | Consistency: 0.111913 |\n",
      "Training epoch: 31 [1500/2000 (75%)] | D loss (A): 0.266166 | D loss (B): 0.305942 | G loss: 2.290503 | Consistency: 0.120886 |\n",
      "Training epoch: 31 [1600/2000 (80%)] | D loss (A): 0.167349 | D loss (B): 0.103503 | G loss: 1.677025 | Consistency: 0.109973 |\n",
      "Training epoch: 31 [1700/2000 (85%)] | D loss (A): 0.253183 | D loss (B): 0.093900 | G loss: 2.221555 | Consistency: 0.137468 |\n",
      "Training epoch: 31 [1800/2000 (90%)] | D loss (A): 0.240827 | D loss (B): 0.145177 | G loss: 1.794784 | Consistency: 0.109386 |\n",
      "Training epoch: 31 [1900/2000 (95%)] | D loss (A): 0.248049 | D loss (B): 0.276621 | G loss: 1.748927 | Consistency: 0.123725 |\n",
      "Training epoch: 32 [0/2000 (0%)] | D loss (A): 0.203976 | D loss (B): 0.084258 | G loss: 2.517621 | Consistency: 0.122105 |\n",
      "Training epoch: 32 [100/2000 (5%)] | D loss (A): 0.162180 | D loss (B): 0.114437 | G loss: 2.555531 | Consistency: 0.143903 |\n",
      "Training epoch: 32 [200/2000 (10%)] | D loss (A): 0.148099 | D loss (B): 0.145263 | G loss: 1.897693 | Consistency: 0.114007 |\n",
      "Training epoch: 32 [300/2000 (15%)] | D loss (A): 0.263212 | D loss (B): 0.086861 | G loss: 1.343485 | Consistency: 0.092500 |\n",
      "Training epoch: 32 [400/2000 (20%)] | D loss (A): 0.258487 | D loss (B): 0.119901 | G loss: 1.577046 | Consistency: 0.103134 |\n",
      "Training epoch: 32 [500/2000 (25%)] | D loss (A): 0.168731 | D loss (B): 0.250456 | G loss: 2.402576 | Consistency: 0.127160 |\n",
      "Training epoch: 32 [600/2000 (30%)] | D loss (A): 0.144548 | D loss (B): 0.162695 | G loss: 1.375341 | Consistency: 0.078135 |\n",
      "Training epoch: 32 [700/2000 (35%)] | D loss (A): 0.178039 | D loss (B): 0.193409 | G loss: 1.730789 | Consistency: 0.103396 |\n",
      "Training epoch: 32 [800/2000 (40%)] | D loss (A): 0.214839 | D loss (B): 0.058795 | G loss: 1.998446 | Consistency: 0.129306 |\n",
      "Training epoch: 32 [900/2000 (45%)] | D loss (A): 0.115026 | D loss (B): 0.150711 | G loss: 2.098049 | Consistency: 0.126317 |\n",
      "Training epoch: 32 [1000/2000 (50%)] | D loss (A): 0.269176 | D loss (B): 0.109574 | G loss: 2.348653 | Consistency: 0.111893 |\n",
      "Training epoch: 32 [1100/2000 (55%)] | D loss (A): 0.150698 | D loss (B): 0.114538 | G loss: 1.817645 | Consistency: 0.085745 |\n",
      "Training epoch: 32 [1200/2000 (60%)] | D loss (A): 0.272073 | D loss (B): 0.351516 | G loss: 3.068361 | Consistency: 0.151995 |\n",
      "Training epoch: 32 [1300/2000 (65%)] | D loss (A): 0.139596 | D loss (B): 0.057110 | G loss: 1.750774 | Consistency: 0.126458 |\n",
      "Training epoch: 32 [1400/2000 (70%)] | D loss (A): 0.280327 | D loss (B): 0.194855 | G loss: 1.887547 | Consistency: 0.107844 |\n",
      "Training epoch: 32 [1500/2000 (75%)] | D loss (A): 0.365548 | D loss (B): 0.124774 | G loss: 2.395513 | Consistency: 0.120526 |\n",
      "Training epoch: 32 [1600/2000 (80%)] | D loss (A): 0.101957 | D loss (B): 0.084383 | G loss: 2.268650 | Consistency: 0.147906 |\n",
      "Training epoch: 32 [1700/2000 (85%)] | D loss (A): 0.081681 | D loss (B): 0.119383 | G loss: 1.786528 | Consistency: 0.108642 |\n",
      "Training epoch: 32 [1800/2000 (90%)] | D loss (A): 0.188391 | D loss (B): 0.135271 | G loss: 1.864151 | Consistency: 0.132676 |\n",
      "Training epoch: 32 [1900/2000 (95%)] | D loss (A): 0.149448 | D loss (B): 0.167464 | G loss: 2.169200 | Consistency: 0.120737 |\n",
      "Training epoch: 33 [0/2000 (0%)] | D loss (A): 0.213178 | D loss (B): 0.279595 | G loss: 2.469528 | Consistency: 0.145755 |\n",
      "Training epoch: 33 [100/2000 (5%)] | D loss (A): 0.233125 | D loss (B): 0.109742 | G loss: 2.565591 | Consistency: 0.147136 |\n",
      "Training epoch: 33 [200/2000 (10%)] | D loss (A): 0.183723 | D loss (B): 0.043906 | G loss: 2.149420 | Consistency: 0.153229 |\n",
      "Training epoch: 33 [300/2000 (15%)] | D loss (A): 0.066733 | D loss (B): 0.294882 | G loss: 1.744128 | Consistency: 0.092338 |\n",
      "Training epoch: 33 [400/2000 (20%)] | D loss (A): 0.153383 | D loss (B): 0.238693 | G loss: 2.431103 | Consistency: 0.125386 |\n",
      "Training epoch: 33 [500/2000 (25%)] | D loss (A): 0.166872 | D loss (B): 0.114601 | G loss: 1.545865 | Consistency: 0.106904 |\n",
      "Training epoch: 33 [600/2000 (30%)] | D loss (A): 0.222178 | D loss (B): 0.043221 | G loss: 1.691000 | Consistency: 0.119224 |\n",
      "Training epoch: 33 [700/2000 (35%)] | D loss (A): 0.231885 | D loss (B): 0.185753 | G loss: 1.928382 | Consistency: 0.096972 |\n",
      "Training epoch: 33 [800/2000 (40%)] | D loss (A): 0.236088 | D loss (B): 0.191506 | G loss: 1.610347 | Consistency: 0.091083 |\n",
      "Training epoch: 33 [900/2000 (45%)] | D loss (A): 0.246829 | D loss (B): 0.406988 | G loss: 2.427613 | Consistency: 0.130175 |\n",
      "Training epoch: 33 [1000/2000 (50%)] | D loss (A): 0.289269 | D loss (B): 0.241690 | G loss: 2.253021 | Consistency: 0.137902 |\n",
      "Training epoch: 33 [1100/2000 (55%)] | D loss (A): 0.256215 | D loss (B): 0.261464 | G loss: 1.879620 | Consistency: 0.103204 |\n",
      "Training epoch: 33 [1200/2000 (60%)] | D loss (A): 0.275771 | D loss (B): 0.135847 | G loss: 1.458958 | Consistency: 0.109421 |\n",
      "Training epoch: 33 [1300/2000 (65%)] | D loss (A): 0.280281 | D loss (B): 0.130831 | G loss: 1.569662 | Consistency: 0.096984 |\n",
      "Training epoch: 33 [1400/2000 (70%)] | D loss (A): 0.309902 | D loss (B): 0.145566 | G loss: 2.100423 | Consistency: 0.110671 |\n",
      "Training epoch: 33 [1500/2000 (75%)] | D loss (A): 0.269993 | D loss (B): 0.354342 | G loss: 1.621564 | Consistency: 0.105970 |\n",
      "Training epoch: 33 [1600/2000 (80%)] | D loss (A): 0.206425 | D loss (B): 0.169360 | G loss: 2.001204 | Consistency: 0.135010 |\n",
      "Training epoch: 33 [1700/2000 (85%)] | D loss (A): 0.274467 | D loss (B): 0.209879 | G loss: 1.589154 | Consistency: 0.094397 |\n",
      "Training epoch: 33 [1800/2000 (90%)] | D loss (A): 0.257866 | D loss (B): 0.054062 | G loss: 1.912031 | Consistency: 0.130575 |\n",
      "Training epoch: 33 [1900/2000 (95%)] | D loss (A): 0.240338 | D loss (B): 0.176132 | G loss: 1.837874 | Consistency: 0.093498 |\n",
      "Training epoch: 34 [0/2000 (0%)] | D loss (A): 0.235775 | D loss (B): 0.125887 | G loss: 1.977995 | Consistency: 0.131352 |\n",
      "Training epoch: 34 [100/2000 (5%)] | D loss (A): 0.298244 | D loss (B): 0.058525 | G loss: 1.348511 | Consistency: 0.076507 |\n",
      "Training epoch: 34 [200/2000 (10%)] | D loss (A): 0.216590 | D loss (B): 0.223283 | G loss: 1.593695 | Consistency: 0.084678 |\n",
      "Training epoch: 34 [300/2000 (15%)] | D loss (A): 0.253627 | D loss (B): 0.090157 | G loss: 1.299391 | Consistency: 0.087471 |\n",
      "Training epoch: 34 [400/2000 (20%)] | D loss (A): 0.279531 | D loss (B): 0.199670 | G loss: 1.869149 | Consistency: 0.133658 |\n",
      "Training epoch: 34 [500/2000 (25%)] | D loss (A): 0.158600 | D loss (B): 0.321061 | G loss: 2.730931 | Consistency: 0.122500 |\n",
      "Training epoch: 34 [600/2000 (30%)] | D loss (A): 0.204807 | D loss (B): 0.218478 | G loss: 2.305558 | Consistency: 0.138205 |\n",
      "Training epoch: 34 [700/2000 (35%)] | D loss (A): 0.150863 | D loss (B): 0.261519 | G loss: 1.686699 | Consistency: 0.119222 |\n",
      "Training epoch: 34 [800/2000 (40%)] | D loss (A): 0.237523 | D loss (B): 0.219773 | G loss: 2.286918 | Consistency: 0.113617 |\n",
      "Training epoch: 34 [900/2000 (45%)] | D loss (A): 0.250610 | D loss (B): 0.161674 | G loss: 1.915389 | Consistency: 0.112624 |\n",
      "Training epoch: 34 [1000/2000 (50%)] | D loss (A): 0.161048 | D loss (B): 0.299940 | G loss: 1.744917 | Consistency: 0.112398 |\n",
      "Training epoch: 34 [1100/2000 (55%)] | D loss (A): 0.123115 | D loss (B): 0.143489 | G loss: 2.144485 | Consistency: 0.111443 |\n",
      "Training epoch: 34 [1200/2000 (60%)] | D loss (A): 0.148143 | D loss (B): 0.279122 | G loss: 2.312899 | Consistency: 0.122345 |\n",
      "Training epoch: 34 [1300/2000 (65%)] | D loss (A): 0.232492 | D loss (B): 0.087945 | G loss: 1.639159 | Consistency: 0.115723 |\n",
      "Training epoch: 34 [1400/2000 (70%)] | D loss (A): 0.214354 | D loss (B): 0.059688 | G loss: 2.465393 | Consistency: 0.119249 |\n",
      "Training epoch: 34 [1500/2000 (75%)] | D loss (A): 0.247204 | D loss (B): 0.134443 | G loss: 2.049187 | Consistency: 0.104700 |\n",
      "Training epoch: 34 [1600/2000 (80%)] | D loss (A): 0.297335 | D loss (B): 0.136773 | G loss: 2.141842 | Consistency: 0.102865 |\n",
      "Training epoch: 34 [1700/2000 (85%)] | D loss (A): 0.181288 | D loss (B): 0.079442 | G loss: 2.179946 | Consistency: 0.147263 |\n",
      "Training epoch: 34 [1800/2000 (90%)] | D loss (A): 0.333673 | D loss (B): 0.075672 | G loss: 4.088559 | Consistency: 0.263876 |\n",
      "Training epoch: 34 [1900/2000 (95%)] | D loss (A): 0.330628 | D loss (B): 0.292665 | G loss: 2.620614 | Consistency: 0.117595 |\n",
      "Training epoch: 35 [0/2000 (0%)] | D loss (A): 0.159125 | D loss (B): 0.126825 | G loss: 2.037676 | Consistency: 0.139801 |\n",
      "Training epoch: 35 [100/2000 (5%)] | D loss (A): 0.247681 | D loss (B): 0.030729 | G loss: 2.470981 | Consistency: 0.136538 |\n",
      "Training epoch: 35 [200/2000 (10%)] | D loss (A): 0.216611 | D loss (B): 0.058762 | G loss: 2.062164 | Consistency: 0.116261 |\n",
      "Training epoch: 35 [300/2000 (15%)] | D loss (A): 0.255686 | D loss (B): 0.187072 | G loss: 1.813246 | Consistency: 0.103344 |\n",
      "Training epoch: 35 [400/2000 (20%)] | D loss (A): 0.202094 | D loss (B): 0.079242 | G loss: 2.275211 | Consistency: 0.128027 |\n",
      "Training epoch: 35 [500/2000 (25%)] | D loss (A): 0.091870 | D loss (B): 0.086919 | G loss: 2.323962 | Consistency: 0.135261 |\n",
      "Training epoch: 35 [600/2000 (30%)] | D loss (A): 0.229215 | D loss (B): 0.220383 | G loss: 1.914713 | Consistency: 0.093473 |\n",
      "Training epoch: 35 [700/2000 (35%)] | D loss (A): 0.378010 | D loss (B): 0.154279 | G loss: 2.472475 | Consistency: 0.121467 |\n",
      "Training epoch: 35 [800/2000 (40%)] | D loss (A): 0.171138 | D loss (B): 0.119782 | G loss: 2.286626 | Consistency: 0.125742 |\n",
      "Training epoch: 35 [900/2000 (45%)] | D loss (A): 0.107461 | D loss (B): 0.049458 | G loss: 2.508201 | Consistency: 0.173742 |\n",
      "Training epoch: 35 [1000/2000 (50%)] | D loss (A): 0.240738 | D loss (B): 0.180304 | G loss: 1.739707 | Consistency: 0.098131 |\n",
      "Training epoch: 35 [1100/2000 (55%)] | D loss (A): 0.109444 | D loss (B): 0.144243 | G loss: 1.914651 | Consistency: 0.150210 |\n",
      "Training epoch: 35 [1200/2000 (60%)] | D loss (A): 0.214897 | D loss (B): 0.101676 | G loss: 2.178828 | Consistency: 0.074668 |\n",
      "Training epoch: 35 [1300/2000 (65%)] | D loss (A): 0.103191 | D loss (B): 0.083864 | G loss: 2.729851 | Consistency: 0.137851 |\n",
      "Training epoch: 35 [1400/2000 (70%)] | D loss (A): 0.194871 | D loss (B): 0.156805 | G loss: 1.763944 | Consistency: 0.100129 |\n",
      "Training epoch: 35 [1500/2000 (75%)] | D loss (A): 0.105261 | D loss (B): 0.172902 | G loss: 1.814668 | Consistency: 0.112430 |\n",
      "Training epoch: 35 [1600/2000 (80%)] | D loss (A): 0.124632 | D loss (B): 0.083500 | G loss: 2.475744 | Consistency: 0.119332 |\n",
      "Training epoch: 35 [1700/2000 (85%)] | D loss (A): 0.125305 | D loss (B): 0.126789 | G loss: 1.769964 | Consistency: 0.131230 |\n",
      "Training epoch: 35 [1800/2000 (90%)] | D loss (A): 0.237353 | D loss (B): 0.236518 | G loss: 2.874792 | Consistency: 0.172952 |\n",
      "Training epoch: 35 [1900/2000 (95%)] | D loss (A): 0.223931 | D loss (B): 0.165213 | G loss: 1.596033 | Consistency: 0.083347 |\n",
      "Training epoch: 36 [0/2000 (0%)] | D loss (A): 0.205919 | D loss (B): 0.120144 | G loss: 2.764782 | Consistency: 0.143607 |\n",
      "Training epoch: 36 [100/2000 (5%)] | D loss (A): 0.121592 | D loss (B): 0.238823 | G loss: 1.782852 | Consistency: 0.108822 |\n",
      "Training epoch: 36 [200/2000 (10%)] | D loss (A): 0.109689 | D loss (B): 0.277447 | G loss: 2.475070 | Consistency: 0.103351 |\n",
      "Training epoch: 36 [300/2000 (15%)] | D loss (A): 0.275846 | D loss (B): 0.160453 | G loss: 2.057802 | Consistency: 0.107670 |\n",
      "Training epoch: 36 [400/2000 (20%)] | D loss (A): 0.107559 | D loss (B): 0.095769 | G loss: 1.966365 | Consistency: 0.122672 |\n",
      "Training epoch: 36 [500/2000 (25%)] | D loss (A): 0.205503 | D loss (B): 0.091440 | G loss: 2.466938 | Consistency: 0.108081 |\n",
      "Training epoch: 36 [600/2000 (30%)] | D loss (A): 0.216978 | D loss (B): 0.152802 | G loss: 2.320541 | Consistency: 0.135521 |\n",
      "Training epoch: 36 [700/2000 (35%)] | D loss (A): 0.272940 | D loss (B): 0.054019 | G loss: 2.178460 | Consistency: 0.106044 |\n",
      "Training epoch: 36 [800/2000 (40%)] | D loss (A): 0.294156 | D loss (B): 0.303393 | G loss: 1.782115 | Consistency: 0.094972 |\n",
      "Training epoch: 36 [900/2000 (45%)] | D loss (A): 0.281751 | D loss (B): 0.083519 | G loss: 1.483152 | Consistency: 0.089278 |\n",
      "Training epoch: 36 [1000/2000 (50%)] | D loss (A): 0.182777 | D loss (B): 0.155734 | G loss: 1.557820 | Consistency: 0.087837 |\n",
      "Training epoch: 36 [1100/2000 (55%)] | D loss (A): 0.193421 | D loss (B): 0.123630 | G loss: 2.005821 | Consistency: 0.101134 |\n",
      "Training epoch: 36 [1200/2000 (60%)] | D loss (A): 0.285152 | D loss (B): 0.070638 | G loss: 1.584019 | Consistency: 0.093689 |\n",
      "Training epoch: 36 [1300/2000 (65%)] | D loss (A): 0.256422 | D loss (B): 0.087301 | G loss: 3.045094 | Consistency: 0.187517 |\n",
      "Training epoch: 36 [1400/2000 (70%)] | D loss (A): 0.223737 | D loss (B): 0.210220 | G loss: 1.970347 | Consistency: 0.110781 |\n",
      "Training epoch: 36 [1500/2000 (75%)] | D loss (A): 0.272579 | D loss (B): 0.173256 | G loss: 2.063053 | Consistency: 0.123161 |\n",
      "Training epoch: 36 [1600/2000 (80%)] | D loss (A): 0.230511 | D loss (B): 0.101992 | G loss: 2.217736 | Consistency: 0.115281 |\n",
      "Training epoch: 36 [1700/2000 (85%)] | D loss (A): 0.197535 | D loss (B): 0.149259 | G loss: 1.168517 | Consistency: 0.075011 |\n",
      "Training epoch: 36 [1800/2000 (90%)] | D loss (A): 0.230698 | D loss (B): 0.036691 | G loss: 1.977327 | Consistency: 0.123735 |\n",
      "Training epoch: 36 [1900/2000 (95%)] | D loss (A): 0.231947 | D loss (B): 0.131066 | G loss: 2.006878 | Consistency: 0.108890 |\n",
      "Training epoch: 37 [0/2000 (0%)] | D loss (A): 0.279661 | D loss (B): 0.107191 | G loss: 1.501056 | Consistency: 0.106288 |\n",
      "Training epoch: 37 [100/2000 (5%)] | D loss (A): 0.263569 | D loss (B): 0.115301 | G loss: 2.178611 | Consistency: 0.110460 |\n",
      "Training epoch: 37 [200/2000 (10%)] | D loss (A): 0.232657 | D loss (B): 0.140387 | G loss: 2.101937 | Consistency: 0.107383 |\n",
      "Training epoch: 37 [300/2000 (15%)] | D loss (A): 0.175925 | D loss (B): 0.143875 | G loss: 1.629050 | Consistency: 0.098289 |\n",
      "Training epoch: 37 [400/2000 (20%)] | D loss (A): 0.261606 | D loss (B): 0.271054 | G loss: 1.429515 | Consistency: 0.088752 |\n",
      "Training epoch: 37 [500/2000 (25%)] | D loss (A): 0.222623 | D loss (B): 0.114057 | G loss: 2.007298 | Consistency: 0.128317 |\n",
      "Training epoch: 37 [600/2000 (30%)] | D loss (A): 0.226317 | D loss (B): 0.183242 | G loss: 1.595433 | Consistency: 0.075879 |\n",
      "Training epoch: 37 [700/2000 (35%)] | D loss (A): 0.139241 | D loss (B): 0.047805 | G loss: 1.695382 | Consistency: 0.114903 |\n",
      "Training epoch: 37 [800/2000 (40%)] | D loss (A): 0.202888 | D loss (B): 0.264685 | G loss: 1.994104 | Consistency: 0.111733 |\n",
      "Training epoch: 37 [900/2000 (45%)] | D loss (A): 0.154466 | D loss (B): 0.200686 | G loss: 1.769878 | Consistency: 0.101437 |\n",
      "Training epoch: 37 [1000/2000 (50%)] | D loss (A): 0.184977 | D loss (B): 0.132965 | G loss: 2.169810 | Consistency: 0.114033 |\n",
      "Training epoch: 37 [1100/2000 (55%)] | D loss (A): 0.225840 | D loss (B): 0.093184 | G loss: 1.469751 | Consistency: 0.101697 |\n",
      "Training epoch: 37 [1200/2000 (60%)] | D loss (A): 0.224787 | D loss (B): 0.186390 | G loss: 1.398205 | Consistency: 0.084071 |\n",
      "Training epoch: 37 [1300/2000 (65%)] | D loss (A): 0.194046 | D loss (B): 0.198726 | G loss: 2.105062 | Consistency: 0.131466 |\n",
      "Training epoch: 37 [1400/2000 (70%)] | D loss (A): 0.065158 | D loss (B): 0.182105 | G loss: 2.209076 | Consistency: 0.131492 |\n",
      "Training epoch: 37 [1500/2000 (75%)] | D loss (A): 0.309504 | D loss (B): 0.337051 | G loss: 1.768409 | Consistency: 0.088443 |\n",
      "Training epoch: 37 [1600/2000 (80%)] | D loss (A): 0.295937 | D loss (B): 0.167371 | G loss: 1.821891 | Consistency: 0.137595 |\n",
      "Training epoch: 37 [1700/2000 (85%)] | D loss (A): 0.176322 | D loss (B): 0.175199 | G loss: 2.493805 | Consistency: 0.156423 |\n",
      "Training epoch: 37 [1800/2000 (90%)] | D loss (A): 0.105151 | D loss (B): 0.124932 | G loss: 2.033124 | Consistency: 0.112687 |\n",
      "Training epoch: 37 [1900/2000 (95%)] | D loss (A): 0.129595 | D loss (B): 0.112946 | G loss: 2.240467 | Consistency: 0.132072 |\n",
      "Training epoch: 38 [0/2000 (0%)] | D loss (A): 0.229900 | D loss (B): 0.138952 | G loss: 2.475540 | Consistency: 0.122650 |\n",
      "Training epoch: 38 [100/2000 (5%)] | D loss (A): 0.175258 | D loss (B): 0.151129 | G loss: 2.508339 | Consistency: 0.122521 |\n",
      "Training epoch: 38 [200/2000 (10%)] | D loss (A): 0.269162 | D loss (B): 0.198651 | G loss: 2.117077 | Consistency: 0.117909 |\n",
      "Training epoch: 38 [300/2000 (15%)] | D loss (A): 0.161630 | D loss (B): 0.121869 | G loss: 2.476197 | Consistency: 0.139351 |\n",
      "Training epoch: 38 [400/2000 (20%)] | D loss (A): 0.267423 | D loss (B): 0.129832 | G loss: 1.855426 | Consistency: 0.124790 |\n",
      "Training epoch: 38 [500/2000 (25%)] | D loss (A): 0.304746 | D loss (B): 0.186507 | G loss: 1.733292 | Consistency: 0.088570 |\n",
      "Training epoch: 38 [600/2000 (30%)] | D loss (A): 0.149487 | D loss (B): 0.186614 | G loss: 2.516256 | Consistency: 0.109305 |\n",
      "Training epoch: 38 [700/2000 (35%)] | D loss (A): 0.268362 | D loss (B): 0.091612 | G loss: 1.609041 | Consistency: 0.105880 |\n",
      "Training epoch: 38 [800/2000 (40%)] | D loss (A): 0.086385 | D loss (B): 0.164614 | G loss: 2.282564 | Consistency: 0.141524 |\n",
      "Training epoch: 38 [900/2000 (45%)] | D loss (A): 0.344218 | D loss (B): 0.092176 | G loss: 2.173059 | Consistency: 0.116394 |\n",
      "Training epoch: 38 [1000/2000 (50%)] | D loss (A): 0.129003 | D loss (B): 0.291736 | G loss: 1.869377 | Consistency: 0.103608 |\n",
      "Training epoch: 38 [1100/2000 (55%)] | D loss (A): 0.210827 | D loss (B): 0.146577 | G loss: 1.735094 | Consistency: 0.094722 |\n",
      "Training epoch: 38 [1200/2000 (60%)] | D loss (A): 0.126546 | D loss (B): 0.176759 | G loss: 1.693029 | Consistency: 0.116910 |\n",
      "Training epoch: 38 [1300/2000 (65%)] | D loss (A): 0.228701 | D loss (B): 0.282934 | G loss: 2.403663 | Consistency: 0.109394 |\n",
      "Training epoch: 38 [1400/2000 (70%)] | D loss (A): 0.273572 | D loss (B): 0.136906 | G loss: 1.877398 | Consistency: 0.095203 |\n",
      "Training epoch: 38 [1500/2000 (75%)] | D loss (A): 0.227929 | D loss (B): 0.176187 | G loss: 2.567118 | Consistency: 0.132224 |\n",
      "Training epoch: 38 [1600/2000 (80%)] | D loss (A): 0.219097 | D loss (B): 0.147383 | G loss: 2.225291 | Consistency: 0.101848 |\n",
      "Training epoch: 38 [1700/2000 (85%)] | D loss (A): 0.079393 | D loss (B): 0.196066 | G loss: 1.571228 | Consistency: 0.089716 |\n",
      "Training epoch: 38 [1800/2000 (90%)] | D loss (A): 0.191834 | D loss (B): 0.150934 | G loss: 2.129558 | Consistency: 0.101846 |\n",
      "Training epoch: 38 [1900/2000 (95%)] | D loss (A): 0.205916 | D loss (B): 0.108442 | G loss: 2.152527 | Consistency: 0.106457 |\n",
      "Training epoch: 39 [0/2000 (0%)] | D loss (A): 0.235449 | D loss (B): 0.151372 | G loss: 1.834515 | Consistency: 0.090943 |\n",
      "Training epoch: 39 [100/2000 (5%)] | D loss (A): 0.348323 | D loss (B): 0.260020 | G loss: 2.260171 | Consistency: 0.132435 |\n",
      "Training epoch: 39 [200/2000 (10%)] | D loss (A): 0.141523 | D loss (B): 0.060187 | G loss: 4.263388 | Consistency: 0.279616 |\n",
      "Training epoch: 39 [300/2000 (15%)] | D loss (A): 0.143615 | D loss (B): 0.106164 | G loss: 2.704177 | Consistency: 0.199548 |\n",
      "Training epoch: 39 [400/2000 (20%)] | D loss (A): 0.069644 | D loss (B): 0.128894 | G loss: 2.259501 | Consistency: 0.163716 |\n",
      "Training epoch: 39 [500/2000 (25%)] | D loss (A): 0.197652 | D loss (B): 0.083520 | G loss: 2.468554 | Consistency: 0.128033 |\n",
      "Training epoch: 39 [600/2000 (30%)] | D loss (A): 0.330357 | D loss (B): 0.238380 | G loss: 2.520996 | Consistency: 0.152333 |\n",
      "Training epoch: 39 [700/2000 (35%)] | D loss (A): 0.235938 | D loss (B): 0.027876 | G loss: 1.880477 | Consistency: 0.130450 |\n",
      "Training epoch: 39 [800/2000 (40%)] | D loss (A): 0.123856 | D loss (B): 0.149045 | G loss: 2.045547 | Consistency: 0.115150 |\n",
      "Training epoch: 39 [900/2000 (45%)] | D loss (A): 0.181799 | D loss (B): 0.140174 | G loss: 1.807542 | Consistency: 0.114910 |\n",
      "Training epoch: 39 [1000/2000 (50%)] | D loss (A): 0.261884 | D loss (B): 0.041563 | G loss: 2.697821 | Consistency: 0.136789 |\n",
      "Training epoch: 39 [1100/2000 (55%)] | D loss (A): 0.132873 | D loss (B): 0.086604 | G loss: 2.201096 | Consistency: 0.093343 |\n",
      "Training epoch: 39 [1200/2000 (60%)] | D loss (A): 0.215209 | D loss (B): 0.134911 | G loss: 1.836036 | Consistency: 0.101995 |\n",
      "Training epoch: 39 [1300/2000 (65%)] | D loss (A): 0.204053 | D loss (B): 0.060535 | G loss: 2.062546 | Consistency: 0.115875 |\n",
      "Training epoch: 39 [1400/2000 (70%)] | D loss (A): 0.177905 | D loss (B): 0.150426 | G loss: 2.193026 | Consistency: 0.111715 |\n",
      "Training epoch: 39 [1500/2000 (75%)] | D loss (A): 0.206966 | D loss (B): 0.209435 | G loss: 2.237271 | Consistency: 0.134830 |\n",
      "Training epoch: 39 [1600/2000 (80%)] | D loss (A): 0.096263 | D loss (B): 0.030337 | G loss: 2.712609 | Consistency: 0.144079 |\n",
      "Training epoch: 39 [1700/2000 (85%)] | D loss (A): 0.188057 | D loss (B): 0.235767 | G loss: 2.849409 | Consistency: 0.188136 |\n",
      "Training epoch: 39 [1800/2000 (90%)] | D loss (A): 0.199688 | D loss (B): 0.167122 | G loss: 2.547016 | Consistency: 0.116180 |\n",
      "Training epoch: 39 [1900/2000 (95%)] | D loss (A): 0.096448 | D loss (B): 0.079920 | G loss: 3.290066 | Consistency: 0.180963 |\n",
      "Training epoch: 40 [0/2000 (0%)] | D loss (A): 0.101508 | D loss (B): 0.127172 | G loss: 1.627455 | Consistency: 0.099867 |\n",
      "Training epoch: 40 [100/2000 (5%)] | D loss (A): 0.077759 | D loss (B): 0.266810 | G loss: 4.810604 | Consistency: 0.327963 |\n",
      "Training epoch: 40 [200/2000 (10%)] | D loss (A): 0.055721 | D loss (B): 0.103655 | G loss: 2.398256 | Consistency: 0.137178 |\n",
      "Training epoch: 40 [300/2000 (15%)] | D loss (A): 0.034207 | D loss (B): 0.034274 | G loss: 2.998775 | Consistency: 0.122402 |\n",
      "Training epoch: 40 [400/2000 (20%)] | D loss (A): 0.042596 | D loss (B): 0.109020 | G loss: 2.797635 | Consistency: 0.128495 |\n",
      "Training epoch: 40 [500/2000 (25%)] | D loss (A): 0.167401 | D loss (B): 0.071008 | G loss: 2.025869 | Consistency: 0.147450 |\n",
      "Training epoch: 40 [600/2000 (30%)] | D loss (A): 0.065775 | D loss (B): 0.160005 | G loss: 2.327167 | Consistency: 0.129322 |\n",
      "Training epoch: 40 [700/2000 (35%)] | D loss (A): 0.095613 | D loss (B): 0.077505 | G loss: 2.533699 | Consistency: 0.176349 |\n",
      "Training epoch: 40 [800/2000 (40%)] | D loss (A): 0.052387 | D loss (B): 0.052357 | G loss: 2.285874 | Consistency: 0.155681 |\n",
      "Training epoch: 40 [900/2000 (45%)] | D loss (A): 0.168183 | D loss (B): 0.182153 | G loss: 2.396482 | Consistency: 0.134608 |\n",
      "Training epoch: 40 [1000/2000 (50%)] | D loss (A): 0.142346 | D loss (B): 0.115765 | G loss: 1.860711 | Consistency: 0.109356 |\n",
      "Training epoch: 40 [1100/2000 (55%)] | D loss (A): 0.056559 | D loss (B): 0.165846 | G loss: 2.960563 | Consistency: 0.145313 |\n",
      "Training epoch: 40 [1200/2000 (60%)] | D loss (A): 0.247562 | D loss (B): 0.124259 | G loss: 2.344909 | Consistency: 0.113103 |\n",
      "Training epoch: 40 [1300/2000 (65%)] | D loss (A): 0.088581 | D loss (B): 0.127307 | G loss: 2.653758 | Consistency: 0.125011 |\n",
      "Training epoch: 40 [1400/2000 (70%)] | D loss (A): 0.209833 | D loss (B): 0.062124 | G loss: 1.667468 | Consistency: 0.087625 |\n",
      "Training epoch: 40 [1500/2000 (75%)] | D loss (A): 0.171311 | D loss (B): 0.267953 | G loss: 2.029299 | Consistency: 0.104588 |\n",
      "Training epoch: 40 [1600/2000 (80%)] | D loss (A): 0.068226 | D loss (B): 0.119787 | G loss: 1.577632 | Consistency: 0.104171 |\n",
      "Training epoch: 40 [1700/2000 (85%)] | D loss (A): 0.229692 | D loss (B): 0.189785 | G loss: 2.195547 | Consistency: 0.107379 |\n",
      "Training epoch: 40 [1800/2000 (90%)] | D loss (A): 0.242215 | D loss (B): 0.139200 | G loss: 1.358426 | Consistency: 0.091813 |\n",
      "Training epoch: 40 [1900/2000 (95%)] | D loss (A): 0.227727 | D loss (B): 0.107185 | G loss: 1.723389 | Consistency: 0.096450 |\n",
      "Training epoch: 41 [0/2000 (0%)] | D loss (A): 0.125999 | D loss (B): 0.163760 | G loss: 1.327866 | Consistency: 0.114208 |\n",
      "Training epoch: 41 [100/2000 (5%)] | D loss (A): 0.178468 | D loss (B): 0.148440 | G loss: 1.844267 | Consistency: 0.097813 |\n",
      "Training epoch: 41 [200/2000 (10%)] | D loss (A): 0.330206 | D loss (B): 0.049553 | G loss: 2.000952 | Consistency: 0.112906 |\n",
      "Training epoch: 41 [300/2000 (15%)] | D loss (A): 0.146395 | D loss (B): 0.086740 | G loss: 2.264935 | Consistency: 0.105605 |\n",
      "Training epoch: 41 [400/2000 (20%)] | D loss (A): 0.152349 | D loss (B): 0.112114 | G loss: 1.475389 | Consistency: 0.103401 |\n",
      "Training epoch: 41 [500/2000 (25%)] | D loss (A): 0.261226 | D loss (B): 0.100618 | G loss: 1.991843 | Consistency: 0.102678 |\n",
      "Training epoch: 41 [600/2000 (30%)] | D loss (A): 0.289574 | D loss (B): 0.203256 | G loss: 2.170394 | Consistency: 0.120388 |\n",
      "Training epoch: 41 [700/2000 (35%)] | D loss (A): 0.217228 | D loss (B): 0.233369 | G loss: 2.726048 | Consistency: 0.155243 |\n",
      "Training epoch: 41 [800/2000 (40%)] | D loss (A): 0.163757 | D loss (B): 0.281379 | G loss: 2.379785 | Consistency: 0.132800 |\n",
      "Training epoch: 41 [900/2000 (45%)] | D loss (A): 0.158432 | D loss (B): 0.150674 | G loss: 2.202820 | Consistency: 0.099315 |\n",
      "Training epoch: 41 [1000/2000 (50%)] | D loss (A): 0.209398 | D loss (B): 0.076192 | G loss: 2.450418 | Consistency: 0.139929 |\n",
      "Training epoch: 41 [1100/2000 (55%)] | D loss (A): 0.121018 | D loss (B): 0.181698 | G loss: 2.454669 | Consistency: 0.132351 |\n",
      "Training epoch: 41 [1200/2000 (60%)] | D loss (A): 0.148908 | D loss (B): 0.132754 | G loss: 1.517151 | Consistency: 0.091406 |\n",
      "Training epoch: 41 [1300/2000 (65%)] | D loss (A): 0.095654 | D loss (B): 0.077823 | G loss: 1.843854 | Consistency: 0.123720 |\n",
      "Training epoch: 41 [1400/2000 (70%)] | D loss (A): 0.129021 | D loss (B): 0.087274 | G loss: 1.503164 | Consistency: 0.110313 |\n",
      "Training epoch: 41 [1500/2000 (75%)] | D loss (A): 0.097321 | D loss (B): 0.030004 | G loss: 2.431187 | Consistency: 0.144987 |\n",
      "Training epoch: 41 [1600/2000 (80%)] | D loss (A): 0.199181 | D loss (B): 0.270603 | G loss: 3.361382 | Consistency: 0.151257 |\n",
      "Training epoch: 41 [1700/2000 (85%)] | D loss (A): 0.052136 | D loss (B): 0.138210 | G loss: 2.614125 | Consistency: 0.124540 |\n",
      "Training epoch: 41 [1800/2000 (90%)] | D loss (A): 0.258991 | D loss (B): 0.049491 | G loss: 4.302731 | Consistency: 0.221058 |\n",
      "Training epoch: 41 [1900/2000 (95%)] | D loss (A): 0.344035 | D loss (B): 0.019059 | G loss: 2.181150 | Consistency: 0.120885 |\n",
      "Training epoch: 42 [0/2000 (0%)] | D loss (A): 0.296152 | D loss (B): 0.155416 | G loss: 2.198272 | Consistency: 0.128707 |\n",
      "Training epoch: 42 [100/2000 (5%)] | D loss (A): 0.254506 | D loss (B): 0.117164 | G loss: 1.664097 | Consistency: 0.099511 |\n",
      "Training epoch: 42 [200/2000 (10%)] | D loss (A): 0.271146 | D loss (B): 0.067964 | G loss: 2.049441 | Consistency: 0.104546 |\n",
      "Training epoch: 42 [300/2000 (15%)] | D loss (A): 0.176132 | D loss (B): 0.075289 | G loss: 1.719893 | Consistency: 0.105321 |\n",
      "Training epoch: 42 [400/2000 (20%)] | D loss (A): 0.174203 | D loss (B): 0.025057 | G loss: 1.397252 | Consistency: 0.095635 |\n",
      "Training epoch: 42 [500/2000 (25%)] | D loss (A): 0.249839 | D loss (B): 0.028102 | G loss: 2.151281 | Consistency: 0.119200 |\n",
      "Training epoch: 42 [600/2000 (30%)] | D loss (A): 0.225741 | D loss (B): 0.256950 | G loss: 1.599181 | Consistency: 0.078391 |\n",
      "Training epoch: 42 [700/2000 (35%)] | D loss (A): 0.243559 | D loss (B): 0.050965 | G loss: 1.910431 | Consistency: 0.117660 |\n",
      "Training epoch: 42 [800/2000 (40%)] | D loss (A): 0.222944 | D loss (B): 0.054105 | G loss: 2.477781 | Consistency: 0.113715 |\n",
      "Training epoch: 42 [900/2000 (45%)] | D loss (A): 0.220067 | D loss (B): 0.042094 | G loss: 2.221181 | Consistency: 0.150267 |\n",
      "Training epoch: 42 [1000/2000 (50%)] | D loss (A): 0.130629 | D loss (B): 0.110046 | G loss: 1.756094 | Consistency: 0.104972 |\n",
      "Training epoch: 42 [1100/2000 (55%)] | D loss (A): 0.185905 | D loss (B): 0.082824 | G loss: 2.060663 | Consistency: 0.104249 |\n",
      "Training epoch: 42 [1200/2000 (60%)] | D loss (A): 0.152999 | D loss (B): 0.238495 | G loss: 1.982337 | Consistency: 0.102207 |\n",
      "Training epoch: 42 [1300/2000 (65%)] | D loss (A): 0.160056 | D loss (B): 0.253467 | G loss: 1.800760 | Consistency: 0.097159 |\n",
      "Training epoch: 42 [1400/2000 (70%)] | D loss (A): 0.088088 | D loss (B): 0.167566 | G loss: 1.867399 | Consistency: 0.108079 |\n",
      "Training epoch: 42 [1500/2000 (75%)] | D loss (A): 0.186059 | D loss (B): 0.067079 | G loss: 1.943245 | Consistency: 0.132401 |\n",
      "Training epoch: 42 [1600/2000 (80%)] | D loss (A): 0.151768 | D loss (B): 0.231755 | G loss: 2.031631 | Consistency: 0.129950 |\n",
      "Training epoch: 42 [1700/2000 (85%)] | D loss (A): 0.171049 | D loss (B): 0.170430 | G loss: 2.073480 | Consistency: 0.109019 |\n",
      "Training epoch: 42 [1800/2000 (90%)] | D loss (A): 0.081291 | D loss (B): 0.247051 | G loss: 2.509751 | Consistency: 0.148535 |\n",
      "Training epoch: 42 [1900/2000 (95%)] | D loss (A): 0.131692 | D loss (B): 0.110439 | G loss: 2.077659 | Consistency: 0.106262 |\n",
      "Training epoch: 43 [0/2000 (0%)] | D loss (A): 0.095949 | D loss (B): 0.242850 | G loss: 1.751623 | Consistency: 0.093330 |\n",
      "Training epoch: 43 [100/2000 (5%)] | D loss (A): 0.135054 | D loss (B): 0.039848 | G loss: 1.712685 | Consistency: 0.102502 |\n",
      "Training epoch: 43 [200/2000 (10%)] | D loss (A): 0.102251 | D loss (B): 0.126539 | G loss: 1.852336 | Consistency: 0.103296 |\n",
      "Training epoch: 43 [300/2000 (15%)] | D loss (A): 0.156925 | D loss (B): 0.160123 | G loss: 1.911268 | Consistency: 0.104339 |\n",
      "Training epoch: 43 [400/2000 (20%)] | D loss (A): 0.216429 | D loss (B): 0.132041 | G loss: 2.181736 | Consistency: 0.123990 |\n",
      "Training epoch: 43 [500/2000 (25%)] | D loss (A): 0.298201 | D loss (B): 0.048462 | G loss: 1.508507 | Consistency: 0.114075 |\n",
      "Training epoch: 43 [600/2000 (30%)] | D loss (A): 0.143550 | D loss (B): 0.141724 | G loss: 2.154079 | Consistency: 0.121389 |\n",
      "Training epoch: 43 [700/2000 (35%)] | D loss (A): 0.206834 | D loss (B): 0.072600 | G loss: 1.954757 | Consistency: 0.111345 |\n",
      "Training epoch: 43 [800/2000 (40%)] | D loss (A): 0.116977 | D loss (B): 0.132085 | G loss: 2.491209 | Consistency: 0.103738 |\n",
      "Training epoch: 43 [900/2000 (45%)] | D loss (A): 0.123321 | D loss (B): 0.264775 | G loss: 1.950292 | Consistency: 0.115662 |\n",
      "Training epoch: 43 [1000/2000 (50%)] | D loss (A): 0.217386 | D loss (B): 0.123771 | G loss: 2.859027 | Consistency: 0.136371 |\n",
      "Training epoch: 43 [1100/2000 (55%)] | D loss (A): 0.141194 | D loss (B): 0.205205 | G loss: 2.208970 | Consistency: 0.110116 |\n",
      "Training epoch: 43 [1200/2000 (60%)] | D loss (A): 0.109891 | D loss (B): 0.118920 | G loss: 2.285508 | Consistency: 0.119311 |\n",
      "Training epoch: 43 [1300/2000 (65%)] | D loss (A): 0.151320 | D loss (B): 0.071611 | G loss: 1.588221 | Consistency: 0.099601 |\n",
      "Training epoch: 43 [1400/2000 (70%)] | D loss (A): 0.065538 | D loss (B): 0.048341 | G loss: 1.913998 | Consistency: 0.125577 |\n",
      "Training epoch: 43 [1500/2000 (75%)] | D loss (A): 0.197765 | D loss (B): 0.089566 | G loss: 2.692389 | Consistency: 0.131192 |\n",
      "Training epoch: 43 [1600/2000 (80%)] | D loss (A): 0.197451 | D loss (B): 0.231059 | G loss: 2.413369 | Consistency: 0.125205 |\n",
      "Training epoch: 43 [1700/2000 (85%)] | D loss (A): 0.196662 | D loss (B): 0.107909 | G loss: 2.340493 | Consistency: 0.108339 |\n",
      "Training epoch: 43 [1800/2000 (90%)] | D loss (A): 0.089528 | D loss (B): 0.137121 | G loss: 3.021246 | Consistency: 0.210496 |\n",
      "Training epoch: 43 [1900/2000 (95%)] | D loss (A): 0.133530 | D loss (B): 0.050190 | G loss: 2.362485 | Consistency: 0.129518 |\n",
      "Training epoch: 44 [0/2000 (0%)] | D loss (A): 0.191551 | D loss (B): 0.155339 | G loss: 2.558969 | Consistency: 0.119805 |\n",
      "Training epoch: 44 [100/2000 (5%)] | D loss (A): 0.049797 | D loss (B): 0.173160 | G loss: 1.784815 | Consistency: 0.095173 |\n",
      "Training epoch: 44 [200/2000 (10%)] | D loss (A): 0.286589 | D loss (B): 0.243648 | G loss: 2.052054 | Consistency: 0.114669 |\n",
      "Training epoch: 44 [300/2000 (15%)] | D loss (A): 0.315997 | D loss (B): 0.270009 | G loss: 2.268747 | Consistency: 0.109608 |\n",
      "Training epoch: 44 [400/2000 (20%)] | D loss (A): 0.111962 | D loss (B): 0.155304 | G loss: 2.146134 | Consistency: 0.116718 |\n",
      "Training epoch: 44 [500/2000 (25%)] | D loss (A): 0.240872 | D loss (B): 0.059701 | G loss: 2.511119 | Consistency: 0.114437 |\n",
      "Training epoch: 44 [600/2000 (30%)] | D loss (A): 0.026138 | D loss (B): 0.198245 | G loss: 1.811959 | Consistency: 0.105896 |\n",
      "Training epoch: 44 [700/2000 (35%)] | D loss (A): 0.131268 | D loss (B): 0.056377 | G loss: 2.693268 | Consistency: 0.141875 |\n",
      "Training epoch: 44 [800/2000 (40%)] | D loss (A): 0.198133 | D loss (B): 0.126643 | G loss: 2.653418 | Consistency: 0.143325 |\n",
      "Training epoch: 44 [900/2000 (45%)] | D loss (A): 0.103935 | D loss (B): 0.114253 | G loss: 1.506107 | Consistency: 0.102618 |\n",
      "Training epoch: 44 [1000/2000 (50%)] | D loss (A): 0.224686 | D loss (B): 0.115240 | G loss: 1.893468 | Consistency: 0.117286 |\n",
      "Training epoch: 44 [1100/2000 (55%)] | D loss (A): 0.172454 | D loss (B): 0.221453 | G loss: 2.828512 | Consistency: 0.135232 |\n",
      "Training epoch: 44 [1200/2000 (60%)] | D loss (A): 0.212574 | D loss (B): 0.073985 | G loss: 2.626506 | Consistency: 0.121130 |\n",
      "Training epoch: 44 [1300/2000 (65%)] | D loss (A): 0.136950 | D loss (B): 0.216355 | G loss: 2.191380 | Consistency: 0.119835 |\n",
      "Training epoch: 44 [1400/2000 (70%)] | D loss (A): 0.136569 | D loss (B): 0.096570 | G loss: 2.386013 | Consistency: 0.113563 |\n",
      "Training epoch: 44 [1500/2000 (75%)] | D loss (A): 0.179968 | D loss (B): 0.204008 | G loss: 1.985834 | Consistency: 0.107457 |\n",
      "Training epoch: 44 [1600/2000 (80%)] | D loss (A): 0.191746 | D loss (B): 0.055700 | G loss: 1.972493 | Consistency: 0.116991 |\n",
      "Training epoch: 44 [1700/2000 (85%)] | D loss (A): 0.066662 | D loss (B): 0.187236 | G loss: 1.803608 | Consistency: 0.089107 |\n",
      "Training epoch: 44 [1800/2000 (90%)] | D loss (A): 0.153533 | D loss (B): 0.118330 | G loss: 2.355992 | Consistency: 0.092861 |\n",
      "Training epoch: 44 [1900/2000 (95%)] | D loss (A): 0.162836 | D loss (B): 0.141168 | G loss: 2.784730 | Consistency: 0.133909 |\n",
      "Training epoch: 45 [0/2000 (0%)] | D loss (A): 0.093540 | D loss (B): 0.157270 | G loss: 2.198719 | Consistency: 0.084832 |\n",
      "Training epoch: 45 [100/2000 (5%)] | D loss (A): 0.213452 | D loss (B): 0.050473 | G loss: 1.408729 | Consistency: 0.078548 |\n",
      "Training epoch: 45 [200/2000 (10%)] | D loss (A): 0.156956 | D loss (B): 0.124121 | G loss: 2.025210 | Consistency: 0.084646 |\n",
      "Training epoch: 45 [300/2000 (15%)] | D loss (A): 0.221305 | D loss (B): 0.178176 | G loss: 1.952720 | Consistency: 0.086310 |\n",
      "Training epoch: 45 [400/2000 (20%)] | D loss (A): 0.375226 | D loss (B): 43.199265 | G loss: 10.578121 | Consistency: 0.301814 |\n",
      "Training epoch: 45 [500/2000 (25%)] | D loss (A): 0.169689 | D loss (B): 0.197508 | G loss: 2.023911 | Consistency: 0.111144 |\n",
      "Training epoch: 45 [600/2000 (30%)] | D loss (A): 0.095570 | D loss (B): 0.259367 | G loss: 1.951056 | Consistency: 0.126745 |\n",
      "Training epoch: 45 [700/2000 (35%)] | D loss (A): 0.096474 | D loss (B): 0.303140 | G loss: 1.549204 | Consistency: 0.101900 |\n",
      "Training epoch: 45 [800/2000 (40%)] | D loss (A): 0.132016 | D loss (B): 0.274906 | G loss: 2.114658 | Consistency: 0.115275 |\n",
      "Training epoch: 45 [900/2000 (45%)] | D loss (A): 0.144608 | D loss (B): 0.326309 | G loss: 1.727112 | Consistency: 0.111596 |\n",
      "Training epoch: 45 [1000/2000 (50%)] | D loss (A): 0.253996 | D loss (B): 0.224219 | G loss: 1.943872 | Consistency: 0.124832 |\n",
      "Training epoch: 45 [1100/2000 (55%)] | D loss (A): 0.108816 | D loss (B): 0.314222 | G loss: 1.976652 | Consistency: 0.077755 |\n",
      "Training epoch: 45 [1200/2000 (60%)] | D loss (A): 0.153517 | D loss (B): 0.251446 | G loss: 2.340111 | Consistency: 0.125872 |\n",
      "Training epoch: 45 [1300/2000 (65%)] | D loss (A): 0.207022 | D loss (B): 0.300810 | G loss: 1.668739 | Consistency: 0.096967 |\n",
      "Training epoch: 45 [1400/2000 (70%)] | D loss (A): 0.103952 | D loss (B): 0.285248 | G loss: 1.782970 | Consistency: 0.103385 |\n",
      "Training epoch: 45 [1500/2000 (75%)] | D loss (A): 8.022488 | D loss (B): 0.216399 | G loss: 3.305954 | Consistency: 0.193785 |\n",
      "Training epoch: 45 [1600/2000 (80%)] | D loss (A): 0.366990 | D loss (B): 0.253720 | G loss: 1.453746 | Consistency: 0.092304 |\n",
      "Training epoch: 45 [1700/2000 (85%)] | D loss (A): 0.288740 | D loss (B): 0.303597 | G loss: 1.501198 | Consistency: 0.104302 |\n",
      "Training epoch: 45 [1800/2000 (90%)] | D loss (A): 0.213141 | D loss (B): 0.229856 | G loss: 1.523263 | Consistency: 0.099228 |\n",
      "Training epoch: 45 [1900/2000 (95%)] | D loss (A): 0.224375 | D loss (B): 0.277156 | G loss: 1.634095 | Consistency: 0.103438 |\n",
      "Training epoch: 46 [0/2000 (0%)] | D loss (A): 0.229572 | D loss (B): 0.183071 | G loss: 1.221852 | Consistency: 0.078509 |\n",
      "Training epoch: 46 [100/2000 (5%)] | D loss (A): 0.242373 | D loss (B): 0.397588 | G loss: 1.507979 | Consistency: 0.094463 |\n",
      "Training epoch: 46 [200/2000 (10%)] | D loss (A): 0.241358 | D loss (B): 0.233908 | G loss: 1.391859 | Consistency: 0.090301 |\n",
      "Training epoch: 46 [300/2000 (15%)] | D loss (A): 0.203398 | D loss (B): 0.192309 | G loss: 1.305322 | Consistency: 0.078696 |\n",
      "Training epoch: 46 [400/2000 (20%)] | D loss (A): 0.258374 | D loss (B): 0.237806 | G loss: 1.638937 | Consistency: 0.105356 |\n",
      "Training epoch: 46 [500/2000 (25%)] | D loss (A): 0.293488 | D loss (B): 0.258433 | G loss: 1.455825 | Consistency: 0.096706 |\n",
      "Training epoch: 46 [600/2000 (30%)] | D loss (A): 0.197453 | D loss (B): 0.274344 | G loss: 1.465778 | Consistency: 0.091355 |\n",
      "Training epoch: 46 [700/2000 (35%)] | D loss (A): 0.374310 | D loss (B): 0.242097 | G loss: 1.511034 | Consistency: 0.097684 |\n",
      "Training epoch: 46 [800/2000 (40%)] | D loss (A): 0.304772 | D loss (B): 0.273582 | G loss: 1.186375 | Consistency: 0.080622 |\n",
      "Training epoch: 46 [900/2000 (45%)] | D loss (A): 0.250659 | D loss (B): 0.183297 | G loss: 1.500826 | Consistency: 0.117032 |\n",
      "Training epoch: 46 [1000/2000 (50%)] | D loss (A): 0.260788 | D loss (B): 0.333349 | G loss: 1.358433 | Consistency: 0.079622 |\n",
      "Training epoch: 46 [1100/2000 (55%)] | D loss (A): 0.289816 | D loss (B): 0.208451 | G loss: 1.414185 | Consistency: 0.091774 |\n",
      "Training epoch: 46 [1200/2000 (60%)] | D loss (A): 0.207255 | D loss (B): 0.225464 | G loss: 1.263155 | Consistency: 0.085722 |\n",
      "Training epoch: 46 [1300/2000 (65%)] | D loss (A): 0.264887 | D loss (B): 0.240255 | G loss: 1.272804 | Consistency: 0.077971 |\n",
      "Training epoch: 46 [1400/2000 (70%)] | D loss (A): 0.270365 | D loss (B): 0.309377 | G loss: 1.997939 | Consistency: 0.120709 |\n",
      "Training epoch: 46 [1500/2000 (75%)] | D loss (A): 0.164355 | D loss (B): 0.226763 | G loss: 1.735989 | Consistency: 0.098748 |\n",
      "Training epoch: 46 [1600/2000 (80%)] | D loss (A): 0.288666 | D loss (B): 0.360587 | G loss: 1.543836 | Consistency: 0.098312 |\n",
      "Training epoch: 46 [1700/2000 (85%)] | D loss (A): 0.191233 | D loss (B): 0.222388 | G loss: 1.634804 | Consistency: 0.090886 |\n",
      "Training epoch: 46 [1800/2000 (90%)] | D loss (A): 0.129562 | D loss (B): 0.235786 | G loss: 1.589948 | Consistency: 0.098482 |\n",
      "Training epoch: 46 [1900/2000 (95%)] | D loss (A): 0.242275 | D loss (B): 0.135902 | G loss: 2.028991 | Consistency: 0.119203 |\n",
      "Training epoch: 47 [0/2000 (0%)] | D loss (A): 0.139444 | D loss (B): 0.198737 | G loss: 1.289118 | Consistency: 0.093772 |\n",
      "Training epoch: 47 [100/2000 (5%)] | D loss (A): 0.106033 | D loss (B): 0.159347 | G loss: 1.366377 | Consistency: 0.090360 |\n",
      "Training epoch: 47 [200/2000 (10%)] | D loss (A): 0.369292 | D loss (B): 0.120053 | G loss: 1.755474 | Consistency: 0.095260 |\n",
      "Training epoch: 47 [300/2000 (15%)] | D loss (A): 0.122312 | D loss (B): 0.168912 | G loss: 1.964234 | Consistency: 0.108660 |\n",
      "Training epoch: 47 [400/2000 (20%)] | D loss (A): 0.101045 | D loss (B): 0.210194 | G loss: 2.109244 | Consistency: 0.126641 |\n",
      "Training epoch: 47 [500/2000 (25%)] | D loss (A): 0.122425 | D loss (B): 0.077101 | G loss: 2.267725 | Consistency: 0.109859 |\n",
      "Training epoch: 47 [600/2000 (30%)] | D loss (A): 0.114459 | D loss (B): 0.092403 | G loss: 1.716564 | Consistency: 0.117043 |\n",
      "Training epoch: 47 [700/2000 (35%)] | D loss (A): 0.153187 | D loss (B): 0.155785 | G loss: 1.751185 | Consistency: 0.103648 |\n",
      "Training epoch: 47 [800/2000 (40%)] | D loss (A): 0.089588 | D loss (B): 0.178954 | G loss: 2.174184 | Consistency: 0.125713 |\n",
      "Training epoch: 47 [900/2000 (45%)] | D loss (A): 0.170773 | D loss (B): 0.127463 | G loss: 2.226397 | Consistency: 0.115463 |\n",
      "Training epoch: 47 [1000/2000 (50%)] | D loss (A): 0.060665 | D loss (B): 0.054507 | G loss: 1.568403 | Consistency: 0.082779 |\n",
      "Training epoch: 47 [1100/2000 (55%)] | D loss (A): 0.080872 | D loss (B): 0.101290 | G loss: 1.662516 | Consistency: 0.111531 |\n",
      "Training epoch: 47 [1200/2000 (60%)] | D loss (A): 0.075904 | D loss (B): 0.200974 | G loss: 2.059972 | Consistency: 0.129080 |\n",
      "Training epoch: 47 [1300/2000 (65%)] | D loss (A): 0.299768 | D loss (B): 0.199658 | G loss: 1.574624 | Consistency: 0.110242 |\n",
      "Training epoch: 47 [1400/2000 (70%)] | D loss (A): 0.459221 | D loss (B): 0.065517 | G loss: 1.687289 | Consistency: 0.096702 |\n",
      "Training epoch: 47 [1500/2000 (75%)] | D loss (A): 0.211631 | D loss (B): 0.116396 | G loss: 2.137344 | Consistency: 0.105482 |\n",
      "Training epoch: 47 [1600/2000 (80%)] | D loss (A): 0.120331 | D loss (B): 0.071087 | G loss: 2.586893 | Consistency: 0.127731 |\n",
      "Training epoch: 47 [1700/2000 (85%)] | D loss (A): 0.178800 | D loss (B): 0.196217 | G loss: 1.965122 | Consistency: 0.101520 |\n",
      "Training epoch: 47 [1800/2000 (90%)] | D loss (A): 0.096442 | D loss (B): 0.107313 | G loss: 3.238573 | Consistency: 0.182488 |\n",
      "Training epoch: 47 [1900/2000 (95%)] | D loss (A): 0.109249 | D loss (B): 0.179230 | G loss: 2.370430 | Consistency: 0.094067 |\n",
      "Training epoch: 48 [0/2000 (0%)] | D loss (A): 0.333372 | D loss (B): 0.041965 | G loss: 1.838680 | Consistency: 0.116851 |\n",
      "Training epoch: 48 [100/2000 (5%)] | D loss (A): 0.107434 | D loss (B): 0.119275 | G loss: 2.136121 | Consistency: 0.108055 |\n",
      "Training epoch: 48 [200/2000 (10%)] | D loss (A): 0.097850 | D loss (B): 0.142816 | G loss: 1.953931 | Consistency: 0.113769 |\n",
      "Training epoch: 48 [300/2000 (15%)] | D loss (A): 0.115328 | D loss (B): 0.118574 | G loss: 2.521203 | Consistency: 0.099530 |\n",
      "Training epoch: 48 [400/2000 (20%)] | D loss (A): 0.138438 | D loss (B): 0.128129 | G loss: 1.638531 | Consistency: 0.078954 |\n",
      "Training epoch: 48 [500/2000 (25%)] | D loss (A): 0.085726 | D loss (B): 0.130741 | G loss: 2.264139 | Consistency: 0.114255 |\n",
      "Training epoch: 48 [600/2000 (30%)] | D loss (A): 0.162854 | D loss (B): 0.055131 | G loss: 1.825147 | Consistency: 0.133195 |\n",
      "Training epoch: 48 [700/2000 (35%)] | D loss (A): 0.208340 | D loss (B): 0.123560 | G loss: 1.895539 | Consistency: 0.131898 |\n",
      "Training epoch: 48 [800/2000 (40%)] | D loss (A): 0.169182 | D loss (B): 0.048917 | G loss: 1.683569 | Consistency: 0.125795 |\n",
      "Training epoch: 48 [900/2000 (45%)] | D loss (A): 0.121570 | D loss (B): 0.106392 | G loss: 1.771904 | Consistency: 0.113449 |\n",
      "Training epoch: 48 [1000/2000 (50%)] | D loss (A): 0.158572 | D loss (B): 0.222868 | G loss: 2.318230 | Consistency: 0.136006 |\n",
      "Training epoch: 48 [1100/2000 (55%)] | D loss (A): 0.210599 | D loss (B): 0.042221 | G loss: 2.239646 | Consistency: 0.130666 |\n",
      "Training epoch: 48 [1200/2000 (60%)] | D loss (A): 0.185116 | D loss (B): 0.078037 | G loss: 1.869525 | Consistency: 0.122693 |\n",
      "Training epoch: 48 [1300/2000 (65%)] | D loss (A): 0.176527 | D loss (B): 0.251511 | G loss: 3.730714 | Consistency: 0.274282 |\n",
      "Training epoch: 48 [1400/2000 (70%)] | D loss (A): 0.270767 | D loss (B): 0.287977 | G loss: 1.948671 | Consistency: 0.137592 |\n",
      "Training epoch: 48 [1500/2000 (75%)] | D loss (A): 0.058646 | D loss (B): 0.258665 | G loss: 2.166250 | Consistency: 0.121382 |\n",
      "Training epoch: 48 [1600/2000 (80%)] | D loss (A): 0.238554 | D loss (B): 0.282998 | G loss: 1.864978 | Consistency: 0.110870 |\n",
      "Training epoch: 48 [1700/2000 (85%)] | D loss (A): 0.071149 | D loss (B): 0.167340 | G loss: 1.386340 | Consistency: 0.103318 |\n",
      "Training epoch: 48 [1800/2000 (90%)] | D loss (A): 0.375504 | D loss (B): 0.183507 | G loss: 1.602014 | Consistency: 0.102256 |\n",
      "Training epoch: 48 [1900/2000 (95%)] | D loss (A): 0.175071 | D loss (B): 0.259132 | G loss: 2.093411 | Consistency: 0.120000 |\n",
      "Training epoch: 49 [0/2000 (0%)] | D loss (A): 0.120495 | D loss (B): 0.318387 | G loss: 1.732148 | Consistency: 0.122744 |\n",
      "Training epoch: 49 [100/2000 (5%)] | D loss (A): 0.184368 | D loss (B): 0.331821 | G loss: 2.182901 | Consistency: 0.104933 |\n",
      "Training epoch: 49 [200/2000 (10%)] | D loss (A): 0.217672 | D loss (B): 0.135345 | G loss: 1.349510 | Consistency: 0.086940 |\n",
      "Training epoch: 49 [300/2000 (15%)] | D loss (A): 0.054119 | D loss (B): 0.261774 | G loss: 2.271563 | Consistency: 0.108882 |\n",
      "Training epoch: 49 [400/2000 (20%)] | D loss (A): 0.072907 | D loss (B): 0.209007 | G loss: 2.878370 | Consistency: 0.162748 |\n",
      "Training epoch: 49 [500/2000 (25%)] | D loss (A): 0.237788 | D loss (B): 0.226782 | G loss: 2.171772 | Consistency: 0.106700 |\n",
      "Training epoch: 49 [600/2000 (30%)] | D loss (A): 0.286299 | D loss (B): 0.199712 | G loss: 1.837156 | Consistency: 0.099423 |\n",
      "Training epoch: 49 [700/2000 (35%)] | D loss (A): 0.130251 | D loss (B): 0.191541 | G loss: 2.042238 | Consistency: 0.126498 |\n",
      "Training epoch: 49 [800/2000 (40%)] | D loss (A): 0.174543 | D loss (B): 0.158564 | G loss: 2.132447 | Consistency: 0.133330 |\n",
      "Training epoch: 49 [900/2000 (45%)] | D loss (A): 0.217042 | D loss (B): 0.149435 | G loss: 1.898452 | Consistency: 0.087720 |\n",
      "Training epoch: 49 [1000/2000 (50%)] | D loss (A): 0.140272 | D loss (B): 0.098600 | G loss: 1.753662 | Consistency: 0.112150 |\n",
      "Training epoch: 49 [1100/2000 (55%)] | D loss (A): 0.257454 | D loss (B): 0.203413 | G loss: 1.925558 | Consistency: 0.100695 |\n",
      "Training epoch: 49 [1200/2000 (60%)] | D loss (A): 0.186999 | D loss (B): 0.105969 | G loss: 1.680262 | Consistency: 0.095779 |\n",
      "Training epoch: 49 [1300/2000 (65%)] | D loss (A): 0.180493 | D loss (B): 0.193728 | G loss: 2.042428 | Consistency: 0.103095 |\n",
      "Training epoch: 49 [1400/2000 (70%)] | D loss (A): 0.159916 | D loss (B): 0.131327 | G loss: 2.212770 | Consistency: 0.118829 |\n",
      "Training epoch: 49 [1500/2000 (75%)] | D loss (A): 0.282052 | D loss (B): 0.138943 | G loss: 1.821084 | Consistency: 0.094978 |\n",
      "Training epoch: 49 [1600/2000 (80%)] | D loss (A): 0.175506 | D loss (B): 0.124390 | G loss: 1.789488 | Consistency: 0.092074 |\n",
      "Training epoch: 49 [1700/2000 (85%)] | D loss (A): 0.108183 | D loss (B): 0.147731 | G loss: 1.987240 | Consistency: 0.102316 |\n",
      "Training epoch: 49 [1800/2000 (90%)] | D loss (A): 0.078983 | D loss (B): 0.317276 | G loss: 2.203058 | Consistency: 0.129092 |\n",
      "Training epoch: 49 [1900/2000 (95%)] | D loss (A): 0.124002 | D loss (B): 0.173342 | G loss: 1.653764 | Consistency: 0.092257 |\n",
      "Training epoch: 50 [0/2000 (0%)] | D loss (A): 0.151207 | D loss (B): 0.065314 | G loss: 2.219493 | Consistency: 0.137599 |\n",
      "Training epoch: 50 [100/2000 (5%)] | D loss (A): 0.238899 | D loss (B): 0.135500 | G loss: 1.681486 | Consistency: 0.087287 |\n",
      "Training epoch: 50 [200/2000 (10%)] | D loss (A): 0.166774 | D loss (B): 0.214059 | G loss: 1.701335 | Consistency: 0.102703 |\n",
      "Training epoch: 50 [300/2000 (15%)] | D loss (A): 0.160741 | D loss (B): 0.219255 | G loss: 2.135693 | Consistency: 0.114663 |\n",
      "Training epoch: 50 [400/2000 (20%)] | D loss (A): 0.213160 | D loss (B): 0.105409 | G loss: 1.794560 | Consistency: 0.102867 |\n",
      "Training epoch: 50 [500/2000 (25%)] | D loss (A): 0.089100 | D loss (B): 0.123101 | G loss: 1.407525 | Consistency: 0.094291 |\n",
      "Training epoch: 50 [600/2000 (30%)] | D loss (A): 0.116398 | D loss (B): 0.065196 | G loss: 2.870070 | Consistency: 0.121689 |\n",
      "Training epoch: 50 [700/2000 (35%)] | D loss (A): 0.189887 | D loss (B): 0.096552 | G loss: 1.802114 | Consistency: 0.098483 |\n",
      "Training epoch: 50 [800/2000 (40%)] | D loss (A): 0.095155 | D loss (B): 0.109257 | G loss: 2.150098 | Consistency: 0.120005 |\n",
      "Training epoch: 50 [900/2000 (45%)] | D loss (A): 0.143261 | D loss (B): 0.155082 | G loss: 1.691688 | Consistency: 0.079620 |\n",
      "Training epoch: 50 [1000/2000 (50%)] | D loss (A): 0.231941 | D loss (B): 0.088424 | G loss: 2.295806 | Consistency: 0.102979 |\n",
      "Training epoch: 50 [1100/2000 (55%)] | D loss (A): 0.163771 | D loss (B): 0.068067 | G loss: 2.252654 | Consistency: 0.092863 |\n",
      "Training epoch: 50 [1200/2000 (60%)] | D loss (A): 0.090573 | D loss (B): 0.164906 | G loss: 1.719448 | Consistency: 0.099531 |\n",
      "Training epoch: 50 [1300/2000 (65%)] | D loss (A): 0.131112 | D loss (B): 0.167538 | G loss: 2.815219 | Consistency: 0.140038 |\n",
      "Training epoch: 50 [1400/2000 (70%)] | D loss (A): 0.181619 | D loss (B): 0.045469 | G loss: 1.793964 | Consistency: 0.103894 |\n",
      "Training epoch: 50 [1500/2000 (75%)] | D loss (A): 0.232686 | D loss (B): 0.094623 | G loss: 2.269263 | Consistency: 0.119571 |\n",
      "Training epoch: 50 [1600/2000 (80%)] | D loss (A): 0.111831 | D loss (B): 0.229652 | G loss: 1.743460 | Consistency: 0.111509 |\n",
      "Training epoch: 50 [1700/2000 (85%)] | D loss (A): 0.175097 | D loss (B): 0.032559 | G loss: 2.332696 | Consistency: 0.110694 |\n",
      "Training epoch: 50 [1800/2000 (90%)] | D loss (A): 0.112524 | D loss (B): 0.103107 | G loss: 1.718732 | Consistency: 0.099678 |\n",
      "Training epoch: 50 [1900/2000 (95%)] | D loss (A): 0.177339 | D loss (B): 0.175097 | G loss: 2.195672 | Consistency: 0.082614 |\n",
      "Training epoch: 51 [0/2000 (0%)] | D loss (A): 0.166106 | D loss (B): 0.165659 | G loss: 1.967173 | Consistency: 0.123802 |\n",
      "Training epoch: 51 [100/2000 (5%)] | D loss (A): 0.138341 | D loss (B): 0.030558 | G loss: 2.200983 | Consistency: 0.116071 |\n",
      "Training epoch: 51 [200/2000 (10%)] | D loss (A): 0.253589 | D loss (B): 0.202550 | G loss: 1.864352 | Consistency: 0.093986 |\n",
      "Training epoch: 51 [300/2000 (15%)] | D loss (A): 0.354092 | D loss (B): 0.105582 | G loss: 1.467666 | Consistency: 0.104398 |\n",
      "Training epoch: 51 [400/2000 (20%)] | D loss (A): 0.142845 | D loss (B): 0.230473 | G loss: 2.480443 | Consistency: 0.106767 |\n",
      "Training epoch: 51 [500/2000 (25%)] | D loss (A): 0.239500 | D loss (B): 0.113705 | G loss: 1.519030 | Consistency: 0.078706 |\n",
      "Training epoch: 51 [600/2000 (30%)] | D loss (A): 0.062679 | D loss (B): 0.081717 | G loss: 1.852292 | Consistency: 0.113268 |\n",
      "Training epoch: 51 [700/2000 (35%)] | D loss (A): 0.293401 | D loss (B): 0.191710 | G loss: 2.055821 | Consistency: 0.101321 |\n",
      "Training epoch: 51 [800/2000 (40%)] | D loss (A): 0.220380 | D loss (B): 0.180992 | G loss: 1.808987 | Consistency: 0.106784 |\n",
      "Training epoch: 51 [900/2000 (45%)] | D loss (A): 0.104713 | D loss (B): 0.104192 | G loss: 3.094580 | Consistency: 0.147014 |\n",
      "Training epoch: 51 [1000/2000 (50%)] | D loss (A): 0.179063 | D loss (B): 0.061274 | G loss: 2.367584 | Consistency: 0.100884 |\n",
      "Training epoch: 51 [1100/2000 (55%)] | D loss (A): 0.093067 | D loss (B): 0.358947 | G loss: 1.534233 | Consistency: 0.091776 |\n",
      "Training epoch: 51 [1200/2000 (60%)] | D loss (A): 0.185359 | D loss (B): 0.051172 | G loss: 2.335114 | Consistency: 0.120210 |\n",
      "Training epoch: 51 [1300/2000 (65%)] | D loss (A): 0.152986 | D loss (B): 0.130810 | G loss: 2.135740 | Consistency: 0.086386 |\n",
      "Training epoch: 51 [1400/2000 (70%)] | D loss (A): 0.123872 | D loss (B): 0.118029 | G loss: 2.222155 | Consistency: 0.128022 |\n",
      "Training epoch: 51 [1500/2000 (75%)] | D loss (A): 0.181375 | D loss (B): 0.275611 | G loss: 1.991117 | Consistency: 0.096066 |\n",
      "Training epoch: 51 [1600/2000 (80%)] | D loss (A): 0.198243 | D loss (B): 0.395977 | G loss: 2.413618 | Consistency: 0.117316 |\n",
      "Training epoch: 51 [1700/2000 (85%)] | D loss (A): 0.127936 | D loss (B): 0.156064 | G loss: 1.624828 | Consistency: 0.100568 |\n",
      "Training epoch: 51 [1800/2000 (90%)] | D loss (A): 0.043642 | D loss (B): 0.071414 | G loss: 2.655148 | Consistency: 0.131633 |\n",
      "Training epoch: 51 [1900/2000 (95%)] | D loss (A): 0.124579 | D loss (B): 0.098359 | G loss: 1.669974 | Consistency: 0.103537 |\n",
      "Training epoch: 52 [0/2000 (0%)] | D loss (A): 0.125319 | D loss (B): 0.203867 | G loss: 2.231385 | Consistency: 0.136216 |\n",
      "Training epoch: 52 [100/2000 (5%)] | D loss (A): 0.126209 | D loss (B): 0.147321 | G loss: 1.920696 | Consistency: 0.116139 |\n",
      "Training epoch: 52 [200/2000 (10%)] | D loss (A): 0.076871 | D loss (B): 0.051401 | G loss: 2.105031 | Consistency: 0.117798 |\n",
      "Training epoch: 52 [300/2000 (15%)] | D loss (A): 0.100121 | D loss (B): 0.111555 | G loss: 1.372209 | Consistency: 0.078336 |\n",
      "Training epoch: 52 [400/2000 (20%)] | D loss (A): 0.170518 | D loss (B): 0.116343 | G loss: 2.205030 | Consistency: 0.100020 |\n",
      "Training epoch: 52 [500/2000 (25%)] | D loss (A): 0.226121 | D loss (B): 0.241130 | G loss: 1.815735 | Consistency: 0.091714 |\n",
      "Training epoch: 52 [600/2000 (30%)] | D loss (A): 0.203811 | D loss (B): 0.133573 | G loss: 2.340214 | Consistency: 0.112575 |\n",
      "Training epoch: 52 [700/2000 (35%)] | D loss (A): 0.089663 | D loss (B): 0.033022 | G loss: 1.926924 | Consistency: 0.106561 |\n",
      "Training epoch: 52 [800/2000 (40%)] | D loss (A): 0.218714 | D loss (B): 0.131104 | G loss: 1.832871 | Consistency: 0.091980 |\n",
      "Training epoch: 52 [900/2000 (45%)] | D loss (A): 0.161342 | D loss (B): 0.146220 | G loss: 2.199727 | Consistency: 0.120485 |\n",
      "Training epoch: 52 [1000/2000 (50%)] | D loss (A): 0.202344 | D loss (B): 0.123279 | G loss: 2.436478 | Consistency: 0.115524 |\n",
      "Training epoch: 52 [1100/2000 (55%)] | D loss (A): 0.146473 | D loss (B): 0.119672 | G loss: 1.203219 | Consistency: 0.089669 |\n",
      "Training epoch: 52 [1200/2000 (60%)] | D loss (A): 0.263808 | D loss (B): 0.186889 | G loss: 1.982851 | Consistency: 0.098564 |\n",
      "Training epoch: 52 [1300/2000 (65%)] | D loss (A): 0.158180 | D loss (B): 0.129535 | G loss: 2.533890 | Consistency: 0.112401 |\n",
      "Training epoch: 52 [1400/2000 (70%)] | D loss (A): 0.859318 | D loss (B): 0.061314 | G loss: 4.492838 | Consistency: 0.112004 |\n",
      "Training epoch: 52 [1500/2000 (75%)] | D loss (A): 0.313263 | D loss (B): 0.198752 | G loss: 2.089833 | Consistency: 0.122229 |\n",
      "Training epoch: 52 [1600/2000 (80%)] | D loss (A): 0.264032 | D loss (B): 0.037122 | G loss: 1.506559 | Consistency: 0.098490 |\n",
      "Training epoch: 52 [1700/2000 (85%)] | D loss (A): 0.255539 | D loss (B): 0.264079 | G loss: 1.728140 | Consistency: 0.096858 |\n",
      "Training epoch: 52 [1800/2000 (90%)] | D loss (A): 0.174703 | D loss (B): 0.066461 | G loss: 1.578345 | Consistency: 0.103537 |\n",
      "Training epoch: 52 [1900/2000 (95%)] | D loss (A): 0.282194 | D loss (B): 0.121295 | G loss: 1.878603 | Consistency: 0.104428 |\n",
      "Training epoch: 53 [0/2000 (0%)] | D loss (A): 0.277385 | D loss (B): 0.131419 | G loss: 1.642099 | Consistency: 0.095434 |\n",
      "Training epoch: 53 [100/2000 (5%)] | D loss (A): 0.293718 | D loss (B): 0.179394 | G loss: 1.834503 | Consistency: 0.104511 |\n",
      "Training epoch: 53 [200/2000 (10%)] | D loss (A): 0.209180 | D loss (B): 0.193152 | G loss: 1.897269 | Consistency: 0.086796 |\n",
      "Training epoch: 53 [300/2000 (15%)] | D loss (A): 0.239430 | D loss (B): 0.247255 | G loss: 1.954296 | Consistency: 0.111601 |\n",
      "Training epoch: 53 [400/2000 (20%)] | D loss (A): 0.309408 | D loss (B): 0.070414 | G loss: 1.491608 | Consistency: 0.088224 |\n",
      "Training epoch: 53 [500/2000 (25%)] | D loss (A): 0.167509 | D loss (B): 0.194706 | G loss: 1.574565 | Consistency: 0.098738 |\n",
      "Training epoch: 53 [600/2000 (30%)] | D loss (A): 0.187408 | D loss (B): 0.252345 | G loss: 1.691890 | Consistency: 0.085876 |\n",
      "Training epoch: 53 [700/2000 (35%)] | D loss (A): 0.265936 | D loss (B): 0.095768 | G loss: 1.539178 | Consistency: 0.083674 |\n",
      "Training epoch: 53 [800/2000 (40%)] | D loss (A): 0.269192 | D loss (B): 0.286491 | G loss: 1.765073 | Consistency: 0.087235 |\n",
      "Training epoch: 53 [900/2000 (45%)] | D loss (A): 0.242514 | D loss (B): 0.175824 | G loss: 1.610051 | Consistency: 0.083113 |\n",
      "Training epoch: 53 [1000/2000 (50%)] | D loss (A): 0.290006 | D loss (B): 0.095727 | G loss: 1.916864 | Consistency: 0.109418 |\n",
      "Training epoch: 53 [1100/2000 (55%)] | D loss (A): 0.238402 | D loss (B): 0.104080 | G loss: 1.430954 | Consistency: 0.102477 |\n",
      "Training epoch: 53 [1200/2000 (60%)] | D loss (A): 0.243648 | D loss (B): 0.162333 | G loss: 1.886479 | Consistency: 0.101812 |\n",
      "Training epoch: 53 [1300/2000 (65%)] | D loss (A): 0.234866 | D loss (B): 0.080913 | G loss: 1.893716 | Consistency: 0.101889 |\n",
      "Training epoch: 53 [1400/2000 (70%)] | D loss (A): 0.189852 | D loss (B): 0.175308 | G loss: 1.405544 | Consistency: 0.084513 |\n",
      "Training epoch: 53 [1500/2000 (75%)] | D loss (A): 0.250906 | D loss (B): 0.079182 | G loss: 2.125334 | Consistency: 0.107132 |\n",
      "Training epoch: 53 [1600/2000 (80%)] | D loss (A): 0.191726 | D loss (B): 0.149772 | G loss: 2.159609 | Consistency: 0.100884 |\n",
      "Training epoch: 53 [1700/2000 (85%)] | D loss (A): 0.177078 | D loss (B): 0.300061 | G loss: 1.907098 | Consistency: 0.114376 |\n",
      "Training epoch: 53 [1800/2000 (90%)] | D loss (A): 0.140826 | D loss (B): 0.109639 | G loss: 2.095931 | Consistency: 0.106792 |\n",
      "Training epoch: 53 [1900/2000 (95%)] | D loss (A): 0.157546 | D loss (B): 0.191960 | G loss: 2.262783 | Consistency: 0.125458 |\n",
      "Training epoch: 54 [0/2000 (0%)] | D loss (A): 0.239853 | D loss (B): 0.141910 | G loss: 1.812541 | Consistency: 0.112986 |\n",
      "Training epoch: 54 [100/2000 (5%)] | D loss (A): 0.106987 | D loss (B): 0.194520 | G loss: 1.848812 | Consistency: 0.128176 |\n",
      "Training epoch: 54 [200/2000 (10%)] | D loss (A): 0.262163 | D loss (B): 0.152277 | G loss: 1.448709 | Consistency: 0.085424 |\n",
      "Training epoch: 54 [300/2000 (15%)] | D loss (A): 0.176508 | D loss (B): 0.150641 | G loss: 2.620416 | Consistency: 0.145382 |\n",
      "Training epoch: 54 [400/2000 (20%)] | D loss (A): 0.239693 | D loss (B): 0.162122 | G loss: 1.394484 | Consistency: 0.074671 |\n",
      "Training epoch: 54 [500/2000 (25%)] | D loss (A): 0.271291 | D loss (B): 0.142342 | G loss: 2.621142 | Consistency: 0.137573 |\n",
      "Training epoch: 54 [600/2000 (30%)] | D loss (A): 0.135307 | D loss (B): 0.358039 | G loss: 2.113329 | Consistency: 0.094672 |\n",
      "Training epoch: 54 [700/2000 (35%)] | D loss (A): 0.127569 | D loss (B): 0.207901 | G loss: 1.689206 | Consistency: 0.097834 |\n",
      "Training epoch: 54 [800/2000 (40%)] | D loss (A): 0.242726 | D loss (B): 0.245714 | G loss: 1.471380 | Consistency: 0.097198 |\n",
      "Training epoch: 54 [900/2000 (45%)] | D loss (A): 0.243099 | D loss (B): 0.071463 | G loss: 1.448447 | Consistency: 0.088783 |\n",
      "Training epoch: 54 [1000/2000 (50%)] | D loss (A): 0.185052 | D loss (B): 0.205134 | G loss: 2.254810 | Consistency: 0.113140 |\n",
      "Training epoch: 54 [1100/2000 (55%)] | D loss (A): 0.207406 | D loss (B): 0.403873 | G loss: 1.900230 | Consistency: 0.102659 |\n",
      "Training epoch: 54 [1200/2000 (60%)] | D loss (A): 0.107609 | D loss (B): 0.081055 | G loss: 1.598293 | Consistency: 0.085251 |\n",
      "Training epoch: 54 [1300/2000 (65%)] | D loss (A): 0.073994 | D loss (B): 0.047689 | G loss: 2.532855 | Consistency: 0.139242 |\n",
      "Training epoch: 54 [1400/2000 (70%)] | D loss (A): 0.171405 | D loss (B): 0.226900 | G loss: 2.052437 | Consistency: 0.096799 |\n",
      "Training epoch: 54 [1500/2000 (75%)] | D loss (A): 0.097196 | D loss (B): 0.183443 | G loss: 2.362412 | Consistency: 0.137132 |\n",
      "Training epoch: 54 [1600/2000 (80%)] | D loss (A): 0.183190 | D loss (B): 0.144040 | G loss: 1.762396 | Consistency: 0.109775 |\n",
      "Training epoch: 54 [1700/2000 (85%)] | D loss (A): 0.177409 | D loss (B): 0.150847 | G loss: 1.809868 | Consistency: 0.084885 |\n",
      "Training epoch: 54 [1800/2000 (90%)] | D loss (A): 0.121002 | D loss (B): 0.098196 | G loss: 2.261261 | Consistency: 0.122618 |\n",
      "Training epoch: 54 [1900/2000 (95%)] | D loss (A): 0.226795 | D loss (B): 0.192297 | G loss: 1.695952 | Consistency: 0.096033 |\n",
      "Training epoch: 55 [0/2000 (0%)] | D loss (A): 0.144032 | D loss (B): 0.167434 | G loss: 1.863793 | Consistency: 0.118467 |\n",
      "Training epoch: 55 [100/2000 (5%)] | D loss (A): 0.207147 | D loss (B): 0.133835 | G loss: 2.013552 | Consistency: 0.095921 |\n",
      "Training epoch: 55 [200/2000 (10%)] | D loss (A): 0.084081 | D loss (B): 0.151078 | G loss: 1.774874 | Consistency: 0.091497 |\n",
      "Training epoch: 55 [300/2000 (15%)] | D loss (A): 0.069411 | D loss (B): 0.058165 | G loss: 1.458649 | Consistency: 0.084688 |\n",
      "Training epoch: 55 [400/2000 (20%)] | D loss (A): 0.139113 | D loss (B): 0.234760 | G loss: 2.270570 | Consistency: 0.101569 |\n",
      "Training epoch: 55 [500/2000 (25%)] | D loss (A): 0.157254 | D loss (B): 0.264558 | G loss: 1.481413 | Consistency: 0.082067 |\n",
      "Training epoch: 55 [600/2000 (30%)] | D loss (A): 0.165060 | D loss (B): 0.058436 | G loss: 2.450943 | Consistency: 0.137147 |\n",
      "Training epoch: 55 [700/2000 (35%)] | D loss (A): 0.046144 | D loss (B): 0.137389 | G loss: 1.867494 | Consistency: 0.098825 |\n",
      "Training epoch: 55 [800/2000 (40%)] | D loss (A): 0.128217 | D loss (B): 0.127751 | G loss: 1.950043 | Consistency: 0.100548 |\n",
      "Training epoch: 55 [900/2000 (45%)] | D loss (A): 0.134478 | D loss (B): 0.089415 | G loss: 2.280676 | Consistency: 0.115024 |\n",
      "Training epoch: 55 [1000/2000 (50%)] | D loss (A): 0.227944 | D loss (B): 0.189399 | G loss: 1.709770 | Consistency: 0.083680 |\n",
      "Training epoch: 55 [1100/2000 (55%)] | D loss (A): 0.343533 | D loss (B): 0.076989 | G loss: 2.274032 | Consistency: 0.120702 |\n",
      "Training epoch: 55 [1200/2000 (60%)] | D loss (A): 0.178615 | D loss (B): 0.138432 | G loss: 1.964711 | Consistency: 0.108013 |\n",
      "Training epoch: 55 [1300/2000 (65%)] | D loss (A): 0.187108 | D loss (B): 0.122394 | G loss: 1.938541 | Consistency: 0.106054 |\n",
      "Training epoch: 55 [1400/2000 (70%)] | D loss (A): 0.181763 | D loss (B): 0.099899 | G loss: 2.203472 | Consistency: 0.097302 |\n",
      "Training epoch: 55 [1500/2000 (75%)] | D loss (A): 0.209811 | D loss (B): 0.086858 | G loss: 1.601789 | Consistency: 0.106652 |\n",
      "Training epoch: 55 [1600/2000 (80%)] | D loss (A): 0.156680 | D loss (B): 0.103995 | G loss: 1.745998 | Consistency: 0.100901 |\n",
      "Training epoch: 55 [1700/2000 (85%)] | D loss (A): 0.111116 | D loss (B): 0.092261 | G loss: 1.848611 | Consistency: 0.106037 |\n",
      "Training epoch: 55 [1800/2000 (90%)] | D loss (A): 0.201465 | D loss (B): 0.076537 | G loss: 1.967741 | Consistency: 0.082543 |\n",
      "Training epoch: 55 [1900/2000 (95%)] | D loss (A): 0.171545 | D loss (B): 0.183542 | G loss: 1.999788 | Consistency: 0.090334 |\n",
      "Training epoch: 56 [0/2000 (0%)] | D loss (A): 0.203715 | D loss (B): 0.086746 | G loss: 2.805424 | Consistency: 0.120648 |\n",
      "Training epoch: 56 [100/2000 (5%)] | D loss (A): 0.178787 | D loss (B): 0.177510 | G loss: 1.605621 | Consistency: 0.071991 |\n",
      "Training epoch: 56 [200/2000 (10%)] | D loss (A): 0.130638 | D loss (B): 0.094302 | G loss: 2.369024 | Consistency: 0.098300 |\n",
      "Training epoch: 56 [300/2000 (15%)] | D loss (A): 0.124011 | D loss (B): 0.108393 | G loss: 1.167234 | Consistency: 0.084493 |\n",
      "Training epoch: 56 [400/2000 (20%)] | D loss (A): 0.268039 | D loss (B): 0.088144 | G loss: 2.535941 | Consistency: 0.087290 |\n",
      "Training epoch: 56 [500/2000 (25%)] | D loss (A): 0.166535 | D loss (B): 0.137778 | G loss: 2.064262 | Consistency: 0.122259 |\n",
      "Training epoch: 56 [600/2000 (30%)] | D loss (A): 0.123931 | D loss (B): 0.048923 | G loss: 1.878174 | Consistency: 0.092367 |\n",
      "Training epoch: 56 [700/2000 (35%)] | D loss (A): 0.169284 | D loss (B): 0.114344 | G loss: 2.317264 | Consistency: 0.117403 |\n",
      "Training epoch: 56 [800/2000 (40%)] | D loss (A): 0.096370 | D loss (B): 0.060595 | G loss: 2.092954 | Consistency: 0.073679 |\n",
      "Training epoch: 56 [900/2000 (45%)] | D loss (A): 0.152783 | D loss (B): 0.093008 | G loss: 2.274543 | Consistency: 0.111454 |\n",
      "Training epoch: 56 [1000/2000 (50%)] | D loss (A): 0.200586 | D loss (B): 0.034646 | G loss: 1.733618 | Consistency: 0.123428 |\n",
      "Training epoch: 56 [1100/2000 (55%)] | D loss (A): 0.166611 | D loss (B): 0.339325 | G loss: 2.351832 | Consistency: 0.114074 |\n",
      "Training epoch: 56 [1200/2000 (60%)] | D loss (A): 0.286486 | D loss (B): 0.109004 | G loss: 1.992309 | Consistency: 0.088067 |\n",
      "Training epoch: 56 [1300/2000 (65%)] | D loss (A): 0.377509 | D loss (B): 0.088303 | G loss: 1.750024 | Consistency: 0.117023 |\n",
      "Training epoch: 56 [1400/2000 (70%)] | D loss (A): 0.190832 | D loss (B): 0.162728 | G loss: 2.749523 | Consistency: 0.122721 |\n",
      "Training epoch: 56 [1500/2000 (75%)] | D loss (A): 0.312552 | D loss (B): 0.061832 | G loss: 1.994790 | Consistency: 0.110622 |\n",
      "Training epoch: 56 [1600/2000 (80%)] | D loss (A): 0.172470 | D loss (B): 0.255676 | G loss: 2.391084 | Consistency: 0.142538 |\n",
      "Training epoch: 56 [1900/2000 (95%)] | D loss (A): 0.169342 | D loss (B): 0.057243 | G loss: 2.040544 | Consistency: 0.089744 |\n",
      "Training epoch: 57 [0/2000 (0%)] | D loss (A): 0.139993 | D loss (B): 0.253861 | G loss: 2.044333 | Consistency: 0.098955 |\n",
      "Training epoch: 57 [100/2000 (5%)] | D loss (A): 0.232447 | D loss (B): 0.054310 | G loss: 2.213094 | Consistency: 0.117063 |\n",
      "Training epoch: 57 [200/2000 (10%)] | D loss (A): 0.217507 | D loss (B): 0.131775 | G loss: 1.562740 | Consistency: 0.104047 |\n",
      "Training epoch: 57 [300/2000 (15%)] | D loss (A): 0.284462 | D loss (B): 0.279638 | G loss: 2.308032 | Consistency: 0.113216 |\n",
      "Training epoch: 57 [400/2000 (20%)] | D loss (A): 0.160024 | D loss (B): 0.036957 | G loss: 2.359650 | Consistency: 0.123654 |\n",
      "Training epoch: 57 [500/2000 (25%)] | D loss (A): 0.282250 | D loss (B): 0.133664 | G loss: 2.642306 | Consistency: 0.142178 |\n",
      "Training epoch: 57 [600/2000 (30%)] | D loss (A): 0.227475 | D loss (B): 0.130968 | G loss: 1.821159 | Consistency: 0.087768 |\n",
      "Training epoch: 57 [700/2000 (35%)] | D loss (A): 0.103566 | D loss (B): 0.250859 | G loss: 2.630780 | Consistency: 0.115888 |\n",
      "Training epoch: 57 [800/2000 (40%)] | D loss (A): 0.116369 | D loss (B): 0.109348 | G loss: 2.459033 | Consistency: 0.129306 |\n",
      "Training epoch: 57 [900/2000 (45%)] | D loss (A): 0.131287 | D loss (B): 0.041152 | G loss: 1.791146 | Consistency: 0.122938 |\n",
      "Training epoch: 57 [1000/2000 (50%)] | D loss (A): 0.186275 | D loss (B): 0.224225 | G loss: 2.262103 | Consistency: 0.106078 |\n",
      "Training epoch: 57 [1100/2000 (55%)] | D loss (A): 0.182811 | D loss (B): 0.206461 | G loss: 2.109842 | Consistency: 0.090285 |\n",
      "Training epoch: 57 [1200/2000 (60%)] | D loss (A): 0.094232 | D loss (B): 0.097089 | G loss: 2.649022 | Consistency: 0.106258 |\n",
      "Training epoch: 57 [1300/2000 (65%)] | D loss (A): 0.129455 | D loss (B): 0.137332 | G loss: 1.905877 | Consistency: 0.094359 |\n",
      "Training epoch: 57 [1400/2000 (70%)] | D loss (A): 0.099516 | D loss (B): 0.462159 | G loss: 1.973357 | Consistency: 0.095897 |\n",
      "Training epoch: 57 [1500/2000 (75%)] | D loss (A): 0.223211 | D loss (B): 0.161648 | G loss: 2.727875 | Consistency: 0.109121 |\n",
      "Training epoch: 57 [1600/2000 (80%)] | D loss (A): 0.085470 | D loss (B): 0.181232 | G loss: 2.476623 | Consistency: 0.103496 |\n",
      "Training epoch: 57 [1700/2000 (85%)] | D loss (A): 0.174674 | D loss (B): 0.206197 | G loss: 2.483487 | Consistency: 0.121371 |\n",
      "Training epoch: 57 [1800/2000 (90%)] | D loss (A): 0.094800 | D loss (B): 0.093244 | G loss: 2.429581 | Consistency: 0.119410 |\n",
      "Training epoch: 57 [1900/2000 (95%)] | D loss (A): 0.352041 | D loss (B): 0.135162 | G loss: 2.017166 | Consistency: 0.101603 |\n",
      "Training epoch: 58 [0/2000 (0%)] | D loss (A): 0.113871 | D loss (B): 0.203723 | G loss: 1.587708 | Consistency: 0.095604 |\n",
      "Training epoch: 58 [100/2000 (5%)] | D loss (A): 0.135840 | D loss (B): 0.195738 | G loss: 1.614321 | Consistency: 0.082918 |\n",
      "Training epoch: 58 [200/2000 (10%)] | D loss (A): 0.418768 | D loss (B): 0.128860 | G loss: 2.229790 | Consistency: 0.091616 |\n",
      "Training epoch: 58 [300/2000 (15%)] | D loss (A): 0.294794 | D loss (B): 0.077962 | G loss: 2.758572 | Consistency: 0.120115 |\n",
      "Training epoch: 58 [400/2000 (20%)] | D loss (A): 0.213958 | D loss (B): 0.174237 | G loss: 1.839768 | Consistency: 0.111921 |\n",
      "Training epoch: 58 [500/2000 (25%)] | D loss (A): 0.236685 | D loss (B): 0.191605 | G loss: 2.311232 | Consistency: 0.099147 |\n",
      "Training epoch: 58 [600/2000 (30%)] | D loss (A): 0.098693 | D loss (B): 0.119526 | G loss: 2.354339 | Consistency: 0.129050 |\n",
      "Training epoch: 58 [700/2000 (35%)] | D loss (A): 0.226235 | D loss (B): 0.163294 | G loss: 2.409006 | Consistency: 0.106402 |\n",
      "Training epoch: 58 [800/2000 (40%)] | D loss (A): 0.341576 | D loss (B): 0.063400 | G loss: 2.055122 | Consistency: 0.124002 |\n",
      "Training epoch: 58 [900/2000 (45%)] | D loss (A): 0.112770 | D loss (B): 0.085659 | G loss: 2.173125 | Consistency: 0.139804 |\n",
      "Training epoch: 58 [1000/2000 (50%)] | D loss (A): 0.166791 | D loss (B): 0.146319 | G loss: 1.865907 | Consistency: 0.093090 |\n",
      "Training epoch: 58 [1100/2000 (55%)] | D loss (A): 0.199141 | D loss (B): 0.151736 | G loss: 1.603877 | Consistency: 0.087020 |\n",
      "Training epoch: 58 [1200/2000 (60%)] | D loss (A): 0.297245 | D loss (B): 0.149965 | G loss: 2.100813 | Consistency: 0.087809 |\n",
      "Training epoch: 58 [1300/2000 (65%)] | D loss (A): 0.178166 | D loss (B): 0.112900 | G loss: 2.059577 | Consistency: 0.099975 |\n",
      "Training epoch: 58 [1400/2000 (70%)] | D loss (A): 0.124327 | D loss (B): 41.083019 | G loss: 11.617271 | Consistency: 0.215440 |\n",
      "Training epoch: 58 [1500/2000 (75%)] | D loss (A): 0.212309 | D loss (B): 0.179418 | G loss: 1.906150 | Consistency: 0.121026 |\n",
      "Training epoch: 58 [1600/2000 (80%)] | D loss (A): 0.258309 | D loss (B): 0.267767 | G loss: 2.117902 | Consistency: 0.134110 |\n",
      "Training epoch: 58 [1700/2000 (85%)] | D loss (A): 0.196460 | D loss (B): 0.266246 | G loss: 1.869396 | Consistency: 0.135515 |\n",
      "Training epoch: 58 [1800/2000 (90%)] | D loss (A): 0.187671 | D loss (B): 0.293034 | G loss: 1.533305 | Consistency: 0.104132 |\n",
      "Training epoch: 58 [1900/2000 (95%)] | D loss (A): 0.299209 | D loss (B): 0.230519 | G loss: 1.344481 | Consistency: 0.091809 |\n",
      "Training epoch: 59 [0/2000 (0%)] | D loss (A): 0.229149 | D loss (B): 0.197359 | G loss: 1.409727 | Consistency: 0.099390 |\n",
      "Training epoch: 59 [100/2000 (5%)] | D loss (A): 0.186385 | D loss (B): 0.238726 | G loss: 1.273959 | Consistency: 0.078696 |\n",
      "Training epoch: 59 [200/2000 (10%)] | D loss (A): 0.222036 | D loss (B): 0.196243 | G loss: 1.454192 | Consistency: 0.090999 |\n",
      "Training epoch: 59 [300/2000 (15%)] | D loss (A): 0.169849 | D loss (B): 0.325852 | G loss: 1.206865 | Consistency: 0.073769 |\n",
      "Training epoch: 59 [400/2000 (20%)] | D loss (A): 0.179521 | D loss (B): 0.215558 | G loss: 1.172251 | Consistency: 0.063046 |\n",
      "Training epoch: 59 [500/2000 (25%)] | D loss (A): 0.215688 | D loss (B): 0.262693 | G loss: 1.193097 | Consistency: 0.060490 |\n",
      "Training epoch: 59 [600/2000 (30%)] | D loss (A): 0.266034 | D loss (B): 0.240112 | G loss: 1.241051 | Consistency: 0.071553 |\n",
      "Training epoch: 59 [700/2000 (35%)] | D loss (A): 0.129493 | D loss (B): 0.212523 | G loss: 1.838594 | Consistency: 0.124471 |\n",
      "Training epoch: 59 [800/2000 (40%)] | D loss (A): 0.239213 | D loss (B): 0.251912 | G loss: 1.424309 | Consistency: 0.092618 |\n",
      "Training epoch: 59 [900/2000 (45%)] | D loss (A): 0.136284 | D loss (B): 0.228976 | G loss: 1.647728 | Consistency: 0.109340 |\n",
      "Training epoch: 59 [1000/2000 (50%)] | D loss (A): 0.113695 | D loss (B): 0.142383 | G loss: 1.587657 | Consistency: 0.103795 |\n",
      "Training epoch: 59 [1100/2000 (55%)] | D loss (A): 0.155884 | D loss (B): 0.180652 | G loss: 1.799363 | Consistency: 0.105730 |\n",
      "Training epoch: 59 [1200/2000 (60%)] | D loss (A): 0.100316 | D loss (B): 0.089896 | G loss: 1.435243 | Consistency: 0.091573 |\n",
      "Training epoch: 59 [1300/2000 (65%)] | D loss (A): 0.261629 | D loss (B): 0.228305 | G loss: 1.474648 | Consistency: 0.076246 |\n",
      "Training epoch: 59 [1400/2000 (70%)] | D loss (A): 0.094723 | D loss (B): 0.271642 | G loss: 1.379776 | Consistency: 0.083826 |\n",
      "Training epoch: 59 [1500/2000 (75%)] | D loss (A): 0.091519 | D loss (B): 0.351100 | G loss: 1.337064 | Consistency: 0.082988 |\n",
      "Training epoch: 59 [1600/2000 (80%)] | D loss (A): 0.138983 | D loss (B): 0.169011 | G loss: 1.772551 | Consistency: 0.083681 |\n",
      "Training epoch: 59 [1700/2000 (85%)] | D loss (A): 0.322347 | D loss (B): 0.206139 | G loss: 2.000763 | Consistency: 0.115223 |\n",
      "Training epoch: 59 [1800/2000 (90%)] | D loss (A): 0.294827 | D loss (B): 0.112967 | G loss: 1.526808 | Consistency: 0.080309 |\n",
      "Training epoch: 59 [1900/2000 (95%)] | D loss (A): 0.225867 | D loss (B): 0.275804 | G loss: 1.761734 | Consistency: 0.080616 |\n",
      "Training epoch: 60 [0/2000 (0%)] | D loss (A): 0.253741 | D loss (B): 0.081398 | G loss: 1.437026 | Consistency: 0.078150 |\n",
      "Training epoch: 60 [100/2000 (5%)] | D loss (A): 0.272620 | D loss (B): 0.022891 | G loss: 2.030762 | Consistency: 0.108813 |\n",
      "Training epoch: 60 [200/2000 (10%)] | D loss (A): 0.136498 | D loss (B): 0.077819 | G loss: 1.738617 | Consistency: 0.078768 |\n",
      "Training epoch: 60 [300/2000 (15%)] | D loss (A): 0.100417 | D loss (B): 0.166297 | G loss: 1.782085 | Consistency: 0.104156 |\n",
      "Training epoch: 60 [400/2000 (20%)] | D loss (A): 0.120040 | D loss (B): 0.048535 | G loss: 2.374022 | Consistency: 0.115151 |\n",
      "Training epoch: 60 [500/2000 (25%)] | D loss (A): 0.322714 | D loss (B): 0.258527 | G loss: 1.781185 | Consistency: 0.093550 |\n",
      "Training epoch: 60 [600/2000 (30%)] | D loss (A): 0.262953 | D loss (B): 0.122677 | G loss: 1.593880 | Consistency: 0.081651 |\n",
      "Training epoch: 60 [700/2000 (35%)] | D loss (A): 0.146271 | D loss (B): 0.145477 | G loss: 1.622103 | Consistency: 0.084551 |\n",
      "Training epoch: 60 [800/2000 (40%)] | D loss (A): 0.146042 | D loss (B): 0.024694 | G loss: 1.406014 | Consistency: 0.068564 |\n",
      "Training epoch: 60 [900/2000 (45%)] | D loss (A): 0.191424 | D loss (B): 0.100346 | G loss: 1.902141 | Consistency: 0.096506 |\n",
      "Training epoch: 60 [1000/2000 (50%)] | D loss (A): 0.225606 | D loss (B): 0.102551 | G loss: 1.883108 | Consistency: 0.100915 |\n",
      "Training epoch: 60 [1100/2000 (55%)] | D loss (A): 0.175123 | D loss (B): 0.115204 | G loss: 1.071637 | Consistency: 0.078973 |\n",
      "Training epoch: 60 [1200/2000 (60%)] | D loss (A): 0.117504 | D loss (B): 0.222255 | G loss: 2.365881 | Consistency: 0.091236 |\n",
      "Training epoch: 60 [1300/2000 (65%)] | D loss (A): 0.221532 | D loss (B): 0.155803 | G loss: 1.549862 | Consistency: 0.088174 |\n",
      "Training epoch: 60 [1400/2000 (70%)] | D loss (A): 0.157127 | D loss (B): 0.067289 | G loss: 1.706920 | Consistency: 0.081561 |\n",
      "Training epoch: 60 [1500/2000 (75%)] | D loss (A): 0.090787 | D loss (B): 0.076651 | G loss: 1.406928 | Consistency: 0.090397 |\n",
      "Training epoch: 60 [1600/2000 (80%)] | D loss (A): 0.118108 | D loss (B): 0.198488 | G loss: 2.558742 | Consistency: 0.120762 |\n",
      "Training epoch: 60 [1700/2000 (85%)] | D loss (A): 0.388585 | D loss (B): 0.087419 | G loss: 2.253384 | Consistency: 0.108533 |\n",
      "Training epoch: 60 [1800/2000 (90%)] | D loss (A): 0.191927 | D loss (B): 0.133634 | G loss: 1.819254 | Consistency: 0.083633 |\n",
      "Training epoch: 60 [1900/2000 (95%)] | D loss (A): 0.112592 | D loss (B): 0.132952 | G loss: 1.777509 | Consistency: 0.072723 |\n",
      "Training epoch: 61 [0/2000 (0%)] | D loss (A): 0.274143 | D loss (B): 0.248520 | G loss: 1.872600 | Consistency: 0.083448 |\n",
      "Training epoch: 61 [100/2000 (5%)] | D loss (A): 0.168747 | D loss (B): 0.104645 | G loss: 2.129076 | Consistency: 0.119383 |\n",
      "Training epoch: 61 [200/2000 (10%)] | D loss (A): 0.178840 | D loss (B): 0.094986 | G loss: 1.717741 | Consistency: 0.081557 |\n",
      "Training epoch: 61 [300/2000 (15%)] | D loss (A): 0.275128 | D loss (B): 0.197451 | G loss: 2.119367 | Consistency: 0.104104 |\n",
      "Training epoch: 61 [400/2000 (20%)] | D loss (A): 0.237295 | D loss (B): 0.224692 | G loss: 2.205435 | Consistency: 0.124318 |\n",
      "Training epoch: 61 [500/2000 (25%)] | D loss (A): 0.115309 | D loss (B): 0.233016 | G loss: 1.754932 | Consistency: 0.096744 |\n",
      "Training epoch: 61 [600/2000 (30%)] | D loss (A): 0.244555 | D loss (B): 0.104138 | G loss: 1.703543 | Consistency: 0.087240 |\n",
      "Training epoch: 61 [700/2000 (35%)] | D loss (A): 0.213698 | D loss (B): 0.340680 | G loss: 3.094893 | Consistency: 0.128130 |\n",
      "Training epoch: 61 [800/2000 (40%)] | D loss (A): 0.112693 | D loss (B): 0.252013 | G loss: 2.113143 | Consistency: 0.095231 |\n",
      "Training epoch: 61 [900/2000 (45%)] | D loss (A): 0.091237 | D loss (B): 0.083041 | G loss: 2.038147 | Consistency: 0.129450 |\n",
      "Training epoch: 61 [1000/2000 (50%)] | D loss (A): 0.139486 | D loss (B): 0.063851 | G loss: 2.202929 | Consistency: 0.122618 |\n",
      "Training epoch: 61 [1100/2000 (55%)] | D loss (A): 0.154506 | D loss (B): 0.066609 | G loss: 2.007915 | Consistency: 0.128735 |\n",
      "Training epoch: 61 [1200/2000 (60%)] | D loss (A): 0.180863 | D loss (B): 0.042581 | G loss: 1.571364 | Consistency: 0.085290 |\n",
      "Training epoch: 61 [1300/2000 (65%)] | D loss (A): 0.163426 | D loss (B): 0.180579 | G loss: 2.120492 | Consistency: 0.108743 |\n",
      "Training epoch: 61 [1400/2000 (70%)] | D loss (A): 0.289861 | D loss (B): 0.243476 | G loss: 1.857434 | Consistency: 0.093367 |\n",
      "Training epoch: 61 [1500/2000 (75%)] | D loss (A): 0.315289 | D loss (B): 0.127899 | G loss: 1.724232 | Consistency: 0.084475 |\n",
      "Training epoch: 61 [1600/2000 (80%)] | D loss (A): 0.167755 | D loss (B): 0.038565 | G loss: 1.915277 | Consistency: 0.105181 |\n",
      "Training epoch: 61 [1700/2000 (85%)] | D loss (A): 0.257611 | D loss (B): 0.165999 | G loss: 2.278395 | Consistency: 0.111336 |\n",
      "Training epoch: 61 [1800/2000 (90%)] | D loss (A): 0.090327 | D loss (B): 0.225474 | G loss: 1.935945 | Consistency: 0.075450 |\n",
      "Training epoch: 61 [1900/2000 (95%)] | D loss (A): 0.144330 | D loss (B): 0.208703 | G loss: 1.881533 | Consistency: 0.106078 |\n",
      "Training epoch: 62 [0/2000 (0%)] | D loss (A): 0.251870 | D loss (B): 0.142523 | G loss: 1.923959 | Consistency: 0.096249 |\n",
      "Training epoch: 62 [100/2000 (5%)] | D loss (A): 0.234195 | D loss (B): 0.207201 | G loss: 1.763661 | Consistency: 0.093270 |\n",
      "Training epoch: 62 [200/2000 (10%)] | D loss (A): 0.194493 | D loss (B): 0.088984 | G loss: 2.370179 | Consistency: 0.110982 |\n",
      "Training epoch: 62 [300/2000 (15%)] | D loss (A): 0.277736 | D loss (B): 0.092578 | G loss: 2.436158 | Consistency: 0.144634 |\n",
      "Training epoch: 62 [400/2000 (20%)] | D loss (A): 0.235416 | D loss (B): 0.037294 | G loss: 2.666601 | Consistency: 0.139087 |\n",
      "Training epoch: 62 [500/2000 (25%)] | D loss (A): 0.286049 | D loss (B): 0.222591 | G loss: 1.662977 | Consistency: 0.083564 |\n",
      "Training epoch: 62 [600/2000 (30%)] | D loss (A): 0.197681 | D loss (B): 0.107853 | G loss: 1.899050 | Consistency: 0.110515 |\n",
      "Training epoch: 62 [700/2000 (35%)] | D loss (A): 0.286378 | D loss (B): 0.033182 | G loss: 1.698351 | Consistency: 0.102239 |\n",
      "Training epoch: 62 [800/2000 (40%)] | D loss (A): 0.289678 | D loss (B): 0.071985 | G loss: 1.898128 | Consistency: 0.142293 |\n",
      "Training epoch: 62 [900/2000 (45%)] | D loss (A): 0.257319 | D loss (B): 0.134288 | G loss: 2.276413 | Consistency: 0.135008 |\n",
      "Training epoch: 62 [1000/2000 (50%)] | D loss (A): 0.239593 | D loss (B): 0.176337 | G loss: 1.424920 | Consistency: 0.090094 |\n",
      "Training epoch: 62 [1100/2000 (55%)] | D loss (A): 0.226097 | D loss (B): 0.185957 | G loss: 1.785533 | Consistency: 0.109297 |\n",
      "Training epoch: 62 [1200/2000 (60%)] | D loss (A): 0.174260 | D loss (B): 0.095971 | G loss: 1.619739 | Consistency: 0.102250 |\n",
      "Training epoch: 62 [1300/2000 (65%)] | D loss (A): 0.252582 | D loss (B): 0.175924 | G loss: 1.555983 | Consistency: 0.104117 |\n",
      "Training epoch: 62 [1400/2000 (70%)] | D loss (A): 0.286193 | D loss (B): 0.079513 | G loss: 1.471536 | Consistency: 0.090948 |\n",
      "Training epoch: 62 [1500/2000 (75%)] | D loss (A): 0.247139 | D loss (B): 0.106389 | G loss: 2.594125 | Consistency: 0.118229 |\n",
      "Training epoch: 62 [1600/2000 (80%)] | D loss (A): 0.320259 | D loss (B): 0.174021 | G loss: 1.422334 | Consistency: 0.071109 |\n",
      "Training epoch: 62 [1700/2000 (85%)] | D loss (A): 0.220204 | D loss (B): 0.203138 | G loss: 1.657125 | Consistency: 0.079933 |\n",
      "Training epoch: 62 [1800/2000 (90%)] | D loss (A): 0.199434 | D loss (B): 0.147417 | G loss: 1.728073 | Consistency: 0.103614 |\n",
      "Training epoch: 62 [1900/2000 (95%)] | D loss (A): 0.186010 | D loss (B): 0.148816 | G loss: 1.683080 | Consistency: 0.084200 |\n",
      "Training epoch: 63 [0/2000 (0%)] | D loss (A): 0.214147 | D loss (B): 0.107293 | G loss: 1.684218 | Consistency: 0.094608 |\n",
      "Training epoch: 63 [100/2000 (5%)] | D loss (A): 0.165819 | D loss (B): 0.155638 | G loss: 1.882542 | Consistency: 0.093685 |\n",
      "Training epoch: 63 [200/2000 (10%)] | D loss (A): 0.246996 | D loss (B): 0.095118 | G loss: 1.579286 | Consistency: 0.066031 |\n",
      "Training epoch: 63 [300/2000 (15%)] | D loss (A): 0.133681 | D loss (B): 0.173946 | G loss: 1.440431 | Consistency: 0.076796 |\n",
      "Training epoch: 63 [400/2000 (20%)] | D loss (A): 0.305092 | D loss (B): 0.078513 | G loss: 1.230084 | Consistency: 0.082266 |\n",
      "Training epoch: 63 [500/2000 (25%)] | D loss (A): 0.224876 | D loss (B): 0.185044 | G loss: 2.176991 | Consistency: 0.097766 |\n",
      "Training epoch: 63 [600/2000 (30%)] | D loss (A): 0.141536 | D loss (B): 0.129818 | G loss: 2.171074 | Consistency: 0.112574 |\n",
      "Training epoch: 63 [700/2000 (35%)] | D loss (A): 0.208148 | D loss (B): 0.202701 | G loss: 1.428711 | Consistency: 0.080739 |\n",
      "Training epoch: 63 [800/2000 (40%)] | D loss (A): 0.230891 | D loss (B): 0.139653 | G loss: 2.009791 | Consistency: 0.096556 |\n",
      "Training epoch: 63 [900/2000 (45%)] | D loss (A): 0.250500 | D loss (B): 0.089784 | G loss: 1.900676 | Consistency: 0.102576 |\n",
      "Training epoch: 63 [1000/2000 (50%)] | D loss (A): 0.206158 | D loss (B): 0.241280 | G loss: 2.338708 | Consistency: 0.110831 |\n",
      "Training epoch: 63 [1100/2000 (55%)] | D loss (A): 0.144940 | D loss (B): 0.058715 | G loss: 1.826332 | Consistency: 0.106940 |\n",
      "Training epoch: 63 [1200/2000 (60%)] | D loss (A): 0.121411 | D loss (B): 0.091249 | G loss: 1.542860 | Consistency: 0.104937 |\n",
      "Training epoch: 63 [1300/2000 (65%)] | D loss (A): 0.092084 | D loss (B): 0.132353 | G loss: 2.241510 | Consistency: 0.113467 |\n",
      "Training epoch: 63 [1400/2000 (70%)] | D loss (A): 0.110859 | D loss (B): 0.164573 | G loss: 1.913555 | Consistency: 0.099195 |\n",
      "Training epoch: 63 [1500/2000 (75%)] | D loss (A): 0.194429 | D loss (B): 0.181411 | G loss: 1.427576 | Consistency: 0.064907 |\n",
      "Training epoch: 63 [1600/2000 (80%)] | D loss (A): 0.181439 | D loss (B): 0.132434 | G loss: 2.382075 | Consistency: 0.125073 |\n",
      "Training epoch: 63 [1700/2000 (85%)] | D loss (A): 0.176297 | D loss (B): 0.214987 | G loss: 1.907062 | Consistency: 0.108227 |\n",
      "Training epoch: 63 [1800/2000 (90%)] | D loss (A): 0.097449 | D loss (B): 0.035220 | G loss: 3.516814 | Consistency: 0.194378 |\n",
      "Training epoch: 63 [1900/2000 (95%)] | D loss (A): 0.070607 | D loss (B): 0.230732 | G loss: 1.644099 | Consistency: 0.128836 |\n",
      "Training epoch: 64 [0/2000 (0%)] | D loss (A): 0.156081 | D loss (B): 0.091828 | G loss: 2.915938 | Consistency: 0.119299 |\n",
      "Training epoch: 64 [100/2000 (5%)] | D loss (A): 0.140688 | D loss (B): 0.125951 | G loss: 2.663832 | Consistency: 0.144844 |\n",
      "Training epoch: 64 [200/2000 (10%)] | D loss (A): 0.176660 | D loss (B): 0.086944 | G loss: 1.650946 | Consistency: 0.082919 |\n",
      "Training epoch: 64 [300/2000 (15%)] | D loss (A): 0.223892 | D loss (B): 0.144032 | G loss: 2.163047 | Consistency: 0.141408 |\n",
      "Training epoch: 64 [400/2000 (20%)] | D loss (A): 0.163528 | D loss (B): 0.128350 | G loss: 2.376225 | Consistency: 0.101458 |\n",
      "Training epoch: 64 [500/2000 (25%)] | D loss (A): 0.218246 | D loss (B): 0.146114 | G loss: 1.291662 | Consistency: 0.064892 |\n",
      "Training epoch: 64 [600/2000 (30%)] | D loss (A): 0.107906 | D loss (B): 0.145219 | G loss: 1.892628 | Consistency: 0.105440 |\n",
      "Training epoch: 64 [700/2000 (35%)] | D loss (A): 0.223117 | D loss (B): 0.223537 | G loss: 2.162904 | Consistency: 0.086879 |\n",
      "Training epoch: 64 [800/2000 (40%)] | D loss (A): 0.232705 | D loss (B): 0.210074 | G loss: 1.381539 | Consistency: 0.091160 |\n",
      "Training epoch: 64 [900/2000 (45%)] | D loss (A): 0.097161 | D loss (B): 0.136086 | G loss: 2.066517 | Consistency: 0.074868 |\n",
      "Training epoch: 64 [1000/2000 (50%)] | D loss (A): 0.168871 | D loss (B): 0.141811 | G loss: 2.157656 | Consistency: 0.114026 |\n",
      "Training epoch: 64 [1100/2000 (55%)] | D loss (A): 0.081745 | D loss (B): 0.432819 | G loss: 1.876253 | Consistency: 0.085803 |\n",
      "Training epoch: 64 [1200/2000 (60%)] | D loss (A): 0.158808 | D loss (B): 0.113081 | G loss: 2.718826 | Consistency: 0.123095 |\n",
      "Training epoch: 64 [1300/2000 (65%)] | D loss (A): 0.217963 | D loss (B): 0.054259 | G loss: 2.057230 | Consistency: 0.106440 |\n",
      "Training epoch: 64 [1400/2000 (70%)] | D loss (A): 0.178122 | D loss (B): 0.103877 | G loss: 1.298829 | Consistency: 0.075841 |\n",
      "Training epoch: 64 [1500/2000 (75%)] | D loss (A): 0.174421 | D loss (B): 0.186978 | G loss: 2.352097 | Consistency: 0.102300 |\n",
      "Training epoch: 64 [1600/2000 (80%)] | D loss (A): 0.209454 | D loss (B): 0.260713 | G loss: 1.736064 | Consistency: 0.088619 |\n",
      "Training epoch: 64 [1700/2000 (85%)] | D loss (A): 0.207868 | D loss (B): 0.097410 | G loss: 2.070970 | Consistency: 0.096155 |\n",
      "Training epoch: 64 [1800/2000 (90%)] | D loss (A): 0.099245 | D loss (B): 0.099638 | G loss: 1.799532 | Consistency: 0.104826 |\n",
      "Training epoch: 64 [1900/2000 (95%)] | D loss (A): 0.055516 | D loss (B): 0.170046 | G loss: 1.724468 | Consistency: 0.069436 |\n",
      "Training epoch: 65 [0/2000 (0%)] | D loss (A): 0.057145 | D loss (B): 0.094456 | G loss: 1.856870 | Consistency: 0.122867 |\n",
      "Training epoch: 65 [100/2000 (5%)] | D loss (A): 0.160778 | D loss (B): 0.191811 | G loss: 2.243543 | Consistency: 0.129033 |\n",
      "Training epoch: 65 [200/2000 (10%)] | D loss (A): 0.197638 | D loss (B): 0.167565 | G loss: 1.800337 | Consistency: 0.078206 |\n",
      "Training epoch: 65 [300/2000 (15%)] | D loss (A): 0.069031 | D loss (B): 0.159280 | G loss: 1.752865 | Consistency: 0.070659 |\n",
      "Training epoch: 65 [400/2000 (20%)] | D loss (A): 0.111428 | D loss (B): 0.053331 | G loss: 1.848205 | Consistency: 0.108631 |\n",
      "Training epoch: 65 [500/2000 (25%)] | D loss (A): 0.319199 | D loss (B): 0.099404 | G loss: 1.971885 | Consistency: 0.090266 |\n",
      "Training epoch: 65 [600/2000 (30%)] | D loss (A): 0.147158 | D loss (B): 0.077808 | G loss: 2.311251 | Consistency: 0.111679 |\n",
      "Training epoch: 65 [700/2000 (35%)] | D loss (A): 0.248723 | D loss (B): 0.127290 | G loss: 1.852010 | Consistency: 0.115414 |\n",
      "Training epoch: 65 [800/2000 (40%)] | D loss (A): 0.178011 | D loss (B): 0.157043 | G loss: 1.946973 | Consistency: 0.112449 |\n",
      "Training epoch: 65 [900/2000 (45%)] | D loss (A): 0.254437 | D loss (B): 0.240492 | G loss: 2.199259 | Consistency: 0.124970 |\n",
      "Training epoch: 65 [1000/2000 (50%)] | D loss (A): 0.234356 | D loss (B): 0.186731 | G loss: 1.712501 | Consistency: 0.112765 |\n",
      "Training epoch: 65 [1100/2000 (55%)] | D loss (A): 0.248531 | D loss (B): 0.110710 | G loss: 2.440822 | Consistency: 0.110086 |\n",
      "Training epoch: 65 [1200/2000 (60%)] | D loss (A): 0.150794 | D loss (B): 0.040776 | G loss: 1.989472 | Consistency: 0.106095 |\n",
      "Training epoch: 65 [1300/2000 (65%)] | D loss (A): 0.158107 | D loss (B): 0.184214 | G loss: 2.005286 | Consistency: 0.105123 |\n",
      "Training epoch: 65 [1400/2000 (70%)] | D loss (A): 0.133559 | D loss (B): 0.059115 | G loss: 1.991770 | Consistency: 0.128117 |\n",
      "Training epoch: 65 [1500/2000 (75%)] | D loss (A): 0.282712 | D loss (B): 0.168746 | G loss: 2.329960 | Consistency: 0.109150 |\n",
      "Training epoch: 65 [1600/2000 (80%)] | D loss (A): 0.158981 | D loss (B): 0.152997 | G loss: 1.883939 | Consistency: 0.092741 |\n",
      "Training epoch: 65 [1700/2000 (85%)] | D loss (A): 0.105271 | D loss (B): 0.113492 | G loss: 2.351494 | Consistency: 0.101365 |\n",
      "Training epoch: 65 [1800/2000 (90%)] | D loss (A): 0.227741 | D loss (B): 0.162041 | G loss: 2.360709 | Consistency: 0.104392 |\n",
      "Training epoch: 65 [1900/2000 (95%)] | D loss (A): 0.172846 | D loss (B): 0.139168 | G loss: 2.429064 | Consistency: 0.107764 |\n",
      "Training epoch: 66 [0/2000 (0%)] | D loss (A): 0.395251 | D loss (B): 0.079772 | G loss: 2.021195 | Consistency: 0.095519 |\n",
      "Training epoch: 66 [100/2000 (5%)] | D loss (A): 0.234128 | D loss (B): 0.158230 | G loss: 1.967609 | Consistency: 0.124919 |\n",
      "Training epoch: 66 [200/2000 (10%)] | D loss (A): 0.111038 | D loss (B): 0.046454 | G loss: 2.787127 | Consistency: 0.120021 |\n",
      "Training epoch: 66 [300/2000 (15%)] | D loss (A): 0.218051 | D loss (B): 0.090901 | G loss: 1.823665 | Consistency: 0.098839 |\n",
      "Training epoch: 66 [400/2000 (20%)] | D loss (A): 0.168395 | D loss (B): 0.052443 | G loss: 2.420031 | Consistency: 0.106099 |\n",
      "Training epoch: 66 [500/2000 (25%)] | D loss (A): 0.209933 | D loss (B): 0.204618 | G loss: 1.831151 | Consistency: 0.088205 |\n",
      "Training epoch: 66 [600/2000 (30%)] | D loss (A): 0.228381 | D loss (B): 0.138259 | G loss: 1.861050 | Consistency: 0.091276 |\n",
      "Training epoch: 66 [700/2000 (35%)] | D loss (A): 0.111912 | D loss (B): 0.143576 | G loss: 2.195654 | Consistency: 0.106239 |\n",
      "Training epoch: 66 [800/2000 (40%)] | D loss (A): 0.073811 | D loss (B): 0.109300 | G loss: 1.591394 | Consistency: 0.094046 |\n",
      "Training epoch: 66 [900/2000 (45%)] | D loss (A): 0.115125 | D loss (B): 0.088896 | G loss: 2.708844 | Consistency: 0.119610 |\n",
      "Training epoch: 66 [1000/2000 (50%)] | D loss (A): 0.085143 | D loss (B): 0.081513 | G loss: 1.612562 | Consistency: 0.113322 |\n",
      "Training epoch: 66 [1100/2000 (55%)] | D loss (A): 0.072528 | D loss (B): 0.070523 | G loss: 2.474523 | Consistency: 0.096888 |\n",
      "Training epoch: 66 [1200/2000 (60%)] | D loss (A): 0.197765 | D loss (B): 0.226075 | G loss: 1.981296 | Consistency: 0.105448 |\n",
      "Training epoch: 66 [1300/2000 (65%)] | D loss (A): 0.075475 | D loss (B): 0.194258 | G loss: 1.700262 | Consistency: 0.077454 |\n",
      "Training epoch: 66 [1400/2000 (70%)] | D loss (A): 0.137610 | D loss (B): 0.111387 | G loss: 2.415964 | Consistency: 0.096868 |\n",
      "Training epoch: 66 [1500/2000 (75%)] | D loss (A): 0.253106 | D loss (B): 0.193679 | G loss: 2.029860 | Consistency: 0.090349 |\n",
      "Training epoch: 66 [1600/2000 (80%)] | D loss (A): 0.194055 | D loss (B): 0.254936 | G loss: 1.941850 | Consistency: 0.087112 |\n",
      "Training epoch: 66 [1700/2000 (85%)] | D loss (A): 0.162614 | D loss (B): 0.092519 | G loss: 1.610021 | Consistency: 0.082703 |\n",
      "Training epoch: 66 [1800/2000 (90%)] | D loss (A): 0.099456 | D loss (B): 0.133726 | G loss: 1.917141 | Consistency: 0.106405 |\n",
      "Training epoch: 66 [1900/2000 (95%)] | D loss (A): 0.157190 | D loss (B): 0.177665 | G loss: 1.932647 | Consistency: 0.069499 |\n",
      "Training epoch: 67 [0/2000 (0%)] | D loss (A): 0.113136 | D loss (B): 0.115120 | G loss: 1.666830 | Consistency: 0.078699 |\n",
      "Training epoch: 67 [100/2000 (5%)] | D loss (A): 0.152796 | D loss (B): 0.107907 | G loss: 1.405583 | Consistency: 0.097433 |\n",
      "Training epoch: 67 [200/2000 (10%)] | D loss (A): 0.278012 | D loss (B): 0.198742 | G loss: 2.268796 | Consistency: 0.122882 |\n",
      "Training epoch: 67 [300/2000 (15%)] | D loss (A): 0.127428 | D loss (B): 0.089711 | G loss: 1.925711 | Consistency: 0.098793 |\n",
      "Training epoch: 67 [400/2000 (20%)] | D loss (A): 0.173251 | D loss (B): 0.122363 | G loss: 2.469822 | Consistency: 0.112320 |\n",
      "Training epoch: 67 [500/2000 (25%)] | D loss (A): 0.164963 | D loss (B): 0.119290 | G loss: 1.862891 | Consistency: 0.110167 |\n",
      "Training epoch: 67 [600/2000 (30%)] | D loss (A): 0.192362 | D loss (B): 0.124299 | G loss: 1.745265 | Consistency: 0.108628 |\n",
      "Training epoch: 67 [700/2000 (35%)] | D loss (A): 0.070917 | D loss (B): 0.122460 | G loss: 1.114626 | Consistency: 0.088667 |\n",
      "Training epoch: 67 [800/2000 (40%)] | D loss (A): 0.123070 | D loss (B): 0.078861 | G loss: 1.934165 | Consistency: 0.114392 |\n",
      "Training epoch: 67 [900/2000 (45%)] | D loss (A): 0.056070 | D loss (B): 0.144134 | G loss: 2.152037 | Consistency: 0.076897 |\n",
      "Training epoch: 67 [1000/2000 (50%)] | D loss (A): 0.064337 | D loss (B): 0.157433 | G loss: 2.158047 | Consistency: 0.097980 |\n",
      "Training epoch: 67 [1100/2000 (55%)] | D loss (A): 0.150125 | D loss (B): 0.096182 | G loss: 2.140743 | Consistency: 0.112675 |\n",
      "Training epoch: 67 [1200/2000 (60%)] | D loss (A): 0.074597 | D loss (B): 0.074757 | G loss: 1.664965 | Consistency: 0.087568 |\n",
      "Training epoch: 67 [1300/2000 (65%)] | D loss (A): 0.141627 | D loss (B): 0.157350 | G loss: 1.786901 | Consistency: 0.096048 |\n",
      "Training epoch: 67 [1400/2000 (70%)] | D loss (A): 0.122261 | D loss (B): 0.051441 | G loss: 2.239197 | Consistency: 0.101799 |\n",
      "Training epoch: 67 [1500/2000 (75%)] | D loss (A): 0.066291 | D loss (B): 0.181206 | G loss: 2.483206 | Consistency: 0.129107 |\n",
      "Training epoch: 67 [1600/2000 (80%)] | D loss (A): 0.280884 | D loss (B): 0.051452 | G loss: 1.893426 | Consistency: 0.102803 |\n",
      "Training epoch: 67 [1700/2000 (85%)] | D loss (A): 0.070251 | D loss (B): 0.083864 | G loss: 1.818428 | Consistency: 0.115372 |\n",
      "Training epoch: 67 [1800/2000 (90%)] | D loss (A): 0.079702 | D loss (B): 0.045240 | G loss: 2.091944 | Consistency: 0.109210 |\n",
      "Training epoch: 67 [1900/2000 (95%)] | D loss (A): 0.113807 | D loss (B): 0.047847 | G loss: 2.026338 | Consistency: 0.115439 |\n",
      "Training epoch: 68 [0/2000 (0%)] | D loss (A): 0.139455 | D loss (B): 0.087889 | G loss: 2.532688 | Consistency: 0.078186 |\n",
      "Training epoch: 68 [100/2000 (5%)] | D loss (A): 0.101898 | D loss (B): 0.159473 | G loss: 1.464917 | Consistency: 0.083209 |\n",
      "Training epoch: 68 [200/2000 (10%)] | D loss (A): 0.173867 | D loss (B): 0.174284 | G loss: 1.257150 | Consistency: 0.062782 |\n",
      "Training epoch: 68 [300/2000 (15%)] | D loss (A): 0.154481 | D loss (B): 0.166875 | G loss: 2.274567 | Consistency: 0.101167 |\n",
      "Training epoch: 68 [400/2000 (20%)] | D loss (A): 0.173808 | D loss (B): 0.087006 | G loss: 1.585376 | Consistency: 0.083229 |\n",
      "Training epoch: 68 [500/2000 (25%)] | D loss (A): 0.284139 | D loss (B): 0.146763 | G loss: 1.573261 | Consistency: 0.098944 |\n",
      "Training epoch: 68 [600/2000 (30%)] | D loss (A): 0.082807 | D loss (B): 0.078973 | G loss: 2.010051 | Consistency: 0.116657 |\n",
      "Training epoch: 68 [700/2000 (35%)] | D loss (A): 0.142259 | D loss (B): 0.179847 | G loss: 1.835897 | Consistency: 0.099568 |\n",
      "Training epoch: 68 [800/2000 (40%)] | D loss (A): 0.224748 | D loss (B): 0.164882 | G loss: 1.883050 | Consistency: 0.088285 |\n",
      "Training epoch: 68 [900/2000 (45%)] | D loss (A): 0.184415 | D loss (B): 0.178306 | G loss: 1.640454 | Consistency: 0.097275 |\n",
      "Training epoch: 68 [1000/2000 (50%)] | D loss (A): 0.126464 | D loss (B): 0.219771 | G loss: 1.714623 | Consistency: 0.098809 |\n",
      "Training epoch: 68 [1100/2000 (55%)] | D loss (A): 0.202631 | D loss (B): 0.174842 | G loss: 1.647280 | Consistency: 0.094208 |\n",
      "Training epoch: 68 [1200/2000 (60%)] | D loss (A): 0.080420 | D loss (B): 0.121280 | G loss: 1.971800 | Consistency: 0.089315 |\n",
      "Training epoch: 68 [1300/2000 (65%)] | D loss (A): 0.143640 | D loss (B): 0.046572 | G loss: 1.872609 | Consistency: 0.094959 |\n",
      "Training epoch: 68 [1400/2000 (70%)] | D loss (A): 0.238206 | D loss (B): 0.215092 | G loss: 2.063241 | Consistency: 0.095137 |\n",
      "Training epoch: 68 [1500/2000 (75%)] | D loss (A): 0.265053 | D loss (B): 0.074186 | G loss: 1.787713 | Consistency: 0.087906 |\n",
      "Training epoch: 68 [1600/2000 (80%)] | D loss (A): 0.143357 | D loss (B): 0.161421 | G loss: 1.467530 | Consistency: 0.084600 |\n",
      "Training epoch: 68 [1700/2000 (85%)] | D loss (A): 0.171827 | D loss (B): 0.268261 | G loss: 2.179796 | Consistency: 0.120675 |\n",
      "Training epoch: 68 [1800/2000 (90%)] | D loss (A): 0.108383 | D loss (B): 0.106644 | G loss: 2.015218 | Consistency: 0.100543 |\n",
      "Training epoch: 68 [1900/2000 (95%)] | D loss (A): 0.243714 | D loss (B): 0.116099 | G loss: 1.740666 | Consistency: 0.067942 |\n",
      "Training epoch: 69 [0/2000 (0%)] | D loss (A): 0.225811 | D loss (B): 0.087916 | G loss: 1.782023 | Consistency: 0.096821 |\n",
      "Training epoch: 69 [100/2000 (5%)] | D loss (A): 0.286380 | D loss (B): 0.092639 | G loss: 1.803791 | Consistency: 0.094492 |\n",
      "Training epoch: 69 [200/2000 (10%)] | D loss (A): 0.126793 | D loss (B): 0.083216 | G loss: 2.751217 | Consistency: 0.142836 |\n",
      "Training epoch: 69 [300/2000 (15%)] | D loss (A): 0.252881 | D loss (B): 0.169381 | G loss: 1.788383 | Consistency: 0.088171 |\n",
      "Training epoch: 69 [400/2000 (20%)] | D loss (A): 0.117183 | D loss (B): 0.174100 | G loss: 1.267186 | Consistency: 0.088176 |\n",
      "Training epoch: 69 [500/2000 (25%)] | D loss (A): 0.210598 | D loss (B): 0.070501 | G loss: 1.931495 | Consistency: 0.088267 |\n",
      "Training epoch: 69 [600/2000 (30%)] | D loss (A): 0.204348 | D loss (B): 0.266316 | G loss: 2.168117 | Consistency: 0.118577 |\n",
      "Training epoch: 69 [700/2000 (35%)] | D loss (A): 0.126813 | D loss (B): 0.104179 | G loss: 1.868342 | Consistency: 0.092259 |\n",
      "Training epoch: 69 [800/2000 (40%)] | D loss (A): 0.160769 | D loss (B): 0.142723 | G loss: 2.177186 | Consistency: 0.117886 |\n",
      "Training epoch: 69 [900/2000 (45%)] | D loss (A): 0.118518 | D loss (B): 0.098723 | G loss: 2.060099 | Consistency: 0.096599 |\n",
      "Training epoch: 69 [1000/2000 (50%)] | D loss (A): 0.126932 | D loss (B): 0.171855 | G loss: 2.721698 | Consistency: 0.117788 |\n",
      "Training epoch: 69 [1100/2000 (55%)] | D loss (A): 0.183064 | D loss (B): 0.099825 | G loss: 1.691535 | Consistency: 0.084084 |\n",
      "Training epoch: 69 [1200/2000 (60%)] | D loss (A): 0.095776 | D loss (B): 0.139271 | G loss: 1.739309 | Consistency: 0.073657 |\n",
      "Training epoch: 69 [1300/2000 (65%)] | D loss (A): 0.115415 | D loss (B): 0.331302 | G loss: 1.452031 | Consistency: 0.076930 |\n",
      "Training epoch: 69 [1400/2000 (70%)] | D loss (A): 0.173669 | D loss (B): 0.048436 | G loss: 2.662265 | Consistency: 0.092546 |\n",
      "Training epoch: 69 [1500/2000 (75%)] | D loss (A): 0.104189 | D loss (B): 0.152268 | G loss: 2.268040 | Consistency: 0.090320 |\n",
      "Training epoch: 69 [1600/2000 (80%)] | D loss (A): 0.084429 | D loss (B): 0.179302 | G loss: 2.542550 | Consistency: 0.105580 |\n",
      "Training epoch: 69 [1700/2000 (85%)] | D loss (A): 0.162757 | D loss (B): 0.135303 | G loss: 2.665764 | Consistency: 0.108070 |\n",
      "Training epoch: 69 [1800/2000 (90%)] | D loss (A): 0.042883 | D loss (B): 0.169451 | G loss: 2.419512 | Consistency: 0.101776 |\n",
      "Training epoch: 69 [1900/2000 (95%)] | D loss (A): 0.092966 | D loss (B): 0.112684 | G loss: 1.975239 | Consistency: 0.128518 |\n",
      "Training epoch: 70 [0/2000 (0%)] | D loss (A): 0.210836 | D loss (B): 0.091096 | G loss: 1.830025 | Consistency: 0.110523 |\n",
      "Training epoch: 70 [100/2000 (5%)] | D loss (A): 0.348284 | D loss (B): 0.172832 | G loss: 1.469030 | Consistency: 0.083490 |\n",
      "Training epoch: 70 [200/2000 (10%)] | D loss (A): 0.216678 | D loss (B): 0.116531 | G loss: 2.499890 | Consistency: 0.146840 |\n",
      "Training epoch: 70 [300/2000 (15%)] | D loss (A): 0.376862 | D loss (B): 0.066831 | G loss: 1.962615 | Consistency: 0.125638 |\n",
      "Training epoch: 70 [400/2000 (20%)] | D loss (A): 0.216872 | D loss (B): 0.048842 | G loss: 1.547672 | Consistency: 0.087534 |\n",
      "Training epoch: 70 [500/2000 (25%)] | D loss (A): 0.298805 | D loss (B): 0.080722 | G loss: 1.700535 | Consistency: 0.102615 |\n",
      "Training epoch: 70 [600/2000 (30%)] | D loss (A): 0.277228 | D loss (B): 0.191903 | G loss: 2.093814 | Consistency: 0.129273 |\n",
      "Training epoch: 70 [700/2000 (35%)] | D loss (A): 0.220813 | D loss (B): 0.125508 | G loss: 1.611041 | Consistency: 0.108922 |\n",
      "Training epoch: 70 [800/2000 (40%)] | D loss (A): 0.232928 | D loss (B): 0.119300 | G loss: 1.474816 | Consistency: 0.092710 |\n",
      "Training epoch: 70 [900/2000 (45%)] | D loss (A): 0.246086 | D loss (B): 0.086857 | G loss: 2.054584 | Consistency: 0.128014 |\n",
      "Training epoch: 70 [1000/2000 (50%)] | D loss (A): 0.301708 | D loss (B): 0.121675 | G loss: 1.948478 | Consistency: 0.086689 |\n",
      "Training epoch: 70 [1100/2000 (55%)] | D loss (A): 0.250855 | D loss (B): 0.230848 | G loss: 1.696375 | Consistency: 0.089849 |\n",
      "Training epoch: 70 [1200/2000 (60%)] | D loss (A): 0.258116 | D loss (B): 0.210838 | G loss: 2.193526 | Consistency: 0.128981 |\n",
      "Training epoch: 70 [1300/2000 (65%)] | D loss (A): 0.274421 | D loss (B): 0.105409 | G loss: 2.042609 | Consistency: 0.092644 |\n",
      "Training epoch: 70 [1400/2000 (70%)] | D loss (A): 0.273904 | D loss (B): 0.176168 | G loss: 1.594372 | Consistency: 0.085093 |\n",
      "Training epoch: 70 [1500/2000 (75%)] | D loss (A): 0.297585 | D loss (B): 0.054816 | G loss: 1.940745 | Consistency: 0.124726 |\n",
      "Training epoch: 70 [1600/2000 (80%)] | D loss (A): 0.354322 | D loss (B): 0.144543 | G loss: 1.605986 | Consistency: 0.075838 |\n",
      "Training epoch: 70 [1700/2000 (85%)] | D loss (A): 0.215110 | D loss (B): 0.113446 | G loss: 2.097217 | Consistency: 0.105374 |\n",
      "Training epoch: 70 [1800/2000 (90%)] | D loss (A): 0.317586 | D loss (B): 0.092080 | G loss: 1.451093 | Consistency: 0.078225 |\n",
      "Training epoch: 70 [1900/2000 (95%)] | D loss (A): 0.311059 | D loss (B): 0.131401 | G loss: 2.143264 | Consistency: 0.124911 |\n",
      "Training epoch: 71 [0/2000 (0%)] | D loss (A): 0.274965 | D loss (B): 0.247896 | G loss: 1.752396 | Consistency: 0.095584 |\n",
      "Training epoch: 71 [100/2000 (5%)] | D loss (A): 0.263566 | D loss (B): 0.123614 | G loss: 1.824766 | Consistency: 0.087877 |\n",
      "Training epoch: 71 [200/2000 (10%)] | D loss (A): 0.284957 | D loss (B): 0.273325 | G loss: 2.299185 | Consistency: 0.092222 |\n",
      "Training epoch: 71 [300/2000 (15%)] | D loss (A): 0.248791 | D loss (B): 0.175617 | G loss: 1.731730 | Consistency: 0.082015 |\n",
      "Training epoch: 71 [400/2000 (20%)] | D loss (A): 0.201339 | D loss (B): 0.114524 | G loss: 1.944895 | Consistency: 0.107293 |\n",
      "Training epoch: 71 [500/2000 (25%)] | D loss (A): 0.245024 | D loss (B): 0.140652 | G loss: 1.477006 | Consistency: 0.088348 |\n",
      "Training epoch: 71 [600/2000 (30%)] | D loss (A): 0.196056 | D loss (B): 0.192764 | G loss: 1.553356 | Consistency: 0.070192 |\n",
      "Training epoch: 71 [700/2000 (35%)] | D loss (A): 0.202453 | D loss (B): 0.127716 | G loss: 1.609539 | Consistency: 0.087160 |\n",
      "Training epoch: 71 [800/2000 (40%)] | D loss (A): 0.240770 | D loss (B): 0.249888 | G loss: 1.590903 | Consistency: 0.065493 |\n",
      "Training epoch: 71 [900/2000 (45%)] | D loss (A): 0.225399 | D loss (B): 0.207383 | G loss: 1.764399 | Consistency: 0.085257 |\n",
      "Training epoch: 71 [1000/2000 (50%)] | D loss (A): 0.261403 | D loss (B): 0.059141 | G loss: 1.662078 | Consistency: 0.092894 |\n",
      "Training epoch: 71 [1100/2000 (55%)] | D loss (A): 0.323615 | D loss (B): 0.066823 | G loss: 1.608862 | Consistency: 0.104592 |\n",
      "Training epoch: 71 [1200/2000 (60%)] | D loss (A): 0.229883 | D loss (B): 0.234009 | G loss: 2.105292 | Consistency: 0.099975 |\n",
      "Training epoch: 71 [1300/2000 (65%)] | D loss (A): 0.247603 | D loss (B): 0.069187 | G loss: 1.323739 | Consistency: 0.077657 |\n",
      "Training epoch: 71 [1400/2000 (70%)] | D loss (A): 0.168552 | D loss (B): 0.098534 | G loss: 1.676565 | Consistency: 0.077873 |\n",
      "Training epoch: 71 [1500/2000 (75%)] | D loss (A): 0.159485 | D loss (B): 0.081028 | G loss: 1.797970 | Consistency: 0.080441 |\n",
      "Training epoch: 71 [1600/2000 (80%)] | D loss (A): 0.232654 | D loss (B): 0.092366 | G loss: 1.384592 | Consistency: 0.073460 |\n",
      "Training epoch: 71 [1700/2000 (85%)] | D loss (A): 0.143760 | D loss (B): 0.080029 | G loss: 1.821751 | Consistency: 0.106131 |\n",
      "Training epoch: 71 [1800/2000 (90%)] | D loss (A): 0.140603 | D loss (B): 0.194602 | G loss: 2.054169 | Consistency: 0.123902 |\n",
      "Training epoch: 71 [1900/2000 (95%)] | D loss (A): 0.163539 | D loss (B): 0.169001 | G loss: 2.016114 | Consistency: 0.089387 |\n",
      "Training epoch: 72 [0/2000 (0%)] | D loss (A): 0.226917 | D loss (B): 0.129289 | G loss: 2.366029 | Consistency: 0.132277 |\n",
      "Training epoch: 72 [100/2000 (5%)] | D loss (A): 0.126783 | D loss (B): 0.171926 | G loss: 2.081897 | Consistency: 0.106195 |\n",
      "Training epoch: 72 [200/2000 (10%)] | D loss (A): 0.161184 | D loss (B): 0.128764 | G loss: 1.944524 | Consistency: 0.080519 |\n",
      "Training epoch: 72 [300/2000 (15%)] | D loss (A): 0.249699 | D loss (B): 0.100872 | G loss: 1.655465 | Consistency: 0.094107 |\n",
      "Training epoch: 72 [400/2000 (20%)] | D loss (A): 0.214961 | D loss (B): 0.065035 | G loss: 1.936298 | Consistency: 0.107994 |\n",
      "Training epoch: 72 [500/2000 (25%)] | D loss (A): 0.198219 | D loss (B): 0.162944 | G loss: 1.927958 | Consistency: 0.092619 |\n",
      "Training epoch: 72 [600/2000 (30%)] | D loss (A): 0.141076 | D loss (B): 0.255322 | G loss: 2.495118 | Consistency: 0.118067 |\n",
      "Training epoch: 72 [700/2000 (35%)] | D loss (A): 0.070389 | D loss (B): 0.160444 | G loss: 1.413340 | Consistency: 0.068845 |\n",
      "Training epoch: 72 [800/2000 (40%)] | D loss (A): 0.128286 | D loss (B): 0.191561 | G loss: 2.128009 | Consistency: 0.097968 |\n",
      "Training epoch: 72 [900/2000 (45%)] | D loss (A): 0.153766 | D loss (B): 0.199943 | G loss: 2.088408 | Consistency: 0.087143 |\n",
      "Training epoch: 72 [1000/2000 (50%)] | D loss (A): 0.224971 | D loss (B): 0.103386 | G loss: 2.614314 | Consistency: 0.137166 |\n",
      "Training epoch: 72 [1100/2000 (55%)] | D loss (A): 0.385945 | D loss (B): 0.128224 | G loss: 1.779277 | Consistency: 0.110563 |\n",
      "Training epoch: 72 [1200/2000 (60%)] | D loss (A): 0.121992 | D loss (B): 0.092488 | G loss: 2.050541 | Consistency: 0.091258 |\n",
      "Training epoch: 72 [1300/2000 (65%)] | D loss (A): 0.194805 | D loss (B): 0.144853 | G loss: 1.330586 | Consistency: 0.078037 |\n",
      "Training epoch: 72 [1400/2000 (70%)] | D loss (A): 0.118244 | D loss (B): 0.145728 | G loss: 2.326516 | Consistency: 0.105113 |\n",
      "Training epoch: 72 [1500/2000 (75%)] | D loss (A): 0.171726 | D loss (B): 0.144403 | G loss: 2.061268 | Consistency: 0.099340 |\n",
      "Training epoch: 72 [1600/2000 (80%)] | D loss (A): 0.222662 | D loss (B): 0.092733 | G loss: 1.768237 | Consistency: 0.085336 |\n",
      "Training epoch: 72 [1700/2000 (85%)] | D loss (A): 0.046534 | D loss (B): 0.056954 | G loss: 1.281120 | Consistency: 0.067692 |\n",
      "Training epoch: 72 [1800/2000 (90%)] | D loss (A): 0.104070 | D loss (B): 0.130911 | G loss: 2.069078 | Consistency: 0.108680 |\n",
      "Training epoch: 72 [1900/2000 (95%)] | D loss (A): 0.047515 | D loss (B): 0.125831 | G loss: 1.492897 | Consistency: 0.082221 |\n",
      "Training epoch: 73 [0/2000 (0%)] | D loss (A): 0.091765 | D loss (B): 0.156088 | G loss: 2.357356 | Consistency: 0.142268 |\n",
      "Training epoch: 73 [100/2000 (5%)] | D loss (A): 0.251260 | D loss (B): 0.069724 | G loss: 1.663346 | Consistency: 0.099310 |\n",
      "Training epoch: 73 [200/2000 (10%)] | D loss (A): 0.197077 | D loss (B): 0.161048 | G loss: 1.732537 | Consistency: 0.071900 |\n",
      "Training epoch: 73 [300/2000 (15%)] | D loss (A): 0.214396 | D loss (B): 0.112277 | G loss: 1.430284 | Consistency: 0.077656 |\n",
      "Training epoch: 73 [400/2000 (20%)] | D loss (A): 0.087820 | D loss (B): 0.053538 | G loss: 2.165800 | Consistency: 0.108762 |\n",
      "Training epoch: 73 [500/2000 (25%)] | D loss (A): 0.096961 | D loss (B): 0.289044 | G loss: 2.764567 | Consistency: 0.175708 |\n",
      "Training epoch: 73 [600/2000 (30%)] | D loss (A): 0.039729 | D loss (B): 0.354997 | G loss: 1.787278 | Consistency: 0.118232 |\n",
      "Training epoch: 73 [700/2000 (35%)] | D loss (A): 0.066455 | D loss (B): 0.185444 | G loss: 2.387046 | Consistency: 0.136752 |\n",
      "Training epoch: 73 [800/2000 (40%)] | D loss (A): 0.045958 | D loss (B): 0.285211 | G loss: 2.030881 | Consistency: 0.136129 |\n",
      "Training epoch: 73 [900/2000 (45%)] | D loss (A): 0.158539 | D loss (B): 0.121874 | G loss: 1.884144 | Consistency: 0.104365 |\n",
      "Training epoch: 73 [1000/2000 (50%)] | D loss (A): 0.110633 | D loss (B): 0.237650 | G loss: 1.510445 | Consistency: 0.111003 |\n",
      "Training epoch: 73 [1100/2000 (55%)] | D loss (A): 0.275087 | D loss (B): 0.151044 | G loss: 1.806407 | Consistency: 0.081347 |\n",
      "Training epoch: 73 [1200/2000 (60%)] | D loss (A): 0.246976 | D loss (B): 0.250938 | G loss: 2.159826 | Consistency: 0.103549 |\n",
      "Training epoch: 73 [1300/2000 (65%)] | D loss (A): 0.205311 | D loss (B): 0.265917 | G loss: 1.629993 | Consistency: 0.084531 |\n",
      "Training epoch: 73 [1400/2000 (70%)] | D loss (A): 0.153371 | D loss (B): 0.163637 | G loss: 1.104044 | Consistency: 0.067597 |\n",
      "Training epoch: 73 [1500/2000 (75%)] | D loss (A): 0.257644 | D loss (B): 0.198147 | G loss: 1.163507 | Consistency: 0.071337 |\n",
      "Training epoch: 73 [1600/2000 (80%)] | D loss (A): 0.281452 | D loss (B): 0.335550 | G loss: 1.492813 | Consistency: 0.084474 |\n",
      "Training epoch: 73 [1700/2000 (85%)] | D loss (A): 0.246955 | D loss (B): 0.207205 | G loss: 1.867397 | Consistency: 0.108736 |\n",
      "Training epoch: 73 [1800/2000 (90%)] | D loss (A): 0.147870 | D loss (B): 0.192725 | G loss: 1.631214 | Consistency: 0.099584 |\n",
      "Training epoch: 73 [1900/2000 (95%)] | D loss (A): 0.145271 | D loss (B): 0.155444 | G loss: 1.779191 | Consistency: 0.089783 |\n",
      "Training epoch: 74 [0/2000 (0%)] | D loss (A): 0.256256 | D loss (B): 0.267003 | G loss: 1.448826 | Consistency: 0.090876 |\n",
      "Training epoch: 74 [100/2000 (5%)] | D loss (A): 0.154764 | D loss (B): 0.211815 | G loss: 2.105387 | Consistency: 0.085487 |\n",
      "Training epoch: 74 [200/2000 (10%)] | D loss (A): 0.119738 | D loss (B): 0.102495 | G loss: 1.539163 | Consistency: 0.101058 |\n",
      "Training epoch: 74 [300/2000 (15%)] | D loss (A): 0.112264 | D loss (B): 0.184764 | G loss: 1.477558 | Consistency: 0.080536 |\n",
      "Training epoch: 74 [400/2000 (20%)] | D loss (A): 0.121325 | D loss (B): 0.081762 | G loss: 1.663574 | Consistency: 0.108041 |\n",
      "Training epoch: 74 [500/2000 (25%)] | D loss (A): 0.113400 | D loss (B): 0.125157 | G loss: 1.437832 | Consistency: 0.081097 |\n",
      "Training epoch: 74 [600/2000 (30%)] | D loss (A): 0.196038 | D loss (B): 0.146827 | G loss: 1.884461 | Consistency: 0.107375 |\n",
      "Training epoch: 74 [700/2000 (35%)] | D loss (A): 0.133593 | D loss (B): 0.197388 | G loss: 2.096994 | Consistency: 0.078352 |\n",
      "Training epoch: 74 [800/2000 (40%)] | D loss (A): 0.176821 | D loss (B): 0.159858 | G loss: 1.718043 | Consistency: 0.085858 |\n",
      "Training epoch: 74 [900/2000 (45%)] | D loss (A): 0.232519 | D loss (B): 0.119422 | G loss: 2.086219 | Consistency: 0.117511 |\n",
      "Training epoch: 74 [1000/2000 (50%)] | D loss (A): 0.179064 | D loss (B): 0.091527 | G loss: 1.699429 | Consistency: 0.091787 |\n",
      "Training epoch: 74 [1100/2000 (55%)] | D loss (A): 0.197070 | D loss (B): 0.304741 | G loss: 1.905849 | Consistency: 0.093542 |\n",
      "Training epoch: 74 [1200/2000 (60%)] | D loss (A): 0.126328 | D loss (B): 0.132787 | G loss: 1.926980 | Consistency: 0.108453 |\n",
      "Training epoch: 74 [1300/2000 (65%)] | D loss (A): 0.072913 | D loss (B): 0.086464 | G loss: 2.124945 | Consistency: 0.099703 |\n",
      "Training epoch: 74 [1400/2000 (70%)] | D loss (A): 0.092899 | D loss (B): 0.092162 | G loss: 1.253459 | Consistency: 0.085433 |\n",
      "Training epoch: 74 [1500/2000 (75%)] | D loss (A): 0.431907 | D loss (B): 0.076016 | G loss: 2.375308 | Consistency: 0.149621 |\n",
      "Training epoch: 74 [1600/2000 (80%)] | D loss (A): 0.341230 | D loss (B): 0.031061 | G loss: 1.999061 | Consistency: 0.108695 |\n",
      "Training epoch: 74 [1700/2000 (85%)] | D loss (A): 0.138868 | D loss (B): 0.086560 | G loss: 2.238184 | Consistency: 0.161565 |\n",
      "Training epoch: 74 [1800/2000 (90%)] | D loss (A): 0.324560 | D loss (B): 0.126634 | G loss: 2.042058 | Consistency: 0.096932 |\n",
      "Training epoch: 74 [1900/2000 (95%)] | D loss (A): 0.177583 | D loss (B): 0.062358 | G loss: 1.569720 | Consistency: 0.111064 |\n",
      "Training epoch: 75 [0/2000 (0%)] | D loss (A): 0.260165 | D loss (B): 0.118952 | G loss: 1.448231 | Consistency: 0.093915 |\n",
      "Training epoch: 75 [100/2000 (5%)] | D loss (A): 0.220711 | D loss (B): 0.148002 | G loss: 1.546875 | Consistency: 0.083495 |\n",
      "Training epoch: 75 [200/2000 (10%)] | D loss (A): 0.270534 | D loss (B): 0.086421 | G loss: 2.087728 | Consistency: 0.114526 |\n",
      "Training epoch: 75 [300/2000 (15%)] | D loss (A): 0.242255 | D loss (B): 0.171154 | G loss: 1.921942 | Consistency: 0.103779 |\n",
      "Training epoch: 75 [400/2000 (20%)] | D loss (A): 0.267514 | D loss (B): 0.026849 | G loss: 1.977205 | Consistency: 0.105296 |\n",
      "Training epoch: 75 [500/2000 (25%)] | D loss (A): 0.221295 | D loss (B): 0.143041 | G loss: 1.325379 | Consistency: 0.063065 |\n",
      "Training epoch: 75 [600/2000 (30%)] | D loss (A): 0.295956 | D loss (B): 0.150910 | G loss: 1.985147 | Consistency: 0.094179 |\n",
      "Training epoch: 75 [700/2000 (35%)] | D loss (A): 0.258537 | D loss (B): 0.132427 | G loss: 1.959639 | Consistency: 0.103550 |\n",
      "Training epoch: 75 [800/2000 (40%)] | D loss (A): 0.286041 | D loss (B): 0.134922 | G loss: 1.723659 | Consistency: 0.087770 |\n",
      "Training epoch: 75 [900/2000 (45%)] | D loss (A): 0.206838 | D loss (B): 0.088746 | G loss: 2.030735 | Consistency: 0.100533 |\n",
      "Training epoch: 75 [1000/2000 (50%)] | D loss (A): 0.257309 | D loss (B): 0.074871 | G loss: 1.524289 | Consistency: 0.074699 |\n",
      "Training epoch: 75 [1100/2000 (55%)] | D loss (A): 0.212519 | D loss (B): 0.094906 | G loss: 1.572817 | Consistency: 0.091944 |\n",
      "Training epoch: 75 [1200/2000 (60%)] | D loss (A): 0.294008 | D loss (B): 0.056183 | G loss: 1.451687 | Consistency: 0.077010 |\n",
      "Training epoch: 75 [1300/2000 (65%)] | D loss (A): 0.284224 | D loss (B): 0.174153 | G loss: 1.509195 | Consistency: 0.081538 |\n",
      "Training epoch: 75 [1400/2000 (70%)] | D loss (A): 0.195417 | D loss (B): 0.080836 | G loss: 1.992032 | Consistency: 0.085722 |\n",
      "Training epoch: 75 [1500/2000 (75%)] | D loss (A): 0.221531 | D loss (B): 0.100467 | G loss: 1.772292 | Consistency: 0.105303 |\n",
      "Training epoch: 75 [1600/2000 (80%)] | D loss (A): 0.229616 | D loss (B): 0.226953 | G loss: 1.793359 | Consistency: 0.088778 |\n",
      "Training epoch: 75 [1700/2000 (85%)] | D loss (A): 0.179593 | D loss (B): 0.133750 | G loss: 1.571657 | Consistency: 0.066283 |\n",
      "Training epoch: 75 [1800/2000 (90%)] | D loss (A): 0.260163 | D loss (B): 0.064952 | G loss: 2.113761 | Consistency: 0.091395 |\n",
      "Training epoch: 75 [1900/2000 (95%)] | D loss (A): 0.196883 | D loss (B): 0.121695 | G loss: 1.875120 | Consistency: 0.115549 |\n",
      "Training epoch: 76 [0/2000 (0%)] | D loss (A): 0.256368 | D loss (B): 0.082113 | G loss: 2.056692 | Consistency: 0.139222 |\n",
      "Training epoch: 76 [100/2000 (5%)] | D loss (A): 0.220932 | D loss (B): 0.062443 | G loss: 1.872710 | Consistency: 0.094929 |\n",
      "Training epoch: 76 [200/2000 (10%)] | D loss (A): 0.235322 | D loss (B): 0.145574 | G loss: 1.730055 | Consistency: 0.082343 |\n",
      "Training epoch: 76 [300/2000 (15%)] | D loss (A): 0.221536 | D loss (B): 0.128896 | G loss: 2.105686 | Consistency: 0.103583 |\n",
      "Training epoch: 76 [400/2000 (20%)] | D loss (A): 0.191456 | D loss (B): 0.155179 | G loss: 1.814756 | Consistency: 0.093397 |\n",
      "Training epoch: 76 [500/2000 (25%)] | D loss (A): 0.175428 | D loss (B): 0.074463 | G loss: 2.279996 | Consistency: 0.109247 |\n",
      "Training epoch: 76 [600/2000 (30%)] | D loss (A): 0.253806 | D loss (B): 0.061278 | G loss: 1.831662 | Consistency: 0.092772 |\n",
      "Training epoch: 76 [700/2000 (35%)] | D loss (A): 0.164724 | D loss (B): 0.217646 | G loss: 1.494643 | Consistency: 0.088509 |\n",
      "Training epoch: 76 [800/2000 (40%)] | D loss (A): 0.269293 | D loss (B): 0.170247 | G loss: 1.648221 | Consistency: 0.084380 |\n",
      "Training epoch: 76 [900/2000 (45%)] | D loss (A): 0.229274 | D loss (B): 0.213983 | G loss: 2.169718 | Consistency: 0.091609 |\n",
      "Training epoch: 76 [1000/2000 (50%)] | D loss (A): 0.197645 | D loss (B): 0.191846 | G loss: 1.622162 | Consistency: 0.090656 |\n",
      "Training epoch: 76 [1100/2000 (55%)] | D loss (A): 0.113324 | D loss (B): 0.140325 | G loss: 1.921119 | Consistency: 0.074678 |\n",
      "Training epoch: 76 [1200/2000 (60%)] | D loss (A): 0.201099 | D loss (B): 0.150499 | G loss: 1.699417 | Consistency: 0.078322 |\n",
      "Training epoch: 76 [1300/2000 (65%)] | D loss (A): 0.109646 | D loss (B): 0.276184 | G loss: 1.801266 | Consistency: 0.116653 |\n",
      "Training epoch: 76 [1400/2000 (70%)] | D loss (A): 0.172558 | D loss (B): 0.252307 | G loss: 2.100313 | Consistency: 0.101101 |\n",
      "Training epoch: 76 [1500/2000 (75%)] | D loss (A): 0.120901 | D loss (B): 0.134917 | G loss: 2.510215 | Consistency: 0.097757 |\n",
      "Training epoch: 76 [1600/2000 (80%)] | D loss (A): 0.164704 | D loss (B): 0.052785 | G loss: 2.041038 | Consistency: 0.105942 |\n",
      "Training epoch: 76 [1700/2000 (85%)] | D loss (A): 0.129474 | D loss (B): 0.260274 | G loss: 2.381083 | Consistency: 0.121140 |\n",
      "Training epoch: 76 [1800/2000 (90%)] | D loss (A): 0.194728 | D loss (B): 0.200449 | G loss: 1.786768 | Consistency: 0.072202 |\n",
      "Training epoch: 76 [1900/2000 (95%)] | D loss (A): 0.100693 | D loss (B): 0.162375 | G loss: 1.726389 | Consistency: 0.094957 |\n",
      "Training epoch: 77 [0/2000 (0%)] | D loss (A): 0.139572 | D loss (B): 0.101802 | G loss: 1.792679 | Consistency: 0.091329 |\n",
      "Training epoch: 77 [100/2000 (5%)] | D loss (A): 0.181106 | D loss (B): 0.192452 | G loss: 1.723374 | Consistency: 0.091190 |\n",
      "Training epoch: 77 [200/2000 (10%)] | D loss (A): 0.202847 | D loss (B): 0.254495 | G loss: 2.033400 | Consistency: 0.111173 |\n",
      "Training epoch: 77 [300/2000 (15%)] | D loss (A): 0.184184 | D loss (B): 0.186059 | G loss: 2.660393 | Consistency: 0.103311 |\n",
      "Training epoch: 77 [400/2000 (20%)] | D loss (A): 0.122684 | D loss (B): 0.106227 | G loss: 2.226648 | Consistency: 0.094128 |\n",
      "Training epoch: 77 [500/2000 (25%)] | D loss (A): 0.146979 | D loss (B): 0.069036 | G loss: 1.817001 | Consistency: 0.087536 |\n",
      "Training epoch: 77 [600/2000 (30%)] | D loss (A): 0.450033 | D loss (B): 0.136812 | G loss: 1.398621 | Consistency: 0.100162 |\n",
      "Training epoch: 77 [700/2000 (35%)] | D loss (A): 0.248924 | D loss (B): 0.216209 | G loss: 2.083292 | Consistency: 0.115583 |\n",
      "Training epoch: 77 [800/2000 (40%)] | D loss (A): 0.151734 | D loss (B): 0.098694 | G loss: 2.630422 | Consistency: 0.130635 |\n",
      "Training epoch: 77 [900/2000 (45%)] | D loss (A): 0.151656 | D loss (B): 0.157675 | G loss: 1.719476 | Consistency: 0.087659 |\n",
      "Training epoch: 77 [1000/2000 (50%)] | D loss (A): 0.053284 | D loss (B): 0.174661 | G loss: 1.763746 | Consistency: 0.076007 |\n",
      "Training epoch: 77 [1100/2000 (55%)] | D loss (A): 0.142302 | D loss (B): 0.185078 | G loss: 1.261667 | Consistency: 0.073613 |\n",
      "Training epoch: 77 [1200/2000 (60%)] | D loss (A): 0.123171 | D loss (B): 0.198670 | G loss: 1.717341 | Consistency: 0.093476 |\n",
      "Training epoch: 77 [1300/2000 (65%)] | D loss (A): 0.252632 | D loss (B): 0.121563 | G loss: 2.151613 | Consistency: 0.100610 |\n",
      "Training epoch: 77 [1400/2000 (70%)] | D loss (A): 0.138120 | D loss (B): 0.159004 | G loss: 1.994264 | Consistency: 0.084197 |\n",
      "Training epoch: 77 [1500/2000 (75%)] | D loss (A): 0.147794 | D loss (B): 0.320734 | G loss: 1.636824 | Consistency: 0.122799 |\n",
      "Training epoch: 77 [1600/2000 (80%)] | D loss (A): 0.186364 | D loss (B): 0.103427 | G loss: 1.929120 | Consistency: 0.082935 |\n",
      "Training epoch: 77 [1700/2000 (85%)] | D loss (A): 0.180623 | D loss (B): 0.226172 | G loss: 2.098853 | Consistency: 0.101736 |\n",
      "Training epoch: 77 [1800/2000 (90%)] | D loss (A): 0.162550 | D loss (B): 0.128297 | G loss: 2.170072 | Consistency: 0.091055 |\n",
      "Training epoch: 77 [1900/2000 (95%)] | D loss (A): 0.102643 | D loss (B): 0.055008 | G loss: 1.962263 | Consistency: 0.129485 |\n",
      "Training epoch: 78 [0/2000 (0%)] | D loss (A): 0.200126 | D loss (B): 0.160367 | G loss: 1.109405 | Consistency: 0.062552 |\n",
      "Training epoch: 78 [100/2000 (5%)] | D loss (A): 0.097507 | D loss (B): 0.142883 | G loss: 2.299201 | Consistency: 0.119282 |\n",
      "Training epoch: 78 [200/2000 (10%)] | D loss (A): 0.257933 | D loss (B): 0.232278 | G loss: 1.906475 | Consistency: 0.090003 |\n",
      "Training epoch: 78 [300/2000 (15%)] | D loss (A): 0.203528 | D loss (B): 0.086398 | G loss: 2.051571 | Consistency: 0.090637 |\n",
      "Training epoch: 78 [400/2000 (20%)] | D loss (A): 0.043246 | D loss (B): 0.173532 | G loss: 1.793739 | Consistency: 0.084694 |\n",
      "Training epoch: 78 [500/2000 (25%)] | D loss (A): 0.143131 | D loss (B): 0.102886 | G loss: 2.625724 | Consistency: 0.109463 |\n",
      "Training epoch: 78 [600/2000 (30%)] | D loss (A): 0.126850 | D loss (B): 0.249493 | G loss: 1.437339 | Consistency: 0.080032 |\n",
      "Training epoch: 78 [700/2000 (35%)] | D loss (A): 0.175095 | D loss (B): 0.149855 | G loss: 1.831791 | Consistency: 0.097956 |\n",
      "Training epoch: 78 [800/2000 (40%)] | D loss (A): 0.136686 | D loss (B): 0.088109 | G loss: 1.743942 | Consistency: 0.100392 |\n",
      "Training epoch: 78 [900/2000 (45%)] | D loss (A): 0.108647 | D loss (B): 0.066952 | G loss: 3.340682 | Consistency: 0.149851 |\n",
      "Training epoch: 78 [1000/2000 (50%)] | D loss (A): 0.372303 | D loss (B): 0.227134 | G loss: 1.897050 | Consistency: 0.093255 |\n",
      "Training epoch: 78 [1100/2000 (55%)] | D loss (A): 0.173138 | D loss (B): 0.070867 | G loss: 1.703425 | Consistency: 0.089421 |\n",
      "Training epoch: 78 [1200/2000 (60%)] | D loss (A): 0.217771 | D loss (B): 0.094261 | G loss: 1.562597 | Consistency: 0.079605 |\n",
      "Training epoch: 78 [1300/2000 (65%)] | D loss (A): 0.054089 | D loss (B): 0.097895 | G loss: 2.404787 | Consistency: 0.124004 |\n",
      "Training epoch: 78 [1400/2000 (70%)] | D loss (A): 0.091784 | D loss (B): 0.072105 | G loss: 2.085185 | Consistency: 0.096858 |\n",
      "Training epoch: 78 [1500/2000 (75%)] | D loss (A): 0.132025 | D loss (B): 0.120605 | G loss: 1.723657 | Consistency: 0.084967 |\n",
      "Training epoch: 78 [1600/2000 (80%)] | D loss (A): 0.411157 | D loss (B): 0.129994 | G loss: 2.336702 | Consistency: 0.158782 |\n",
      "Training epoch: 78 [1700/2000 (85%)] | D loss (A): 0.280188 | D loss (B): 0.043929 | G loss: 1.735866 | Consistency: 0.126655 |\n",
      "Training epoch: 78 [1800/2000 (90%)] | D loss (A): 0.178244 | D loss (B): 0.131442 | G loss: 1.851379 | Consistency: 0.088214 |\n",
      "Training epoch: 78 [1900/2000 (95%)] | D loss (A): 0.214897 | D loss (B): 0.068894 | G loss: 1.563394 | Consistency: 0.098249 |\n",
      "Training epoch: 79 [0/2000 (0%)] | D loss (A): 0.047555 | D loss (B): 0.168870 | G loss: 1.551733 | Consistency: 0.089648 |\n",
      "Training epoch: 79 [100/2000 (5%)] | D loss (A): 0.346773 | D loss (B): 0.283019 | G loss: 1.626314 | Consistency: 0.087759 |\n",
      "Training epoch: 79 [200/2000 (10%)] | D loss (A): 0.267655 | D loss (B): 0.084703 | G loss: 2.360526 | Consistency: 0.120205 |\n",
      "Training epoch: 79 [300/2000 (15%)] | D loss (A): 0.207655 | D loss (B): 0.098778 | G loss: 1.304441 | Consistency: 0.079237 |\n",
      "Training epoch: 79 [400/2000 (20%)] | D loss (A): 0.223760 | D loss (B): 0.168034 | G loss: 1.642044 | Consistency: 0.080528 |\n",
      "Training epoch: 79 [500/2000 (25%)] | D loss (A): 0.269989 | D loss (B): 0.308423 | G loss: 1.697218 | Consistency: 0.094681 |\n",
      "Training epoch: 79 [600/2000 (30%)] | D loss (A): 0.271264 | D loss (B): 0.221394 | G loss: 1.697257 | Consistency: 0.077044 |\n",
      "Training epoch: 79 [700/2000 (35%)] | D loss (A): 0.208158 | D loss (B): 0.245019 | G loss: 1.926105 | Consistency: 0.107012 |\n",
      "Training epoch: 79 [800/2000 (40%)] | D loss (A): 0.307148 | D loss (B): 0.226418 | G loss: 2.048464 | Consistency: 0.122242 |\n",
      "Training epoch: 79 [900/2000 (45%)] | D loss (A): 0.243522 | D loss (B): 0.172440 | G loss: 1.531362 | Consistency: 0.092043 |\n",
      "Training epoch: 79 [1000/2000 (50%)] | D loss (A): 0.185434 | D loss (B): 0.153096 | G loss: 1.895153 | Consistency: 0.104345 |\n",
      "Training epoch: 79 [1100/2000 (55%)] | D loss (A): 0.193828 | D loss (B): 0.098225 | G loss: 1.782696 | Consistency: 0.119132 |\n",
      "Training epoch: 79 [1200/2000 (60%)] | D loss (A): 0.162406 | D loss (B): 0.037755 | G loss: 2.052750 | Consistency: 0.096835 |\n",
      "Training epoch: 79 [1300/2000 (65%)] | D loss (A): 0.168328 | D loss (B): 0.124378 | G loss: 1.935486 | Consistency: 0.084912 |\n",
      "Training epoch: 79 [1400/2000 (70%)] | D loss (A): 0.166229 | D loss (B): 0.158162 | G loss: 1.957137 | Consistency: 0.091565 |\n",
      "Training epoch: 79 [1500/2000 (75%)] | D loss (A): 0.126444 | D loss (B): 0.075287 | G loss: 1.549252 | Consistency: 0.074655 |\n",
      "Training epoch: 79 [1600/2000 (80%)] | D loss (A): 0.151495 | D loss (B): 0.065153 | G loss: 2.642027 | Consistency: 0.167392 |\n",
      "Training epoch: 79 [1700/2000 (85%)] | D loss (A): 0.054465 | D loss (B): 0.130495 | G loss: 1.956494 | Consistency: 0.094436 |\n",
      "Training epoch: 79 [1800/2000 (90%)] | D loss (A): 0.193750 | D loss (B): 0.184177 | G loss: 1.654234 | Consistency: 0.070654 |\n",
      "Training epoch: 79 [1900/2000 (95%)] | D loss (A): 0.162593 | D loss (B): 0.167375 | G loss: 2.397714 | Consistency: 0.094631 |\n",
      "Training epoch: 80 [0/2000 (0%)] | D loss (A): 0.121462 | D loss (B): 0.306313 | G loss: 1.483527 | Consistency: 0.069479 |\n",
      "Training epoch: 80 [100/2000 (5%)] | D loss (A): 0.170221 | D loss (B): 0.211017 | G loss: 2.013415 | Consistency: 0.082538 |\n",
      "Training epoch: 80 [200/2000 (10%)] | D loss (A): 0.097470 | D loss (B): 0.225386 | G loss: 1.814376 | Consistency: 0.086237 |\n",
      "Training epoch: 80 [300/2000 (15%)] | D loss (A): 0.206104 | D loss (B): 0.189988 | G loss: 2.054595 | Consistency: 0.094647 |\n",
      "Training epoch: 80 [400/2000 (20%)] | D loss (A): 0.181291 | D loss (B): 0.166274 | G loss: 1.555385 | Consistency: 0.100682 |\n",
      "Training epoch: 80 [500/2000 (25%)] | D loss (A): 0.118253 | D loss (B): 0.082232 | G loss: 2.435156 | Consistency: 0.109396 |\n",
      "Training epoch: 80 [600/2000 (30%)] | D loss (A): 0.159812 | D loss (B): 0.180597 | G loss: 1.967860 | Consistency: 0.109020 |\n",
      "Training epoch: 80 [700/2000 (35%)] | D loss (A): 0.093184 | D loss (B): 0.135708 | G loss: 1.655635 | Consistency: 0.100025 |\n",
      "Training epoch: 80 [800/2000 (40%)] | D loss (A): 0.116412 | D loss (B): 0.100826 | G loss: 1.928507 | Consistency: 0.101403 |\n",
      "Training epoch: 80 [900/2000 (45%)] | D loss (A): 0.147194 | D loss (B): 0.051764 | G loss: 2.316047 | Consistency: 0.101561 |\n",
      "Training epoch: 80 [1000/2000 (50%)] | D loss (A): 0.185820 | D loss (B): 0.084777 | G loss: 2.007085 | Consistency: 0.112759 |\n",
      "Training epoch: 80 [1100/2000 (55%)] | D loss (A): 0.108617 | D loss (B): 0.080145 | G loss: 2.811865 | Consistency: 0.125636 |\n",
      "Training epoch: 80 [1200/2000 (60%)] | D loss (A): 0.271803 | D loss (B): 0.233263 | G loss: 1.983440 | Consistency: 0.104031 |\n",
      "Training epoch: 80 [1300/2000 (65%)] | D loss (A): 0.086617 | D loss (B): 0.186608 | G loss: 2.134714 | Consistency: 0.114749 |\n",
      "Training epoch: 80 [1400/2000 (70%)] | D loss (A): 0.154385 | D loss (B): 0.047129 | G loss: 1.887205 | Consistency: 0.103127 |\n",
      "Training epoch: 80 [1500/2000 (75%)] | D loss (A): 0.122951 | D loss (B): 0.053520 | G loss: 1.331627 | Consistency: 0.077072 |\n",
      "Training epoch: 80 [1600/2000 (80%)] | D loss (A): 0.056271 | D loss (B): 0.203941 | G loss: 1.917553 | Consistency: 0.086636 |\n",
      "Training epoch: 80 [1700/2000 (85%)] | D loss (A): 0.166972 | D loss (B): 0.105723 | G loss: 1.848151 | Consistency: 0.090693 |\n",
      "Training epoch: 80 [1800/2000 (90%)] | D loss (A): 0.098787 | D loss (B): 0.081181 | G loss: 1.743568 | Consistency: 0.097579 |\n",
      "Training epoch: 80 [1900/2000 (95%)] | D loss (A): 0.114453 | D loss (B): 0.092541 | G loss: 1.887518 | Consistency: 0.088411 |\n",
      "Training epoch: 81 [0/2000 (0%)] | D loss (A): 0.175809 | D loss (B): 0.065721 | G loss: 2.291160 | Consistency: 0.096608 |\n",
      "Training epoch: 81 [100/2000 (5%)] | D loss (A): 0.237890 | D loss (B): 0.194246 | G loss: 1.996995 | Consistency: 0.092512 |\n",
      "Training epoch: 81 [200/2000 (10%)] | D loss (A): 0.245471 | D loss (B): 0.145857 | G loss: 2.109360 | Consistency: 0.086142 |\n",
      "Training epoch: 81 [300/2000 (15%)] | D loss (A): 0.213487 | D loss (B): 0.088777 | G loss: 2.334373 | Consistency: 0.097131 |\n",
      "Training epoch: 81 [400/2000 (20%)] | D loss (A): 0.130812 | D loss (B): 0.105678 | G loss: 1.677918 | Consistency: 0.079208 |\n",
      "Training epoch: 81 [500/2000 (25%)] | D loss (A): 0.169492 | D loss (B): 0.153752 | G loss: 1.488165 | Consistency: 0.073753 |\n",
      "Training epoch: 81 [600/2000 (30%)] | D loss (A): 0.193547 | D loss (B): 0.145423 | G loss: 2.247900 | Consistency: 0.095636 |\n",
      "Training epoch: 81 [700/2000 (35%)] | D loss (A): 0.136539 | D loss (B): 0.134314 | G loss: 1.813495 | Consistency: 0.099465 |\n",
      "Training epoch: 81 [800/2000 (40%)] | D loss (A): 0.204179 | D loss (B): 0.060275 | G loss: 2.049817 | Consistency: 0.122578 |\n",
      "Training epoch: 81 [900/2000 (45%)] | D loss (A): 0.095162 | D loss (B): 0.039143 | G loss: 1.867052 | Consistency: 0.114565 |\n",
      "Training epoch: 81 [1000/2000 (50%)] | D loss (A): 0.169208 | D loss (B): 0.234284 | G loss: 1.892244 | Consistency: 0.080524 |\n",
      "Training epoch: 81 [1100/2000 (55%)] | D loss (A): 0.192771 | D loss (B): 0.103053 | G loss: 1.867605 | Consistency: 0.108490 |\n",
      "Training epoch: 81 [1200/2000 (60%)] | D loss (A): 0.313783 | D loss (B): 0.050669 | G loss: 1.798019 | Consistency: 0.099178 |\n",
      "Training epoch: 81 [1300/2000 (65%)] | D loss (A): 0.219814 | D loss (B): 0.068557 | G loss: 1.818797 | Consistency: 0.095950 |\n",
      "Training epoch: 81 [1400/2000 (70%)] | D loss (A): 0.102033 | D loss (B): 0.160690 | G loss: 1.835378 | Consistency: 0.100945 |\n",
      "Training epoch: 81 [1500/2000 (75%)] | D loss (A): 0.210370 | D loss (B): 0.060357 | G loss: 1.648519 | Consistency: 0.075674 |\n",
      "Training epoch: 81 [1600/2000 (80%)] | D loss (A): 0.133506 | D loss (B): 0.065697 | G loss: 1.630945 | Consistency: 0.095527 |\n",
      "Training epoch: 81 [1700/2000 (85%)] | D loss (A): 0.119458 | D loss (B): 0.036504 | G loss: 2.228280 | Consistency: 0.110146 |\n",
      "Training epoch: 81 [1800/2000 (90%)] | D loss (A): 0.161709 | D loss (B): 0.081406 | G loss: 1.406157 | Consistency: 0.091900 |\n",
      "Training epoch: 81 [1900/2000 (95%)] | D loss (A): 0.330115 | D loss (B): 0.133795 | G loss: 2.193222 | Consistency: 0.114902 |\n",
      "Training epoch: 82 [0/2000 (0%)] | D loss (A): 0.228367 | D loss (B): 0.090019 | G loss: 1.802069 | Consistency: 0.084635 |\n",
      "Training epoch: 82 [100/2000 (5%)] | D loss (A): 0.082720 | D loss (B): 0.051308 | G loss: 1.740345 | Consistency: 0.082089 |\n",
      "Training epoch: 82 [200/2000 (10%)] | D loss (A): 0.104148 | D loss (B): 0.122534 | G loss: 2.596235 | Consistency: 0.091174 |\n",
      "Training epoch: 82 [300/2000 (15%)] | D loss (A): 0.213409 | D loss (B): 0.107773 | G loss: 1.794754 | Consistency: 0.087213 |\n",
      "Training epoch: 82 [400/2000 (20%)] | D loss (A): 0.207499 | D loss (B): 0.253784 | G loss: 2.277830 | Consistency: 0.069321 |\n",
      "Training epoch: 82 [500/2000 (25%)] | D loss (A): 0.090896 | D loss (B): 0.150990 | G loss: 1.982974 | Consistency: 0.099349 |\n",
      "Training epoch: 82 [600/2000 (30%)] | D loss (A): 0.115626 | D loss (B): 0.241350 | G loss: 1.538093 | Consistency: 0.092724 |\n",
      "Training epoch: 82 [700/2000 (35%)] | D loss (A): 0.105682 | D loss (B): 0.141429 | G loss: 1.823874 | Consistency: 0.084326 |\n",
      "Training epoch: 82 [800/2000 (40%)] | D loss (A): 0.134584 | D loss (B): 0.148870 | G loss: 1.464260 | Consistency: 0.086046 |\n",
      "Training epoch: 82 [900/2000 (45%)] | D loss (A): 0.224597 | D loss (B): 0.167978 | G loss: 2.107903 | Consistency: 0.112936 |\n",
      "Training epoch: 82 [1000/2000 (50%)] | D loss (A): 0.214633 | D loss (B): 0.128450 | G loss: 1.822464 | Consistency: 0.104474 |\n",
      "Training epoch: 82 [1100/2000 (55%)] | D loss (A): 0.168757 | D loss (B): 0.155914 | G loss: 2.145951 | Consistency: 0.084379 |\n",
      "Training epoch: 82 [1200/2000 (60%)] | D loss (A): 0.081062 | D loss (B): 0.097567 | G loss: 1.336234 | Consistency: 0.093453 |\n",
      "Training epoch: 82 [1300/2000 (65%)] | D loss (A): 0.150529 | D loss (B): 0.077915 | G loss: 1.753766 | Consistency: 0.081566 |\n",
      "Training epoch: 82 [1400/2000 (70%)] | D loss (A): 0.030991 | D loss (B): 0.104266 | G loss: 1.821020 | Consistency: 0.084925 |\n",
      "Training epoch: 82 [1500/2000 (75%)] | D loss (A): 0.232279 | D loss (B): 0.155284 | G loss: 2.343550 | Consistency: 0.110287 |\n",
      "Training epoch: 82 [1600/2000 (80%)] | D loss (A): 0.154924 | D loss (B): 0.101622 | G loss: 1.990391 | Consistency: 0.091181 |\n",
      "Training epoch: 82 [1700/2000 (85%)] | D loss (A): 0.136119 | D loss (B): 0.150782 | G loss: 2.765871 | Consistency: 0.131812 |\n",
      "Training epoch: 82 [1800/2000 (90%)] | D loss (A): 0.183841 | D loss (B): 0.131407 | G loss: 1.744072 | Consistency: 0.086890 |\n",
      "Training epoch: 82 [1900/2000 (95%)] | D loss (A): 0.117120 | D loss (B): 0.177560 | G loss: 1.736421 | Consistency: 0.091515 |\n",
      "Training epoch: 83 [0/2000 (0%)] | D loss (A): 0.217879 | D loss (B): 0.055432 | G loss: 2.068546 | Consistency: 0.119155 |\n",
      "Training epoch: 83 [100/2000 (5%)] | D loss (A): 0.095074 | D loss (B): 0.178405 | G loss: 2.041115 | Consistency: 0.104464 |\n",
      "Training epoch: 83 [200/2000 (10%)] | D loss (A): 0.144705 | D loss (B): 0.104660 | G loss: 2.233555 | Consistency: 0.087276 |\n",
      "Training epoch: 83 [300/2000 (15%)] | D loss (A): 0.289689 | D loss (B): 0.084490 | G loss: 2.512491 | Consistency: 0.109644 |\n",
      "Training epoch: 83 [400/2000 (20%)] | D loss (A): 0.064865 | D loss (B): 0.053212 | G loss: 2.226066 | Consistency: 0.118636 |\n",
      "Training epoch: 83 [500/2000 (25%)] | D loss (A): 0.098674 | D loss (B): 0.107662 | G loss: 2.022283 | Consistency: 0.126303 |\n",
      "Training epoch: 83 [600/2000 (30%)] | D loss (A): 0.218670 | D loss (B): 0.111024 | G loss: 2.634555 | Consistency: 0.107235 |\n",
      "Training epoch: 83 [700/2000 (35%)] | D loss (A): 0.166757 | D loss (B): 0.030474 | G loss: 1.927290 | Consistency: 0.095966 |\n",
      "Training epoch: 83 [800/2000 (40%)] | D loss (A): 0.201819 | D loss (B): 0.155944 | G loss: 2.164503 | Consistency: 0.102565 |\n",
      "Training epoch: 83 [900/2000 (45%)] | D loss (A): 0.257926 | D loss (B): 0.059423 | G loss: 2.718633 | Consistency: 0.118896 |\n",
      "Training epoch: 83 [1000/2000 (50%)] | D loss (A): 0.247143 | D loss (B): 0.200098 | G loss: 1.891525 | Consistency: 0.095241 |\n",
      "Training epoch: 83 [1100/2000 (55%)] | D loss (A): 0.239991 | D loss (B): 0.167506 | G loss: 1.877632 | Consistency: 0.082868 |\n",
      "Training epoch: 83 [1200/2000 (60%)] | D loss (A): 0.124230 | D loss (B): 0.229865 | G loss: 1.456453 | Consistency: 0.081390 |\n",
      "Training epoch: 83 [1300/2000 (65%)] | D loss (A): 0.201479 | D loss (B): 0.063005 | G loss: 1.561784 | Consistency: 0.068712 |\n",
      "Training epoch: 83 [1400/2000 (70%)] | D loss (A): 0.201459 | D loss (B): 0.191064 | G loss: 2.004704 | Consistency: 0.081534 |\n",
      "Training epoch: 83 [1500/2000 (75%)] | D loss (A): 0.076233 | D loss (B): 0.140718 | G loss: 1.976757 | Consistency: 0.106589 |\n",
      "Training epoch: 83 [1600/2000 (80%)] | D loss (A): 0.296162 | D loss (B): 0.212574 | G loss: 2.111644 | Consistency: 0.106534 |\n",
      "Training epoch: 83 [1700/2000 (85%)] | D loss (A): 0.121050 | D loss (B): 0.108687 | G loss: 1.776660 | Consistency: 0.082681 |\n",
      "Training epoch: 83 [1800/2000 (90%)] | D loss (A): 0.085878 | D loss (B): 0.191829 | G loss: 1.988106 | Consistency: 0.096404 |\n",
      "Training epoch: 83 [1900/2000 (95%)] | D loss (A): 0.127037 | D loss (B): 0.085498 | G loss: 1.989120 | Consistency: 0.099454 |\n",
      "Training epoch: 84 [0/2000 (0%)] | D loss (A): 0.178467 | D loss (B): 0.183108 | G loss: 2.363627 | Consistency: 0.109134 |\n",
      "Training epoch: 84 [100/2000 (5%)] | D loss (A): 0.057870 | D loss (B): 0.103322 | G loss: 2.433781 | Consistency: 0.110132 |\n",
      "Training epoch: 84 [200/2000 (10%)] | D loss (A): 0.166930 | D loss (B): 0.128659 | G loss: 1.852434 | Consistency: 0.088535 |\n",
      "Training epoch: 84 [300/2000 (15%)] | D loss (A): 0.127389 | D loss (B): 0.342736 | G loss: 3.277680 | Consistency: 0.224709 |\n",
      "Training epoch: 84 [400/2000 (20%)] | D loss (A): 0.176665 | D loss (B): 0.066966 | G loss: 1.718676 | Consistency: 0.073416 |\n",
      "Training epoch: 84 [500/2000 (25%)] | D loss (A): 0.332414 | D loss (B): 0.095649 | G loss: 2.609932 | Consistency: 0.097677 |\n",
      "Training epoch: 84 [600/2000 (30%)] | D loss (A): 0.082964 | D loss (B): 0.090071 | G loss: 1.141213 | Consistency: 0.075173 |\n",
      "Training epoch: 84 [700/2000 (35%)] | D loss (A): 0.157004 | D loss (B): 0.150124 | G loss: 2.142783 | Consistency: 0.106072 |\n",
      "Training epoch: 84 [800/2000 (40%)] | D loss (A): 0.111947 | D loss (B): 0.409097 | G loss: 2.331610 | Consistency: 0.107942 |\n",
      "Training epoch: 84 [900/2000 (45%)] | D loss (A): 0.148322 | D loss (B): 0.206234 | G loss: 1.923607 | Consistency: 0.086085 |\n",
      "Training epoch: 84 [1000/2000 (50%)] | D loss (A): 0.169799 | D loss (B): 0.135155 | G loss: 2.481172 | Consistency: 0.119351 |\n",
      "Training epoch: 84 [1100/2000 (55%)] | D loss (A): 0.164801 | D loss (B): 0.077067 | G loss: 2.931938 | Consistency: 0.111816 |\n",
      "Training epoch: 84 [1200/2000 (60%)] | D loss (A): 0.183854 | D loss (B): 0.170142 | G loss: 1.669323 | Consistency: 0.079595 |\n",
      "Training epoch: 84 [1300/2000 (65%)] | D loss (A): 0.095003 | D loss (B): 0.201917 | G loss: 1.753390 | Consistency: 0.092140 |\n",
      "Training epoch: 84 [1400/2000 (70%)] | D loss (A): 0.148648 | D loss (B): 0.191315 | G loss: 2.169255 | Consistency: 0.091855 |\n",
      "Training epoch: 84 [1500/2000 (75%)] | D loss (A): 0.267769 | D loss (B): 0.084985 | G loss: 1.814946 | Consistency: 0.094602 |\n",
      "Training epoch: 84 [1600/2000 (80%)] | D loss (A): 0.158579 | D loss (B): 0.124270 | G loss: 2.109007 | Consistency: 0.107356 |\n",
      "Training epoch: 84 [1700/2000 (85%)] | D loss (A): 0.177400 | D loss (B): 0.097890 | G loss: 1.456367 | Consistency: 0.083822 |\n",
      "Training epoch: 84 [1800/2000 (90%)] | D loss (A): 0.155104 | D loss (B): 0.152005 | G loss: 2.300246 | Consistency: 0.116516 |\n",
      "Training epoch: 84 [1900/2000 (95%)] | D loss (A): 0.306058 | D loss (B): 0.160010 | G loss: 1.960674 | Consistency: 0.112214 |\n",
      "Training epoch: 85 [0/2000 (0%)] | D loss (A): 0.147582 | D loss (B): 0.074576 | G loss: 2.002727 | Consistency: 0.111647 |\n",
      "Training epoch: 85 [100/2000 (5%)] | D loss (A): 0.366224 | D loss (B): 0.252779 | G loss: 1.778031 | Consistency: 0.081177 |\n",
      "Training epoch: 85 [200/2000 (10%)] | D loss (A): 0.205593 | D loss (B): 0.111418 | G loss: 2.220618 | Consistency: 0.096119 |\n",
      "Training epoch: 85 [300/2000 (15%)] | D loss (A): 0.141072 | D loss (B): 0.214038 | G loss: 1.926379 | Consistency: 0.096473 |\n",
      "Training epoch: 85 [400/2000 (20%)] | D loss (A): 0.251603 | D loss (B): 0.048187 | G loss: 2.154933 | Consistency: 0.113655 |\n",
      "Training epoch: 85 [500/2000 (25%)] | D loss (A): 0.187752 | D loss (B): 0.162424 | G loss: 1.822542 | Consistency: 0.079140 |\n",
      "Training epoch: 85 [600/2000 (30%)] | D loss (A): 0.265055 | D loss (B): 0.061952 | G loss: 2.279178 | Consistency: 0.115396 |\n",
      "Training epoch: 85 [700/2000 (35%)] | D loss (A): 0.136151 | D loss (B): 0.186470 | G loss: 1.947850 | Consistency: 0.088650 |\n",
      "Training epoch: 85 [800/2000 (40%)] | D loss (A): 0.087327 | D loss (B): 0.098580 | G loss: 2.059991 | Consistency: 0.133501 |\n",
      "Training epoch: 85 [900/2000 (45%)] | D loss (A): 0.204431 | D loss (B): 0.123853 | G loss: 1.483265 | Consistency: 0.099638 |\n",
      "Training epoch: 85 [1000/2000 (50%)] | D loss (A): 0.157494 | D loss (B): 0.072271 | G loss: 2.105886 | Consistency: 0.108826 |\n",
      "Training epoch: 85 [1100/2000 (55%)] | D loss (A): 0.132028 | D loss (B): 0.123878 | G loss: 1.280403 | Consistency: 0.087604 |\n",
      "Training epoch: 85 [1200/2000 (60%)] | D loss (A): 0.115911 | D loss (B): 0.257703 | G loss: 1.664955 | Consistency: 0.080905 |\n",
      "Training epoch: 85 [1300/2000 (65%)] | D loss (A): 0.281547 | D loss (B): 0.083721 | G loss: 3.044570 | Consistency: 0.179123 |\n",
      "Training epoch: 85 [1400/2000 (70%)] | D loss (A): 0.391611 | D loss (B): 0.131089 | G loss: 2.440430 | Consistency: 0.151747 |\n",
      "Training epoch: 85 [1500/2000 (75%)] | D loss (A): 0.198968 | D loss (B): 0.101936 | G loss: 2.853310 | Consistency: 0.167070 |\n",
      "Training epoch: 85 [1600/2000 (80%)] | D loss (A): 0.192663 | D loss (B): 0.101765 | G loss: 2.027181 | Consistency: 0.099125 |\n",
      "Training epoch: 85 [1700/2000 (85%)] | D loss (A): 0.182501 | D loss (B): 0.113965 | G loss: 1.598835 | Consistency: 0.089538 |\n",
      "Training epoch: 85 [1800/2000 (90%)] | D loss (A): 0.197765 | D loss (B): 0.299489 | G loss: 2.109099 | Consistency: 0.117079 |\n",
      "Training epoch: 85 [1900/2000 (95%)] | D loss (A): 0.319179 | D loss (B): 0.147621 | G loss: 1.650911 | Consistency: 0.089460 |\n",
      "Training epoch: 86 [0/2000 (0%)] | D loss (A): 0.252693 | D loss (B): 0.174162 | G loss: 1.519453 | Consistency: 0.083405 |\n",
      "Training epoch: 86 [100/2000 (5%)] | D loss (A): 0.214484 | D loss (B): 0.178611 | G loss: 1.489580 | Consistency: 0.085174 |\n",
      "Training epoch: 86 [200/2000 (10%)] | D loss (A): 0.271532 | D loss (B): 0.157426 | G loss: 1.710866 | Consistency: 0.088149 |\n",
      "Training epoch: 86 [300/2000 (15%)] | D loss (A): 0.392690 | D loss (B): 0.272163 | G loss: 1.442329 | Consistency: 0.083747 |\n",
      "Training epoch: 86 [400/2000 (20%)] | D loss (A): 0.167885 | D loss (B): 0.038622 | G loss: 2.023976 | Consistency: 0.093972 |\n",
      "Training epoch: 86 [500/2000 (25%)] | D loss (A): 0.176678 | D loss (B): 0.173826 | G loss: 1.521418 | Consistency: 0.085774 |\n",
      "Training epoch: 86 [600/2000 (30%)] | D loss (A): 0.281878 | D loss (B): 0.142540 | G loss: 1.486554 | Consistency: 0.099701 |\n",
      "Training epoch: 86 [700/2000 (35%)] | D loss (A): 0.225753 | D loss (B): 0.129577 | G loss: 1.268558 | Consistency: 0.065597 |\n",
      "Training epoch: 86 [800/2000 (40%)] | D loss (A): 0.202335 | D loss (B): 0.085769 | G loss: 1.977765 | Consistency: 0.085977 |\n",
      "Training epoch: 86 [900/2000 (45%)] | D loss (A): 0.246249 | D loss (B): 0.063891 | G loss: 1.634515 | Consistency: 0.111574 |\n",
      "Training epoch: 86 [1000/2000 (50%)] | D loss (A): 0.276389 | D loss (B): 0.148547 | G loss: 1.869901 | Consistency: 0.110028 |\n",
      "Training epoch: 86 [1100/2000 (55%)] | D loss (A): 0.223197 | D loss (B): 0.343468 | G loss: 1.578800 | Consistency: 0.092409 |\n",
      "Training epoch: 86 [1200/2000 (60%)] | D loss (A): 0.247756 | D loss (B): 0.215205 | G loss: 1.701756 | Consistency: 0.083473 |\n",
      "Training epoch: 86 [1300/2000 (65%)] | D loss (A): 0.100006 | D loss (B): 0.183664 | G loss: 1.595145 | Consistency: 0.098634 |\n",
      "Training epoch: 86 [1400/2000 (70%)] | D loss (A): 0.259320 | D loss (B): 0.031000 | G loss: 1.556701 | Consistency: 0.091589 |\n",
      "Training epoch: 86 [1500/2000 (75%)] | D loss (A): 0.301879 | D loss (B): 0.080889 | G loss: 1.335024 | Consistency: 0.083455 |\n",
      "Training epoch: 86 [1600/2000 (80%)] | D loss (A): 0.219373 | D loss (B): 0.399472 | G loss: 1.554525 | Consistency: 0.077108 |\n",
      "Training epoch: 86 [1700/2000 (85%)] | D loss (A): 0.163688 | D loss (B): 0.070499 | G loss: 1.838452 | Consistency: 0.116797 |\n",
      "Training epoch: 86 [1800/2000 (90%)] | D loss (A): 0.138101 | D loss (B): 0.122562 | G loss: 1.926198 | Consistency: 0.085716 |\n",
      "Training epoch: 86 [1900/2000 (95%)] | D loss (A): 0.177245 | D loss (B): 0.176707 | G loss: 1.455403 | Consistency: 0.073872 |\n",
      "Training epoch: 87 [0/2000 (0%)] | D loss (A): 0.311860 | D loss (B): 0.176241 | G loss: 1.229479 | Consistency: 0.072843 |\n",
      "Training epoch: 87 [100/2000 (5%)] | D loss (A): 0.174061 | D loss (B): 0.104603 | G loss: 1.158645 | Consistency: 0.086715 |\n",
      "Training epoch: 87 [200/2000 (10%)] | D loss (A): 0.212057 | D loss (B): 0.110074 | G loss: 1.839760 | Consistency: 0.079261 |\n",
      "Training epoch: 87 [300/2000 (15%)] | D loss (A): 0.299381 | D loss (B): 0.180964 | G loss: 1.466676 | Consistency: 0.077758 |\n",
      "Training epoch: 87 [400/2000 (20%)] | D loss (A): 0.216439 | D loss (B): 0.190637 | G loss: 1.534837 | Consistency: 0.090914 |\n",
      "Training epoch: 87 [500/2000 (25%)] | D loss (A): 0.142089 | D loss (B): 0.062481 | G loss: 1.359655 | Consistency: 0.075291 |\n",
      "Training epoch: 87 [600/2000 (30%)] | D loss (A): 0.194328 | D loss (B): 0.151882 | G loss: 2.032871 | Consistency: 0.091167 |\n",
      "Training epoch: 87 [700/2000 (35%)] | D loss (A): 0.194031 | D loss (B): 0.077546 | G loss: 1.438409 | Consistency: 0.074520 |\n",
      "Training epoch: 87 [800/2000 (40%)] | D loss (A): 0.135386 | D loss (B): 0.117881 | G loss: 1.471467 | Consistency: 0.082466 |\n",
      "Training epoch: 87 [900/2000 (45%)] | D loss (A): 0.145968 | D loss (B): 0.207520 | G loss: 1.798589 | Consistency: 0.085123 |\n",
      "Training epoch: 87 [1000/2000 (50%)] | D loss (A): 0.113410 | D loss (B): 0.108113 | G loss: 2.245971 | Consistency: 0.102736 |\n",
      "Training epoch: 87 [1100/2000 (55%)] | D loss (A): 0.110283 | D loss (B): 0.047146 | G loss: 2.396336 | Consistency: 0.106526 |\n",
      "Training epoch: 87 [1200/2000 (60%)] | D loss (A): 0.221200 | D loss (B): 0.138530 | G loss: 2.090969 | Consistency: 0.113072 |\n",
      "Training epoch: 87 [1300/2000 (65%)] | D loss (A): 0.178962 | D loss (B): 0.166286 | G loss: 1.875163 | Consistency: 0.091671 |\n",
      "Training epoch: 87 [1400/2000 (70%)] | D loss (A): 0.149560 | D loss (B): 0.040029 | G loss: 2.319146 | Consistency: 0.104301 |\n",
      "Training epoch: 87 [1500/2000 (75%)] | D loss (A): 0.245222 | D loss (B): 0.150941 | G loss: 2.484860 | Consistency: 0.103768 |\n",
      "Training epoch: 87 [1600/2000 (80%)] | D loss (A): 0.186477 | D loss (B): 0.124694 | G loss: 2.425686 | Consistency: 0.101302 |\n",
      "Training epoch: 87 [1700/2000 (85%)] | D loss (A): 0.084469 | D loss (B): 0.150530 | G loss: 1.898381 | Consistency: 0.087709 |\n",
      "Training epoch: 87 [1800/2000 (90%)] | D loss (A): 0.102959 | D loss (B): 0.194738 | G loss: 2.147251 | Consistency: 0.093610 |\n",
      "Training epoch: 87 [1900/2000 (95%)] | D loss (A): 0.046768 | D loss (B): 0.131552 | G loss: 2.087885 | Consistency: 0.082536 |\n",
      "Training epoch: 88 [0/2000 (0%)] | D loss (A): 0.184916 | D loss (B): 0.128996 | G loss: 1.695320 | Consistency: 0.091974 |\n",
      "Training epoch: 88 [100/2000 (5%)] | D loss (A): 0.140864 | D loss (B): 0.049506 | G loss: 1.874508 | Consistency: 0.103382 |\n",
      "Training epoch: 88 [200/2000 (10%)] | D loss (A): 0.246748 | D loss (B): 0.063758 | G loss: 2.026882 | Consistency: 0.093746 |\n",
      "Training epoch: 88 [300/2000 (15%)] | D loss (A): 0.240249 | D loss (B): 0.128229 | G loss: 2.227915 | Consistency: 0.096797 |\n",
      "Training epoch: 88 [400/2000 (20%)] | D loss (A): 0.199775 | D loss (B): 0.102850 | G loss: 1.933200 | Consistency: 0.080284 |\n",
      "Training epoch: 88 [500/2000 (25%)] | D loss (A): 0.212434 | D loss (B): 0.166723 | G loss: 1.951529 | Consistency: 0.090448 |\n",
      "Training epoch: 88 [600/2000 (30%)] | D loss (A): 0.164996 | D loss (B): 0.067465 | G loss: 1.627683 | Consistency: 0.088605 |\n",
      "Training epoch: 88 [700/2000 (35%)] | D loss (A): 0.092749 | D loss (B): 0.063530 | G loss: 2.681581 | Consistency: 0.138834 |\n",
      "Training epoch: 88 [800/2000 (40%)] | D loss (A): 0.117999 | D loss (B): 0.218155 | G loss: 1.629939 | Consistency: 0.122186 |\n",
      "Training epoch: 88 [900/2000 (45%)] | D loss (A): 0.070237 | D loss (B): 0.072130 | G loss: 1.825172 | Consistency: 0.088039 |\n",
      "Training epoch: 88 [1000/2000 (50%)] | D loss (A): 0.102908 | D loss (B): 0.161412 | G loss: 1.429801 | Consistency: 0.087987 |\n",
      "Training epoch: 88 [1100/2000 (55%)] | D loss (A): 0.100376 | D loss (B): 0.241651 | G loss: 2.521514 | Consistency: 0.094287 |\n",
      "Training epoch: 88 [1200/2000 (60%)] | D loss (A): 0.182866 | D loss (B): 0.087907 | G loss: 2.659301 | Consistency: 0.114795 |\n",
      "Training epoch: 88 [1300/2000 (65%)] | D loss (A): 0.170656 | D loss (B): 0.137537 | G loss: 1.830394 | Consistency: 0.088295 |\n",
      "Training epoch: 88 [1400/2000 (70%)] | D loss (A): 0.230291 | D loss (B): 0.087846 | G loss: 1.708103 | Consistency: 0.084440 |\n",
      "Training epoch: 88 [1500/2000 (75%)] | D loss (A): 0.101665 | D loss (B): 0.059490 | G loss: 1.667790 | Consistency: 0.101468 |\n",
      "Training epoch: 88 [1600/2000 (80%)] | D loss (A): 0.139535 | D loss (B): 0.042152 | G loss: 1.676777 | Consistency: 0.104276 |\n",
      "Training epoch: 88 [1700/2000 (85%)] | D loss (A): 0.150718 | D loss (B): 0.337854 | G loss: 3.035384 | Consistency: 0.126145 |\n",
      "Training epoch: 88 [1800/2000 (90%)] | D loss (A): 0.169577 | D loss (B): 0.222635 | G loss: 2.457153 | Consistency: 0.139592 |\n",
      "Training epoch: 88 [1900/2000 (95%)] | D loss (A): 0.213546 | D loss (B): 0.249125 | G loss: 1.627609 | Consistency: 0.096729 |\n",
      "Training epoch: 89 [0/2000 (0%)] | D loss (A): 0.144504 | D loss (B): 0.428760 | G loss: 1.879212 | Consistency: 0.101990 |\n",
      "Training epoch: 89 [100/2000 (5%)] | D loss (A): 0.185346 | D loss (B): 0.308524 | G loss: 1.792570 | Consistency: 0.096634 |\n",
      "Training epoch: 89 [200/2000 (10%)] | D loss (A): 0.153492 | D loss (B): 0.159413 | G loss: 1.717603 | Consistency: 0.099699 |\n",
      "Training epoch: 89 [300/2000 (15%)] | D loss (A): 0.099357 | D loss (B): 0.299355 | G loss: 1.287061 | Consistency: 0.079609 |\n",
      "Training epoch: 89 [400/2000 (20%)] | D loss (A): 0.261885 | D loss (B): 0.195638 | G loss: 1.714784 | Consistency: 0.081909 |\n",
      "Training epoch: 89 [500/2000 (25%)] | D loss (A): 0.179179 | D loss (B): 0.268822 | G loss: 1.199066 | Consistency: 0.074530 |\n",
      "Training epoch: 89 [600/2000 (30%)] | D loss (A): 0.269033 | D loss (B): 0.189081 | G loss: 1.256050 | Consistency: 0.077533 |\n",
      "Training epoch: 89 [700/2000 (35%)] | D loss (A): 0.215265 | D loss (B): 0.256332 | G loss: 1.158038 | Consistency: 0.075766 |\n",
      "Training epoch: 89 [800/2000 (40%)] | D loss (A): 0.174558 | D loss (B): 0.126690 | G loss: 1.145413 | Consistency: 0.075786 |\n",
      "Training epoch: 89 [900/2000 (45%)] | D loss (A): 0.214408 | D loss (B): 0.148496 | G loss: 1.637151 | Consistency: 0.105622 |\n",
      "Training epoch: 89 [1000/2000 (50%)] | D loss (A): 0.278967 | D loss (B): 0.128651 | G loss: 1.723790 | Consistency: 0.101167 |\n",
      "Training epoch: 89 [1100/2000 (55%)] | D loss (A): 0.275666 | D loss (B): 0.199951 | G loss: 1.340214 | Consistency: 0.078241 |\n",
      "Training epoch: 89 [1200/2000 (60%)] | D loss (A): 0.235389 | D loss (B): 0.252003 | G loss: 1.147525 | Consistency: 0.065613 |\n",
      "Training epoch: 89 [1300/2000 (65%)] | D loss (A): 0.301303 | D loss (B): 0.098888 | G loss: 1.196191 | Consistency: 0.075302 |\n",
      "Training epoch: 89 [1400/2000 (70%)] | D loss (A): 0.292929 | D loss (B): 0.196548 | G loss: 1.329263 | Consistency: 0.069086 |\n",
      "Training epoch: 89 [1500/2000 (75%)] | D loss (A): 0.178535 | D loss (B): 0.146656 | G loss: 1.415624 | Consistency: 0.076584 |\n",
      "Training epoch: 89 [1600/2000 (80%)] | D loss (A): 0.291323 | D loss (B): 0.219984 | G loss: 1.652364 | Consistency: 0.118603 |\n",
      "Training epoch: 89 [1700/2000 (85%)] | D loss (A): 0.242663 | D loss (B): 0.108665 | G loss: 1.809351 | Consistency: 0.098326 |\n",
      "Training epoch: 89 [1800/2000 (90%)] | D loss (A): 0.187199 | D loss (B): 0.184945 | G loss: 1.693398 | Consistency: 0.108473 |\n",
      "Training epoch: 89 [1900/2000 (95%)] | D loss (A): 0.189141 | D loss (B): 0.305393 | G loss: 1.580519 | Consistency: 0.102080 |\n",
      "Training epoch: 90 [0/2000 (0%)] | D loss (A): 0.193496 | D loss (B): 0.134159 | G loss: 1.450240 | Consistency: 0.091481 |\n",
      "Training epoch: 90 [100/2000 (5%)] | D loss (A): 0.216249 | D loss (B): 0.101128 | G loss: 1.839990 | Consistency: 0.093868 |\n",
      "Training epoch: 90 [200/2000 (10%)] | D loss (A): 0.206299 | D loss (B): 0.098038 | G loss: 1.097498 | Consistency: 0.083444 |\n",
      "Training epoch: 90 [300/2000 (15%)] | D loss (A): 0.165014 | D loss (B): 0.173426 | G loss: 1.383016 | Consistency: 0.075871 |\n",
      "Training epoch: 90 [400/2000 (20%)] | D loss (A): 0.206549 | D loss (B): 0.128993 | G loss: 1.610248 | Consistency: 0.074763 |\n",
      "Training epoch: 90 [500/2000 (25%)] | D loss (A): 0.198691 | D loss (B): 0.199138 | G loss: 1.416336 | Consistency: 0.069366 |\n",
      "Training epoch: 90 [600/2000 (30%)] | D loss (A): 0.144987 | D loss (B): 0.219175 | G loss: 1.535269 | Consistency: 0.088176 |\n",
      "Training epoch: 90 [700/2000 (35%)] | D loss (A): 0.185455 | D loss (B): 0.074253 | G loss: 1.548687 | Consistency: 0.092717 |\n",
      "Training epoch: 90 [800/2000 (40%)] | D loss (A): 0.163428 | D loss (B): 0.077398 | G loss: 2.009188 | Consistency: 0.089742 |\n",
      "Training epoch: 90 [900/2000 (45%)] | D loss (A): 0.205594 | D loss (B): 0.144204 | G loss: 1.466483 | Consistency: 0.087648 |\n",
      "Training epoch: 90 [1000/2000 (50%)] | D loss (A): 0.184004 | D loss (B): 0.154315 | G loss: 1.785971 | Consistency: 0.091378 |\n",
      "Training epoch: 90 [1100/2000 (55%)] | D loss (A): 0.113211 | D loss (B): 0.163883 | G loss: 1.516104 | Consistency: 0.074451 |\n",
      "Training epoch: 90 [1200/2000 (60%)] | D loss (A): 0.108270 | D loss (B): 0.052503 | G loss: 1.781509 | Consistency: 0.083925 |\n",
      "Training epoch: 90 [1300/2000 (65%)] | D loss (A): 0.168534 | D loss (B): 0.201099 | G loss: 1.241384 | Consistency: 0.072007 |\n",
      "Training epoch: 90 [1400/2000 (70%)] | D loss (A): 0.121589 | D loss (B): 0.142162 | G loss: 2.012853 | Consistency: 0.114822 |\n",
      "Training epoch: 90 [1500/2000 (75%)] | D loss (A): 0.143336 | D loss (B): 0.067834 | G loss: 2.007670 | Consistency: 0.094787 |\n",
      "Training epoch: 90 [1600/2000 (80%)] | D loss (A): 0.150952 | D loss (B): 0.089485 | G loss: 2.104919 | Consistency: 0.091013 |\n",
      "Training epoch: 90 [1700/2000 (85%)] | D loss (A): 0.144213 | D loss (B): 0.037854 | G loss: 1.976579 | Consistency: 0.117610 |\n",
      "Training epoch: 90 [1800/2000 (90%)] | D loss (A): 0.068816 | D loss (B): 0.060578 | G loss: 1.120581 | Consistency: 0.072320 |\n",
      "Training epoch: 90 [1900/2000 (95%)] | D loss (A): 0.222257 | D loss (B): 0.215701 | G loss: 1.831226 | Consistency: 0.079658 |\n",
      "Training epoch: 91 [0/2000 (0%)] | D loss (A): 0.116747 | D loss (B): 0.262567 | G loss: 1.619142 | Consistency: 0.088635 |\n",
      "Training epoch: 91 [100/2000 (5%)] | D loss (A): 0.054741 | D loss (B): 0.296288 | G loss: 2.110991 | Consistency: 0.108931 |\n",
      "Training epoch: 91 [200/2000 (10%)] | D loss (A): 0.243058 | D loss (B): 0.325496 | G loss: 1.591359 | Consistency: 0.083077 |\n",
      "Training epoch: 91 [300/2000 (15%)] | D loss (A): 0.117857 | D loss (B): 0.109949 | G loss: 2.083032 | Consistency: 0.092955 |\n",
      "Training epoch: 91 [400/2000 (20%)] | D loss (A): 0.177039 | D loss (B): 0.227298 | G loss: 2.295677 | Consistency: 0.100820 |\n",
      "Training epoch: 91 [500/2000 (25%)] | D loss (A): 0.044058 | D loss (B): 0.056554 | G loss: 2.996787 | Consistency: 0.144052 |\n",
      "Training epoch: 91 [600/2000 (30%)] | D loss (A): 0.122782 | D loss (B): 0.170164 | G loss: 1.650897 | Consistency: 0.075972 |\n",
      "Training epoch: 91 [700/2000 (35%)] | D loss (A): 0.169624 | D loss (B): 0.079156 | G loss: 2.239605 | Consistency: 0.097781 |\n",
      "Training epoch: 91 [800/2000 (40%)] | D loss (A): 0.120443 | D loss (B): 0.138795 | G loss: 1.765755 | Consistency: 0.071548 |\n",
      "Training epoch: 91 [900/2000 (45%)] | D loss (A): 0.488255 | D loss (B): 0.198614 | G loss: 1.665086 | Consistency: 0.090316 |\n",
      "Training epoch: 91 [1000/2000 (50%)] | D loss (A): 0.269496 | D loss (B): 0.073071 | G loss: 1.665722 | Consistency: 0.095533 |\n",
      "Training epoch: 91 [1100/2000 (55%)] | D loss (A): 0.147948 | D loss (B): 0.024995 | G loss: 1.955237 | Consistency: 0.090789 |\n",
      "Training epoch: 91 [1200/2000 (60%)] | D loss (A): 0.198007 | D loss (B): 0.046385 | G loss: 1.752468 | Consistency: 0.101429 |\n",
      "Training epoch: 91 [1300/2000 (65%)] | D loss (A): 0.281764 | D loss (B): 0.189181 | G loss: 1.680601 | Consistency: 0.083327 |\n",
      "Training epoch: 91 [1400/2000 (70%)] | D loss (A): 0.243339 | D loss (B): 0.095479 | G loss: 1.770579 | Consistency: 0.112021 |\n",
      "Training epoch: 91 [1500/2000 (75%)] | D loss (A): 0.161615 | D loss (B): 0.072362 | G loss: 1.387296 | Consistency: 0.080484 |\n",
      "Training epoch: 91 [1600/2000 (80%)] | D loss (A): 0.293801 | D loss (B): 0.059378 | G loss: 1.496182 | Consistency: 0.075689 |\n",
      "Training epoch: 91 [1700/2000 (85%)] | D loss (A): 0.130727 | D loss (B): 0.344291 | G loss: 2.004659 | Consistency: 0.099095 |\n",
      "Training epoch: 91 [1800/2000 (90%)] | D loss (A): 0.132716 | D loss (B): 0.056159 | G loss: 2.467265 | Consistency: 0.089840 |\n",
      "Training epoch: 91 [1900/2000 (95%)] | D loss (A): 0.078224 | D loss (B): 0.112607 | G loss: 1.659254 | Consistency: 0.087975 |\n",
      "Training epoch: 92 [0/2000 (0%)] | D loss (A): 0.062705 | D loss (B): 0.149815 | G loss: 1.749320 | Consistency: 0.092899 |\n",
      "Training epoch: 92 [100/2000 (5%)] | D loss (A): 0.042909 | D loss (B): 0.207470 | G loss: 1.774457 | Consistency: 0.074440 |\n",
      "Training epoch: 92 [200/2000 (10%)] | D loss (A): 0.255247 | D loss (B): 0.094351 | G loss: 2.626146 | Consistency: 0.143933 |\n",
      "Training epoch: 92 [300/2000 (15%)] | D loss (A): 0.207592 | D loss (B): 0.158886 | G loss: 1.821676 | Consistency: 0.082560 |\n",
      "Training epoch: 92 [400/2000 (20%)] | D loss (A): 0.258653 | D loss (B): 0.107657 | G loss: 1.831158 | Consistency: 0.095852 |\n",
      "Training epoch: 92 [500/2000 (25%)] | D loss (A): 0.274541 | D loss (B): 0.093211 | G loss: 2.360194 | Consistency: 0.104242 |\n",
      "Training epoch: 92 [600/2000 (30%)] | D loss (A): 0.133861 | D loss (B): 0.138427 | G loss: 1.850924 | Consistency: 0.083989 |\n",
      "Training epoch: 92 [700/2000 (35%)] | D loss (A): 0.183674 | D loss (B): 0.082606 | G loss: 2.486253 | Consistency: 0.089273 |\n",
      "Training epoch: 92 [800/2000 (40%)] | D loss (A): 0.181431 | D loss (B): 0.247994 | G loss: 1.559272 | Consistency: 0.094920 |\n",
      "Training epoch: 92 [900/2000 (45%)] | D loss (A): 0.164229 | D loss (B): 0.147358 | G loss: 1.995862 | Consistency: 0.087821 |\n",
      "Training epoch: 92 [1000/2000 (50%)] | D loss (A): 0.163145 | D loss (B): 0.057425 | G loss: 2.390307 | Consistency: 0.134768 |\n",
      "Training epoch: 92 [1100/2000 (55%)] | D loss (A): 0.288458 | D loss (B): 0.051130 | G loss: 2.552167 | Consistency: 0.089534 |\n",
      "Training epoch: 92 [1200/2000 (60%)] | D loss (A): 0.099199 | D loss (B): 0.046876 | G loss: 1.666721 | Consistency: 0.085851 |\n",
      "Training epoch: 92 [1300/2000 (65%)] | D loss (A): 0.211615 | D loss (B): 0.102702 | G loss: 2.038816 | Consistency: 0.108360 |\n",
      "Training epoch: 92 [1400/2000 (70%)] | D loss (A): 0.146887 | D loss (B): 0.116159 | G loss: 2.001371 | Consistency: 0.113638 |\n",
      "Training epoch: 92 [1500/2000 (75%)] | D loss (A): 0.188411 | D loss (B): 0.042033 | G loss: 1.701583 | Consistency: 0.095048 |\n",
      "Training epoch: 92 [1600/2000 (80%)] | D loss (A): 0.072328 | D loss (B): 0.208096 | G loss: 1.887589 | Consistency: 0.083611 |\n",
      "Training epoch: 92 [1700/2000 (85%)] | D loss (A): 0.191259 | D loss (B): 0.081211 | G loss: 1.591445 | Consistency: 0.063077 |\n",
      "Training epoch: 92 [1800/2000 (90%)] | D loss (A): 0.173128 | D loss (B): 0.096474 | G loss: 2.447156 | Consistency: 0.096930 |\n",
      "Training epoch: 92 [1900/2000 (95%)] | D loss (A): 0.112359 | D loss (B): 0.195893 | G loss: 2.186410 | Consistency: 0.097153 |\n",
      "Training epoch: 93 [0/2000 (0%)] | D loss (A): 0.273626 | D loss (B): 0.051828 | G loss: 2.000210 | Consistency: 0.094993 |\n",
      "Training epoch: 93 [100/2000 (5%)] | D loss (A): 0.089020 | D loss (B): 0.171425 | G loss: 2.256429 | Consistency: 0.086834 |\n",
      "Training epoch: 93 [200/2000 (10%)] | D loss (A): 0.085109 | D loss (B): 0.049610 | G loss: 2.299720 | Consistency: 0.110753 |\n",
      "Training epoch: 93 [300/2000 (15%)] | D loss (A): 0.166212 | D loss (B): 0.102258 | G loss: 1.701162 | Consistency: 0.104139 |\n",
      "Training epoch: 93 [400/2000 (20%)] | D loss (A): 0.159160 | D loss (B): 0.106016 | G loss: 1.585332 | Consistency: 0.092652 |\n",
      "Training epoch: 93 [500/2000 (25%)] | D loss (A): 0.134136 | D loss (B): 0.112321 | G loss: 2.219074 | Consistency: 0.102959 |\n",
      "Training epoch: 93 [600/2000 (30%)] | D loss (A): 0.057083 | D loss (B): 0.238875 | G loss: 2.491569 | Consistency: 0.115303 |\n",
      "Training epoch: 93 [700/2000 (35%)] | D loss (A): 0.216343 | D loss (B): 0.119546 | G loss: 2.403234 | Consistency: 0.107985 |\n",
      "Training epoch: 93 [800/2000 (40%)] | D loss (A): 0.177344 | D loss (B): 0.080854 | G loss: 2.018322 | Consistency: 0.111711 |\n",
      "Training epoch: 93 [900/2000 (45%)] | D loss (A): 0.196276 | D loss (B): 0.074704 | G loss: 2.052725 | Consistency: 0.098242 |\n",
      "Training epoch: 93 [1000/2000 (50%)] | D loss (A): 0.155306 | D loss (B): 0.133525 | G loss: 1.757507 | Consistency: 0.070050 |\n",
      "Training epoch: 93 [1100/2000 (55%)] | D loss (A): 0.185573 | D loss (B): 0.165882 | G loss: 2.261229 | Consistency: 0.091443 |\n",
      "Training epoch: 93 [1200/2000 (60%)] | D loss (A): 0.221378 | D loss (B): 0.177329 | G loss: 2.043497 | Consistency: 0.084726 |\n",
      "Training epoch: 93 [1300/2000 (65%)] | D loss (A): 0.086845 | D loss (B): 0.035470 | G loss: 1.677546 | Consistency: 0.090908 |\n",
      "Training epoch: 93 [1400/2000 (70%)] | D loss (A): 0.150515 | D loss (B): 0.332014 | G loss: 1.550886 | Consistency: 0.074535 |\n",
      "Training epoch: 93 [1500/2000 (75%)] | D loss (A): 0.316696 | D loss (B): 0.100484 | G loss: 1.811605 | Consistency: 0.077707 |\n",
      "Training epoch: 93 [1600/2000 (80%)] | D loss (A): 0.176634 | D loss (B): 0.134026 | G loss: 2.203633 | Consistency: 0.116211 |\n",
      "Training epoch: 93 [1700/2000 (85%)] | D loss (A): 0.180310 | D loss (B): 0.299357 | G loss: 1.916029 | Consistency: 0.078115 |\n",
      "Training epoch: 93 [1800/2000 (90%)] | D loss (A): 0.116638 | D loss (B): 0.187787 | G loss: 1.886385 | Consistency: 0.079594 |\n",
      "Training epoch: 93 [1900/2000 (95%)] | D loss (A): 0.289606 | D loss (B): 0.082149 | G loss: 1.870806 | Consistency: 0.100396 |\n",
      "Training epoch: 94 [0/2000 (0%)] | D loss (A): 0.085951 | D loss (B): 0.270087 | G loss: 1.647219 | Consistency: 0.083648 |\n",
      "Training epoch: 94 [100/2000 (5%)] | D loss (A): 0.092851 | D loss (B): 0.184290 | G loss: 1.932165 | Consistency: 0.069331 |\n",
      "Training epoch: 94 [200/2000 (10%)] | D loss (A): 0.148182 | D loss (B): 0.219143 | G loss: 1.671754 | Consistency: 0.070677 |\n",
      "Training epoch: 94 [300/2000 (15%)] | D loss (A): 0.186365 | D loss (B): 0.298168 | G loss: 2.151537 | Consistency: 0.076409 |\n",
      "Training epoch: 94 [400/2000 (20%)] | D loss (A): 0.315674 | D loss (B): 0.162743 | G loss: 1.462490 | Consistency: 0.096168 |\n",
      "Training epoch: 94 [500/2000 (25%)] | D loss (A): 0.188989 | D loss (B): 0.033722 | G loss: 2.519218 | Consistency: 0.122402 |\n",
      "Training epoch: 94 [600/2000 (30%)] | D loss (A): 0.148345 | D loss (B): 0.273944 | G loss: 2.444728 | Consistency: 0.111420 |\n",
      "Training epoch: 94 [700/2000 (35%)] | D loss (A): 0.158198 | D loss (B): 0.086374 | G loss: 1.891738 | Consistency: 0.082746 |\n",
      "Training epoch: 94 [800/2000 (40%)] | D loss (A): 0.146451 | D loss (B): 0.192015 | G loss: 2.079872 | Consistency: 0.086260 |\n",
      "Training epoch: 94 [900/2000 (45%)] | D loss (A): 0.135329 | D loss (B): 0.154843 | G loss: 1.959543 | Consistency: 0.098300 |\n",
      "Training epoch: 94 [1000/2000 (50%)] | D loss (A): 0.058959 | D loss (B): 0.172469 | G loss: 2.285573 | Consistency: 0.110970 |\n",
      "Training epoch: 94 [1100/2000 (55%)] | D loss (A): 0.125159 | D loss (B): 0.102603 | G loss: 2.392157 | Consistency: 0.119248 |\n",
      "Training epoch: 94 [1200/2000 (60%)] | D loss (A): 0.171502 | D loss (B): 0.093545 | G loss: 1.865463 | Consistency: 0.102221 |\n",
      "Training epoch: 94 [1300/2000 (65%)] | D loss (A): 0.214330 | D loss (B): 0.183562 | G loss: 2.121247 | Consistency: 0.101136 |\n",
      "Training epoch: 94 [1400/2000 (70%)] | D loss (A): 0.242972 | D loss (B): 0.137217 | G loss: 1.829665 | Consistency: 0.075779 |\n",
      "Training epoch: 94 [1500/2000 (75%)] | D loss (A): 0.327480 | D loss (B): 0.184088 | G loss: 2.147902 | Consistency: 0.091964 |\n",
      "Training epoch: 94 [1600/2000 (80%)] | D loss (A): 0.167733 | D loss (B): 0.150407 | G loss: 1.950217 | Consistency: 0.085042 |\n",
      "Training epoch: 94 [1700/2000 (85%)] | D loss (A): 0.117808 | D loss (B): 0.135856 | G loss: 1.869024 | Consistency: 0.085828 |\n",
      "Training epoch: 94 [1800/2000 (90%)] | D loss (A): 0.217949 | D loss (B): 0.225502 | G loss: 2.098579 | Consistency: 0.080885 |\n",
      "Training epoch: 94 [1900/2000 (95%)] | D loss (A): 0.132944 | D loss (B): 0.165796 | G loss: 1.992717 | Consistency: 0.076930 |\n",
      "Training epoch: 95 [0/2000 (0%)] | D loss (A): 0.118549 | D loss (B): 0.308443 | G loss: 1.630099 | Consistency: 0.094564 |\n",
      "Training epoch: 95 [100/2000 (5%)] | D loss (A): 0.079539 | D loss (B): 0.124150 | G loss: 2.349243 | Consistency: 0.109100 |\n",
      "Training epoch: 95 [200/2000 (10%)] | D loss (A): 0.173880 | D loss (B): 0.051664 | G loss: 2.322674 | Consistency: 0.110834 |\n",
      "Training epoch: 95 [300/2000 (15%)] | D loss (A): 0.131647 | D loss (B): 0.270074 | G loss: 1.751104 | Consistency: 0.096620 |\n",
      "Training epoch: 95 [400/2000 (20%)] | D loss (A): 0.157361 | D loss (B): 0.163003 | G loss: 2.090448 | Consistency: 0.092022 |\n",
      "Training epoch: 95 [500/2000 (25%)] | D loss (A): 0.203699 | D loss (B): 0.117409 | G loss: 1.618241 | Consistency: 0.094524 |\n",
      "Training epoch: 95 [600/2000 (30%)] | D loss (A): 0.167847 | D loss (B): 0.115089 | G loss: 1.552957 | Consistency: 0.080188 |\n",
      "Training epoch: 95 [700/2000 (35%)] | D loss (A): 0.187992 | D loss (B): 0.044778 | G loss: 1.924558 | Consistency: 0.091022 |\n",
      "Training epoch: 95 [800/2000 (40%)] | D loss (A): 0.149427 | D loss (B): 0.065854 | G loss: 1.368070 | Consistency: 0.089924 |\n",
      "Training epoch: 95 [900/2000 (45%)] | D loss (A): 0.086512 | D loss (B): 0.098467 | G loss: 1.800093 | Consistency: 0.078715 |\n",
      "Training epoch: 95 [1000/2000 (50%)] | D loss (A): 0.268285 | D loss (B): 0.109827 | G loss: 2.024828 | Consistency: 0.097378 |\n",
      "Training epoch: 95 [1100/2000 (55%)] | D loss (A): 0.087629 | D loss (B): 0.064247 | G loss: 2.082042 | Consistency: 0.120533 |\n",
      "Training epoch: 95 [1200/2000 (60%)] | D loss (A): 0.134024 | D loss (B): 0.051884 | G loss: 1.702035 | Consistency: 0.105054 |\n",
      "Training epoch: 95 [1300/2000 (65%)] | D loss (A): 0.168407 | D loss (B): 0.060023 | G loss: 1.897039 | Consistency: 0.103146 |\n",
      "Training epoch: 95 [1400/2000 (70%)] | D loss (A): 0.278799 | D loss (B): 0.095302 | G loss: 1.312903 | Consistency: 0.075462 |\n",
      "Training epoch: 95 [1500/2000 (75%)] | D loss (A): 0.034817 | D loss (B): 0.176757 | G loss: 2.007483 | Consistency: 0.078225 |\n",
      "Training epoch: 95 [1600/2000 (80%)] | D loss (A): 0.049523 | D loss (B): 0.207503 | G loss: 1.868671 | Consistency: 0.096162 |\n",
      "Training epoch: 95 [1700/2000 (85%)] | D loss (A): 0.146778 | D loss (B): 0.092035 | G loss: 2.636141 | Consistency: 0.114004 |\n",
      "Training epoch: 95 [1800/2000 (90%)] | D loss (A): 0.159632 | D loss (B): 0.111099 | G loss: 2.230145 | Consistency: 0.099510 |\n",
      "Training epoch: 95 [1900/2000 (95%)] | D loss (A): 0.303693 | D loss (B): 0.143211 | G loss: 2.038325 | Consistency: 0.089382 |\n",
      "Training epoch: 96 [0/2000 (0%)] | D loss (A): 0.164640 | D loss (B): 0.128394 | G loss: 1.351992 | Consistency: 0.085225 |\n",
      "Training epoch: 96 [100/2000 (5%)] | D loss (A): 0.109989 | D loss (B): 0.052252 | G loss: 2.686816 | Consistency: 0.128579 |\n",
      "Training epoch: 96 [200/2000 (10%)] | D loss (A): 0.085052 | D loss (B): 0.091682 | G loss: 1.443541 | Consistency: 0.090392 |\n",
      "Training epoch: 96 [300/2000 (15%)] | D loss (A): 0.187662 | D loss (B): 0.142396 | G loss: 2.068388 | Consistency: 0.077427 |\n",
      "Training epoch: 96 [400/2000 (20%)] | D loss (A): 0.190441 | D loss (B): 0.075734 | G loss: 2.624476 | Consistency: 0.098371 |\n",
      "Training epoch: 96 [500/2000 (25%)] | D loss (A): 0.130281 | D loss (B): 0.039777 | G loss: 1.943297 | Consistency: 0.100765 |\n",
      "Training epoch: 96 [600/2000 (30%)] | D loss (A): 0.158002 | D loss (B): 0.104123 | G loss: 1.973640 | Consistency: 0.094025 |\n",
      "Training epoch: 96 [700/2000 (35%)] | D loss (A): 0.201783 | D loss (B): 0.057237 | G loss: 2.026888 | Consistency: 0.094046 |\n",
      "Training epoch: 96 [800/2000 (40%)] | D loss (A): 0.076912 | D loss (B): 0.140279 | G loss: 1.570706 | Consistency: 0.087609 |\n",
      "Training epoch: 96 [900/2000 (45%)] | D loss (A): 0.148859 | D loss (B): 0.086708 | G loss: 1.326110 | Consistency: 0.078036 |\n",
      "Training epoch: 96 [1000/2000 (50%)] | D loss (A): 0.227433 | D loss (B): 0.124362 | G loss: 1.898156 | Consistency: 0.090016 |\n",
      "Training epoch: 96 [1100/2000 (55%)] | D loss (A): 0.199353 | D loss (B): 0.131696 | G loss: 1.967979 | Consistency: 0.086001 |\n",
      "Training epoch: 96 [1200/2000 (60%)] | D loss (A): 0.148482 | D loss (B): 0.121630 | G loss: 1.905347 | Consistency: 0.099586 |\n",
      "Training epoch: 96 [1300/2000 (65%)] | D loss (A): 0.130835 | D loss (B): 0.176978 | G loss: 1.513258 | Consistency: 0.077950 |\n",
      "Training epoch: 96 [1400/2000 (70%)] | D loss (A): 0.136622 | D loss (B): 0.172185 | G loss: 1.910954 | Consistency: 0.056940 |\n",
      "Training epoch: 96 [1500/2000 (75%)] | D loss (A): 0.051108 | D loss (B): 0.064002 | G loss: 2.699808 | Consistency: 0.103036 |\n",
      "Training epoch: 96 [1600/2000 (80%)] | D loss (A): 0.200133 | D loss (B): 0.150796 | G loss: 2.074586 | Consistency: 0.073120 |\n",
      "Training epoch: 96 [1700/2000 (85%)] | D loss (A): 0.230954 | D loss (B): 0.170486 | G loss: 1.920586 | Consistency: 0.116413 |\n",
      "Training epoch: 96 [1800/2000 (90%)] | D loss (A): 0.065572 | D loss (B): 0.065918 | G loss: 2.274038 | Consistency: 0.131958 |\n",
      "Training epoch: 96 [1900/2000 (95%)] | D loss (A): 0.178939 | D loss (B): 0.098629 | G loss: 1.974115 | Consistency: 0.096496 |\n",
      "Training epoch: 97 [0/2000 (0%)] | D loss (A): 0.118571 | D loss (B): 0.155879 | G loss: 2.183065 | Consistency: 0.095567 |\n",
      "Training epoch: 97 [100/2000 (5%)] | D loss (A): 0.116475 | D loss (B): 0.156955 | G loss: 1.759979 | Consistency: 0.081148 |\n",
      "Training epoch: 97 [200/2000 (10%)] | D loss (A): 0.069832 | D loss (B): 0.045709 | G loss: 1.539032 | Consistency: 0.080088 |\n",
      "Training epoch: 97 [300/2000 (15%)] | D loss (A): 0.217334 | D loss (B): 0.151212 | G loss: 1.583408 | Consistency: 0.090539 |\n",
      "Training epoch: 97 [400/2000 (20%)] | D loss (A): 0.067434 | D loss (B): 0.058655 | G loss: 1.799210 | Consistency: 0.080698 |\n",
      "Training epoch: 97 [500/2000 (25%)] | D loss (A): 0.060078 | D loss (B): 0.186723 | G loss: 1.569481 | Consistency: 0.098427 |\n",
      "Training epoch: 97 [600/2000 (30%)] | D loss (A): 0.152282 | D loss (B): 0.228640 | G loss: 1.455849 | Consistency: 0.073606 |\n",
      "Training epoch: 97 [700/2000 (35%)] | D loss (A): 0.117464 | D loss (B): 0.089741 | G loss: 2.751930 | Consistency: 0.103580 |\n",
      "Training epoch: 97 [800/2000 (40%)] | D loss (A): 0.245971 | D loss (B): 0.064744 | G loss: 2.453193 | Consistency: 0.107104 |\n",
      "Training epoch: 97 [900/2000 (45%)] | D loss (A): 0.186580 | D loss (B): 0.147721 | G loss: 2.106650 | Consistency: 0.082112 |\n",
      "Training epoch: 97 [1000/2000 (50%)] | D loss (A): 0.148344 | D loss (B): 0.160921 | G loss: 2.084160 | Consistency: 0.113115 |\n",
      "Training epoch: 97 [1100/2000 (55%)] | D loss (A): 0.121458 | D loss (B): 0.151048 | G loss: 1.476546 | Consistency: 0.075551 |\n",
      "Training epoch: 97 [1200/2000 (60%)] | D loss (A): 0.212003 | D loss (B): 0.087636 | G loss: 1.973935 | Consistency: 0.068290 |\n",
      "Training epoch: 97 [1300/2000 (65%)] | D loss (A): 0.163716 | D loss (B): 0.047777 | G loss: 2.535275 | Consistency: 0.135754 |\n",
      "Training epoch: 97 [1400/2000 (70%)] | D loss (A): 0.142757 | D loss (B): 0.188949 | G loss: 2.328717 | Consistency: 0.130787 |\n",
      "Training epoch: 97 [1500/2000 (75%)] | D loss (A): 0.119543 | D loss (B): 0.108727 | G loss: 2.117567 | Consistency: 0.122717 |\n",
      "Training epoch: 97 [1600/2000 (80%)] | D loss (A): 0.060614 | D loss (B): 0.053609 | G loss: 2.353652 | Consistency: 0.113338 |\n",
      "Training epoch: 97 [1700/2000 (85%)] | D loss (A): 0.231982 | D loss (B): 0.090267 | G loss: 1.981600 | Consistency: 0.083053 |\n",
      "Training epoch: 97 [1800/2000 (90%)] | D loss (A): 0.118168 | D loss (B): 0.114666 | G loss: 2.634896 | Consistency: 0.105991 |\n",
      "Training epoch: 97 [1900/2000 (95%)] | D loss (A): 0.155050 | D loss (B): 0.094731 | G loss: 2.149035 | Consistency: 0.096311 |\n",
      "Training epoch: 98 [0/2000 (0%)] | D loss (A): 0.130236 | D loss (B): 0.110925 | G loss: 1.984426 | Consistency: 0.110876 |\n",
      "Training epoch: 98 [100/2000 (5%)] | D loss (A): 0.244761 | D loss (B): 0.116645 | G loss: 1.992809 | Consistency: 0.067334 |\n",
      "Training epoch: 98 [200/2000 (10%)] | D loss (A): 0.186425 | D loss (B): 0.090982 | G loss: 2.154797 | Consistency: 0.083104 |\n",
      "Training epoch: 98 [300/2000 (15%)] | D loss (A): 0.083225 | D loss (B): 0.123277 | G loss: 1.837501 | Consistency: 0.094536 |\n",
      "Training epoch: 98 [400/2000 (20%)] | D loss (A): 0.178885 | D loss (B): 0.144331 | G loss: 1.834289 | Consistency: 0.087909 |\n",
      "Training epoch: 98 [500/2000 (25%)] | D loss (A): 0.138294 | D loss (B): 0.131045 | G loss: 1.582777 | Consistency: 0.084906 |\n",
      "Training epoch: 98 [600/2000 (30%)] | D loss (A): 0.120759 | D loss (B): 0.077498 | G loss: 2.054774 | Consistency: 0.111495 |\n",
      "Training epoch: 98 [700/2000 (35%)] | D loss (A): 0.087901 | D loss (B): 0.269867 | G loss: 1.913182 | Consistency: 0.086811 |\n",
      "Training epoch: 98 [800/2000 (40%)] | D loss (A): 0.126677 | D loss (B): 0.108512 | G loss: 1.841081 | Consistency: 0.083137 |\n",
      "Training epoch: 98 [900/2000 (45%)] | D loss (A): 0.077491 | D loss (B): 0.033677 | G loss: 2.087380 | Consistency: 0.116016 |\n",
      "Training epoch: 98 [1000/2000 (50%)] | D loss (A): 0.195033 | D loss (B): 0.199338 | G loss: 2.201337 | Consistency: 0.105289 |\n",
      "Training epoch: 98 [1100/2000 (55%)] | D loss (A): 0.151362 | D loss (B): 0.091470 | G loss: 2.467479 | Consistency: 0.107508 |\n",
      "Training epoch: 98 [1200/2000 (60%)] | D loss (A): 0.263091 | D loss (B): 0.228385 | G loss: 2.222421 | Consistency: 0.099467 |\n",
      "Training epoch: 98 [1300/2000 (65%)] | D loss (A): 0.138376 | D loss (B): 0.194096 | G loss: 1.573092 | Consistency: 0.092944 |\n",
      "Training epoch: 98 [1400/2000 (70%)] | D loss (A): 0.079881 | D loss (B): 0.201134 | G loss: 1.470624 | Consistency: 0.084020 |\n",
      "Training epoch: 98 [1500/2000 (75%)] | D loss (A): 0.135716 | D loss (B): 0.251938 | G loss: 1.471484 | Consistency: 0.073920 |\n",
      "Training epoch: 98 [1600/2000 (80%)] | D loss (A): 0.142400 | D loss (B): 0.080077 | G loss: 1.962422 | Consistency: 0.072259 |\n",
      "Training epoch: 98 [1700/2000 (85%)] | D loss (A): 0.074032 | D loss (B): 0.054802 | G loss: 2.524825 | Consistency: 0.113903 |\n",
      "Training epoch: 98 [1800/2000 (90%)] | D loss (A): 0.093130 | D loss (B): 0.114603 | G loss: 2.303846 | Consistency: 0.073692 |\n",
      "Training epoch: 98 [1900/2000 (95%)] | D loss (A): 0.303067 | D loss (B): 0.149404 | G loss: 2.111716 | Consistency: 0.101439 |\n",
      "Training epoch: 99 [0/2000 (0%)] | D loss (A): 0.219405 | D loss (B): 0.144735 | G loss: 1.686592 | Consistency: 0.100057 |\n",
      "Training epoch: 99 [100/2000 (5%)] | D loss (A): 0.092154 | D loss (B): 0.223068 | G loss: 1.934350 | Consistency: 0.110176 |\n",
      "Training epoch: 99 [200/2000 (10%)] | D loss (A): 0.234837 | D loss (B): 0.171930 | G loss: 1.909743 | Consistency: 0.108957 |\n",
      "Training epoch: 99 [300/2000 (15%)] | D loss (A): 0.182430 | D loss (B): 0.138668 | G loss: 1.720794 | Consistency: 0.082376 |\n",
      "Training epoch: 99 [400/2000 (20%)] | D loss (A): 0.106500 | D loss (B): 0.142222 | G loss: 2.058620 | Consistency: 0.104206 |\n",
      "Training epoch: 99 [500/2000 (25%)] | D loss (A): 0.100929 | D loss (B): 0.078448 | G loss: 1.911720 | Consistency: 0.103784 |\n",
      "Training epoch: 99 [600/2000 (30%)] | D loss (A): 0.198534 | D loss (B): 0.093674 | G loss: 1.279996 | Consistency: 0.075561 |\n",
      "Training epoch: 99 [700/2000 (35%)] | D loss (A): 0.166301 | D loss (B): 0.051584 | G loss: 1.245043 | Consistency: 0.068044 |\n",
      "Training epoch: 99 [800/2000 (40%)] | D loss (A): 0.143053 | D loss (B): 0.158327 | G loss: 2.038733 | Consistency: 0.089598 |\n",
      "Training epoch: 99 [900/2000 (45%)] | D loss (A): 0.200036 | D loss (B): 0.063171 | G loss: 1.476954 | Consistency: 0.068073 |\n",
      "Training epoch: 99 [1000/2000 (50%)] | D loss (A): 0.213822 | D loss (B): 0.125185 | G loss: 2.359500 | Consistency: 0.096882 |\n",
      "Training epoch: 99 [1100/2000 (55%)] | D loss (A): 0.100377 | D loss (B): 0.219357 | G loss: 1.797116 | Consistency: 0.093608 |\n",
      "Training epoch: 99 [1200/2000 (60%)] | D loss (A): 0.117950 | D loss (B): 0.053293 | G loss: 2.230096 | Consistency: 0.101826 |\n",
      "Training epoch: 99 [1300/2000 (65%)] | D loss (A): 0.156344 | D loss (B): 0.074059 | G loss: 2.137608 | Consistency: 0.094692 |\n",
      "Training epoch: 99 [1400/2000 (70%)] | D loss (A): 0.233872 | D loss (B): 0.051673 | G loss: 1.555233 | Consistency: 0.073446 |\n",
      "Training epoch: 99 [1500/2000 (75%)] | D loss (A): 0.090396 | D loss (B): 0.183744 | G loss: 1.902673 | Consistency: 0.084532 |\n",
      "Training epoch: 99 [1600/2000 (80%)] | D loss (A): 0.112448 | D loss (B): 0.135415 | G loss: 2.643608 | Consistency: 0.098324 |\n",
      "Training epoch: 99 [1700/2000 (85%)] | D loss (A): 0.249446 | D loss (B): 0.225179 | G loss: 2.401804 | Consistency: 0.107698 |\n",
      "Training epoch: 99 [1800/2000 (90%)] | D loss (A): 0.086938 | D loss (B): 0.123615 | G loss: 1.467698 | Consistency: 0.090407 |\n",
      "Training epoch: 99 [1900/2000 (95%)] | D loss (A): 0.225512 | D loss (B): 0.128043 | G loss: 1.726068 | Consistency: 0.086258 |\n",
      "Training epoch: 100 [0/2000 (0%)] | D loss (A): 0.212153 | D loss (B): 0.136451 | G loss: 1.972305 | Consistency: 0.092643 |\n",
      "Training epoch: 100 [100/2000 (5%)] | D loss (A): 0.197350 | D loss (B): 0.049258 | G loss: 2.305902 | Consistency: 0.102519 |\n",
      "Training epoch: 100 [200/2000 (10%)] | D loss (A): 0.228936 | D loss (B): 0.034496 | G loss: 2.192735 | Consistency: 0.103056 |\n",
      "Training epoch: 100 [300/2000 (15%)] | D loss (A): 0.244781 | D loss (B): 0.091765 | G loss: 2.445393 | Consistency: 0.115061 |\n",
      "Training epoch: 100 [400/2000 (20%)] | D loss (A): 0.194003 | D loss (B): 0.119571 | G loss: 2.583628 | Consistency: 0.087864 |\n",
      "Training epoch: 100 [500/2000 (25%)] | D loss (A): 0.145781 | D loss (B): 0.103206 | G loss: 2.034950 | Consistency: 0.091938 |\n",
      "Training epoch: 100 [600/2000 (30%)] | D loss (A): 0.114183 | D loss (B): 0.246638 | G loss: 1.793974 | Consistency: 0.088368 |\n",
      "Training epoch: 100 [700/2000 (35%)] | D loss (A): 0.243399 | D loss (B): 0.065522 | G loss: 2.027350 | Consistency: 0.088628 |\n",
      "Training epoch: 100 [800/2000 (40%)] | D loss (A): 0.059299 | D loss (B): 0.192495 | G loss: 1.835850 | Consistency: 0.077945 |\n",
      "Training epoch: 100 [900/2000 (45%)] | D loss (A): 0.050787 | D loss (B): 0.069973 | G loss: 2.012868 | Consistency: 0.108319 |\n",
      "Training epoch: 100 [1000/2000 (50%)] | D loss (A): 0.107939 | D loss (B): 0.207356 | G loss: 1.852711 | Consistency: 0.095343 |\n",
      "Training epoch: 100 [1100/2000 (55%)] | D loss (A): 0.119536 | D loss (B): 0.202582 | G loss: 1.771945 | Consistency: 0.104984 |\n",
      "Training epoch: 100 [1200/2000 (60%)] | D loss (A): 0.168442 | D loss (B): 0.037010 | G loss: 2.137952 | Consistency: 0.097856 |\n",
      "Training epoch: 100 [1300/2000 (65%)] | D loss (A): 0.130548 | D loss (B): 0.157822 | G loss: 2.195748 | Consistency: 0.093310 |\n",
      "Training epoch: 100 [1400/2000 (70%)] | D loss (A): 0.136767 | D loss (B): 0.077805 | G loss: 2.297725 | Consistency: 0.091853 |\n",
      "Training epoch: 100 [1500/2000 (75%)] | D loss (A): 0.174433 | D loss (B): 0.137144 | G loss: 1.699570 | Consistency: 0.087828 |\n",
      "Training epoch: 100 [1600/2000 (80%)] | D loss (A): 0.079041 | D loss (B): 0.117729 | G loss: 2.245438 | Consistency: 0.107864 |\n",
      "Training epoch: 100 [1700/2000 (85%)] | D loss (A): 0.117364 | D loss (B): 0.224507 | G loss: 1.829489 | Consistency: 0.078785 |\n",
      "Training epoch: 100 [1800/2000 (90%)] | D loss (A): 0.286535 | D loss (B): 0.054712 | G loss: 2.603529 | Consistency: 0.095808 |\n",
      "Training epoch: 100 [1900/2000 (95%)] | D loss (A): 0.255477 | D loss (B): 0.128516 | G loss: 1.612608 | Consistency: 0.093184 |\n",
      "Training epoch: 101 [0/2000 (0%)] | D loss (A): 0.156242 | D loss (B): 0.171259 | G loss: 1.764333 | Consistency: 0.081011 |\n",
      "Training epoch: 101 [100/2000 (5%)] | D loss (A): 0.050274 | D loss (B): 0.075408 | G loss: 1.469004 | Consistency: 0.074027 |\n",
      "Training epoch: 101 [200/2000 (10%)] | D loss (A): 0.081126 | D loss (B): 0.051425 | G loss: 1.714924 | Consistency: 0.104375 |\n",
      "Training epoch: 101 [300/2000 (15%)] | D loss (A): 0.141456 | D loss (B): 0.090876 | G loss: 1.597964 | Consistency: 0.096001 |\n",
      "Training epoch: 101 [400/2000 (20%)] | D loss (A): 0.253765 | D loss (B): 0.083641 | G loss: 1.731905 | Consistency: 0.095876 |\n",
      "Training epoch: 101 [500/2000 (25%)] | D loss (A): 0.123974 | D loss (B): 0.051801 | G loss: 2.529674 | Consistency: 0.110733 |\n",
      "Training epoch: 101 [600/2000 (30%)] | D loss (A): 0.200895 | D loss (B): 0.177335 | G loss: 1.966368 | Consistency: 0.082248 |\n",
      "Training epoch: 101 [700/2000 (35%)] | D loss (A): 0.295618 | D loss (B): 0.100762 | G loss: 2.179323 | Consistency: 0.082179 |\n",
      "Training epoch: 101 [800/2000 (40%)] | D loss (A): 0.056249 | D loss (B): 0.079421 | G loss: 2.330129 | Consistency: 0.085096 |\n",
      "Training epoch: 101 [900/2000 (45%)] | D loss (A): 0.054843 | D loss (B): 0.124347 | G loss: 2.444128 | Consistency: 0.076997 |\n",
      "Training epoch: 101 [1000/2000 (50%)] | D loss (A): 0.162342 | D loss (B): 0.071121 | G loss: 1.737148 | Consistency: 0.081619 |\n",
      "Training epoch: 101 [1100/2000 (55%)] | D loss (A): 0.106187 | D loss (B): 0.060141 | G loss: 3.013155 | Consistency: 0.115814 |\n",
      "Training epoch: 101 [1200/2000 (60%)] | D loss (A): 0.181473 | D loss (B): 0.142808 | G loss: 2.638335 | Consistency: 0.115094 |\n",
      "Training epoch: 101 [1300/2000 (65%)] | D loss (A): 0.132528 | D loss (B): 0.260389 | G loss: 1.739128 | Consistency: 0.081441 |\n",
      "Training epoch: 101 [1400/2000 (70%)] | D loss (A): 0.168660 | D loss (B): 0.212805 | G loss: 2.185393 | Consistency: 0.083276 |\n",
      "Training epoch: 101 [1500/2000 (75%)] | D loss (A): 0.164022 | D loss (B): 0.127235 | G loss: 1.580058 | Consistency: 0.092276 |\n",
      "Training epoch: 101 [1600/2000 (80%)] | D loss (A): 0.195250 | D loss (B): 0.170440 | G loss: 2.244955 | Consistency: 0.090403 |\n",
      "Training epoch: 101 [1700/2000 (85%)] | D loss (A): 0.212583 | D loss (B): 0.163341 | G loss: 1.907565 | Consistency: 0.063292 |\n",
      "Training epoch: 101 [1800/2000 (90%)] | D loss (A): 0.158712 | D loss (B): 0.126982 | G loss: 2.110621 | Consistency: 0.063408 |\n",
      "Training epoch: 101 [1900/2000 (95%)] | D loss (A): 0.172533 | D loss (B): 0.221028 | G loss: 1.720811 | Consistency: 0.072992 |\n",
      "Training epoch: 102 [0/2000 (0%)] | D loss (A): 0.114378 | D loss (B): 0.231749 | G loss: 2.029173 | Consistency: 0.073326 |\n",
      "Training epoch: 102 [100/2000 (5%)] | D loss (A): 0.179546 | D loss (B): 0.099550 | G loss: 1.956546 | Consistency: 0.089663 |\n",
      "Training epoch: 102 [200/2000 (10%)] | D loss (A): 0.100435 | D loss (B): 0.113301 | G loss: 2.063256 | Consistency: 0.100569 |\n",
      "Training epoch: 102 [300/2000 (15%)] | D loss (A): 0.166707 | D loss (B): 0.093135 | G loss: 2.224902 | Consistency: 0.091699 |\n",
      "Training epoch: 102 [400/2000 (20%)] | D loss (A): 0.077170 | D loss (B): 0.103160 | G loss: 1.592862 | Consistency: 0.071881 |\n",
      "Training epoch: 102 [500/2000 (25%)] | D loss (A): 0.051988 | D loss (B): 0.104014 | G loss: 2.078531 | Consistency: 0.105987 |\n",
      "Training epoch: 102 [600/2000 (30%)] | D loss (A): 0.201830 | D loss (B): 0.064459 | G loss: 1.423680 | Consistency: 0.068475 |\n",
      "Training epoch: 102 [700/2000 (35%)] | D loss (A): 0.105833 | D loss (B): 0.153154 | G loss: 2.065614 | Consistency: 0.096246 |\n",
      "Training epoch: 102 [800/2000 (40%)] | D loss (A): 0.155513 | D loss (B): 0.280968 | G loss: 1.963754 | Consistency: 0.081019 |\n",
      "Training epoch: 102 [900/2000 (45%)] | D loss (A): 0.262223 | D loss (B): 0.189497 | G loss: 1.840933 | Consistency: 0.078558 |\n",
      "Training epoch: 102 [1000/2000 (50%)] | D loss (A): 0.322475 | D loss (B): 0.206363 | G loss: 1.558056 | Consistency: 0.084839 |\n",
      "Training epoch: 102 [1100/2000 (55%)] | D loss (A): 0.113364 | D loss (B): 0.201757 | G loss: 1.599248 | Consistency: 0.082188 |\n",
      "Training epoch: 102 [1200/2000 (60%)] | D loss (A): 0.193297 | D loss (B): 0.171295 | G loss: 1.740218 | Consistency: 0.089851 |\n",
      "Training epoch: 102 [1300/2000 (65%)] | D loss (A): 0.136636 | D loss (B): 0.091789 | G loss: 0.948652 | Consistency: 0.069159 |\n",
      "Training epoch: 102 [1400/2000 (70%)] | D loss (A): 0.067101 | D loss (B): 0.130390 | G loss: 1.807905 | Consistency: 0.091999 |\n",
      "Training epoch: 102 [1500/2000 (75%)] | D loss (A): 0.250501 | D loss (B): 0.238671 | G loss: 1.693830 | Consistency: 0.084423 |\n",
      "Training epoch: 102 [1600/2000 (80%)] | D loss (A): 0.264019 | D loss (B): 0.090121 | G loss: 2.313215 | Consistency: 0.100458 |\n",
      "Training epoch: 102 [1700/2000 (85%)] | D loss (A): 0.179063 | D loss (B): 0.206045 | G loss: 1.598124 | Consistency: 0.073909 |\n",
      "Training epoch: 102 [1800/2000 (90%)] | D loss (A): 0.103296 | D loss (B): 0.256806 | G loss: 2.228902 | Consistency: 0.093276 |\n",
      "Training epoch: 102 [1900/2000 (95%)] | D loss (A): 0.266546 | D loss (B): 0.170191 | G loss: 2.046586 | Consistency: 0.075459 |\n",
      "Training epoch: 103 [0/2000 (0%)] | D loss (A): 0.069180 | D loss (B): 0.086674 | G loss: 2.309780 | Consistency: 0.125842 |\n",
      "Training epoch: 103 [100/2000 (5%)] | D loss (A): 0.127876 | D loss (B): 0.152804 | G loss: 2.176000 | Consistency: 0.118133 |\n",
      "Training epoch: 103 [200/2000 (10%)] | D loss (A): 0.190460 | D loss (B): 0.092722 | G loss: 2.094573 | Consistency: 0.079099 |\n",
      "Training epoch: 103 [300/2000 (15%)] | D loss (A): 0.212373 | D loss (B): 0.129197 | G loss: 2.051044 | Consistency: 0.092726 |\n",
      "Training epoch: 103 [400/2000 (20%)] | D loss (A): 0.080872 | D loss (B): 0.059711 | G loss: 1.902638 | Consistency: 0.102045 |\n",
      "Training epoch: 103 [500/2000 (25%)] | D loss (A): 0.128649 | D loss (B): 0.160579 | G loss: 1.462559 | Consistency: 0.089043 |\n",
      "Training epoch: 103 [600/2000 (30%)] | D loss (A): 0.183080 | D loss (B): 0.056424 | G loss: 1.574022 | Consistency: 0.078196 |\n",
      "Training epoch: 103 [700/2000 (35%)] | D loss (A): 0.096172 | D loss (B): 0.090919 | G loss: 2.511100 | Consistency: 0.114290 |\n",
      "Training epoch: 103 [800/2000 (40%)] | D loss (A): 0.080735 | D loss (B): 0.065390 | G loss: 4.700708 | Consistency: 0.282441 |\n",
      "Training epoch: 103 [900/2000 (45%)] | D loss (A): 0.358852 | D loss (B): 0.159711 | G loss: 1.802835 | Consistency: 0.121358 |\n",
      "Training epoch: 103 [1000/2000 (50%)] | D loss (A): 0.220818 | D loss (B): 0.102661 | G loss: 1.578484 | Consistency: 0.099566 |\n",
      "Training epoch: 103 [1100/2000 (55%)] | D loss (A): 0.219138 | D loss (B): 0.099860 | G loss: 2.323700 | Consistency: 0.122751 |\n",
      "Training epoch: 103 [1200/2000 (60%)] | D loss (A): 0.221182 | D loss (B): 0.048142 | G loss: 1.732502 | Consistency: 0.110305 |\n",
      "Training epoch: 103 [1300/2000 (65%)] | D loss (A): 0.295641 | D loss (B): 0.077139 | G loss: 1.617314 | Consistency: 0.079028 |\n",
      "Training epoch: 103 [1400/2000 (70%)] | D loss (A): 0.292397 | D loss (B): 0.105902 | G loss: 1.826847 | Consistency: 0.108104 |\n",
      "Training epoch: 103 [1500/2000 (75%)] | D loss (A): 0.224268 | D loss (B): 0.100740 | G loss: 1.805143 | Consistency: 0.116915 |\n",
      "Training epoch: 103 [1600/2000 (80%)] | D loss (A): 0.299837 | D loss (B): 0.087170 | G loss: 1.977005 | Consistency: 0.087744 |\n",
      "Training epoch: 103 [1700/2000 (85%)] | D loss (A): 0.119275 | D loss (B): 0.221433 | G loss: 1.611834 | Consistency: 0.093431 |\n",
      "Training epoch: 103 [1800/2000 (90%)] | D loss (A): 0.177741 | D loss (B): 0.208188 | G loss: 1.492998 | Consistency: 0.066756 |\n",
      "Training epoch: 103 [1900/2000 (95%)] | D loss (A): 0.275761 | D loss (B): 0.124897 | G loss: 2.270175 | Consistency: 0.103721 |\n",
      "Training epoch: 104 [0/2000 (0%)] | D loss (A): 0.198166 | D loss (B): 0.111789 | G loss: 1.304219 | Consistency: 0.077897 |\n",
      "Training epoch: 104 [100/2000 (5%)] | D loss (A): 0.158228 | D loss (B): 0.080302 | G loss: 1.753835 | Consistency: 0.077173 |\n",
      "Training epoch: 104 [200/2000 (10%)] | D loss (A): 0.258599 | D loss (B): 0.086754 | G loss: 2.105651 | Consistency: 0.099130 |\n",
      "Training epoch: 104 [300/2000 (15%)] | D loss (A): 0.234523 | D loss (B): 0.264112 | G loss: 2.162869 | Consistency: 0.089483 |\n",
      "Training epoch: 104 [400/2000 (20%)] | D loss (A): 0.133564 | D loss (B): 0.101016 | G loss: 2.042079 | Consistency: 0.091080 |\n",
      "Training epoch: 104 [500/2000 (25%)] | D loss (A): 0.180809 | D loss (B): 0.144480 | G loss: 1.908556 | Consistency: 0.099573 |\n",
      "Training epoch: 104 [600/2000 (30%)] | D loss (A): 0.222827 | D loss (B): 0.196251 | G loss: 1.551030 | Consistency: 0.065669 |\n",
      "Training epoch: 104 [700/2000 (35%)] | D loss (A): 0.199662 | D loss (B): 0.147860 | G loss: 1.505581 | Consistency: 0.083315 |\n",
      "Training epoch: 104 [800/2000 (40%)] | D loss (A): 0.107538 | D loss (B): 0.044253 | G loss: 2.571427 | Consistency: 0.113381 |\n",
      "Training epoch: 104 [900/2000 (45%)] | D loss (A): 0.140730 | D loss (B): 0.352579 | G loss: 2.021694 | Consistency: 0.107749 |\n",
      "Training epoch: 104 [1000/2000 (50%)] | D loss (A): 0.218036 | D loss (B): 0.174559 | G loss: 1.560964 | Consistency: 0.090168 |\n",
      "Training epoch: 104 [1100/2000 (55%)] | D loss (A): 0.163034 | D loss (B): 0.184448 | G loss: 1.985796 | Consistency: 0.099638 |\n",
      "Training epoch: 104 [1200/2000 (60%)] | D loss (A): 0.108997 | D loss (B): 0.144163 | G loss: 2.122385 | Consistency: 0.104137 |\n",
      "Training epoch: 104 [1300/2000 (65%)] | D loss (A): 0.244004 | D loss (B): 0.165001 | G loss: 1.310937 | Consistency: 0.072864 |\n",
      "Training epoch: 104 [1400/2000 (70%)] | D loss (A): 0.203781 | D loss (B): 0.122559 | G loss: 1.159331 | Consistency: 0.081726 |\n",
      "Training epoch: 104 [1500/2000 (75%)] | D loss (A): 0.168132 | D loss (B): 0.158029 | G loss: 1.790816 | Consistency: 0.085252 |\n",
      "Training epoch: 104 [1600/2000 (80%)] | D loss (A): 0.225088 | D loss (B): 0.086487 | G loss: 2.205264 | Consistency: 0.092059 |\n",
      "Training epoch: 104 [1700/2000 (85%)] | D loss (A): 0.117560 | D loss (B): 0.185587 | G loss: 1.610271 | Consistency: 0.088078 |\n",
      "Training epoch: 104 [1800/2000 (90%)] | D loss (A): 0.189923 | D loss (B): 0.112326 | G loss: 1.847333 | Consistency: 0.076257 |\n",
      "Training epoch: 104 [1900/2000 (95%)] | D loss (A): 0.212402 | D loss (B): 0.123586 | G loss: 1.543840 | Consistency: 0.060040 |\n",
      "Training epoch: 105 [0/2000 (0%)] | D loss (A): 0.215271 | D loss (B): 0.104278 | G loss: 2.032052 | Consistency: 0.087939 |\n",
      "Training epoch: 105 [100/2000 (5%)] | D loss (A): 0.226289 | D loss (B): 0.220663 | G loss: 1.608401 | Consistency: 0.070113 |\n",
      "Training epoch: 105 [200/2000 (10%)] | D loss (A): 0.088391 | D loss (B): 0.064460 | G loss: 1.855044 | Consistency: 0.085638 |\n",
      "Training epoch: 105 [300/2000 (15%)] | D loss (A): 0.115045 | D loss (B): 0.158358 | G loss: 1.637188 | Consistency: 0.083464 |\n",
      "Training epoch: 105 [400/2000 (20%)] | D loss (A): 0.122297 | D loss (B): 0.072981 | G loss: 1.930712 | Consistency: 0.084007 |\n",
      "Training epoch: 105 [500/2000 (25%)] | D loss (A): 0.146578 | D loss (B): 0.076802 | G loss: 2.144357 | Consistency: 0.111016 |\n",
      "Training epoch: 105 [600/2000 (30%)] | D loss (A): 0.126367 | D loss (B): 0.158487 | G loss: 2.191908 | Consistency: 0.104654 |\n",
      "Training epoch: 105 [700/2000 (35%)] | D loss (A): 0.166279 | D loss (B): 0.138082 | G loss: 1.824431 | Consistency: 0.070446 |\n",
      "Training epoch: 105 [800/2000 (40%)] | D loss (A): 0.140307 | D loss (B): 0.255205 | G loss: 2.107342 | Consistency: 0.088946 |\n",
      "Training epoch: 105 [900/2000 (45%)] | D loss (A): 0.045416 | D loss (B): 0.039363 | G loss: 1.532555 | Consistency: 0.085059 |\n",
      "Training epoch: 105 [1000/2000 (50%)] | D loss (A): 0.171796 | D loss (B): 0.095155 | G loss: 1.538061 | Consistency: 0.075081 |\n",
      "Training epoch: 105 [1100/2000 (55%)] | D loss (A): 0.233169 | D loss (B): 0.207508 | G loss: 2.103541 | Consistency: 0.101615 |\n",
      "Training epoch: 105 [1200/2000 (60%)] | D loss (A): 0.246239 | D loss (B): 0.174856 | G loss: 1.456460 | Consistency: 0.082945 |\n",
      "Training epoch: 105 [1300/2000 (65%)] | D loss (A): 0.163299 | D loss (B): 0.097463 | G loss: 1.359708 | Consistency: 0.084406 |\n",
      "Training epoch: 105 [1400/2000 (70%)] | D loss (A): 0.147187 | D loss (B): 0.131434 | G loss: 2.228030 | Consistency: 0.095538 |\n",
      "Training epoch: 105 [1500/2000 (75%)] | D loss (A): 0.198395 | D loss (B): 0.175459 | G loss: 2.072794 | Consistency: 0.095578 |\n",
      "Training epoch: 105 [1600/2000 (80%)] | D loss (A): 0.202015 | D loss (B): 0.055660 | G loss: 2.311478 | Consistency: 0.136699 |\n",
      "Training epoch: 105 [1700/2000 (85%)] | D loss (A): 0.114940 | D loss (B): 0.166175 | G loss: 1.974711 | Consistency: 0.101350 |\n",
      "Training epoch: 105 [1800/2000 (90%)] | D loss (A): 0.329715 | D loss (B): 0.143192 | G loss: 1.605747 | Consistency: 0.100942 |\n",
      "Training epoch: 105 [1900/2000 (95%)] | D loss (A): 0.083384 | D loss (B): 0.207413 | G loss: 1.535932 | Consistency: 0.084970 |\n",
      "Training epoch: 106 [0/2000 (0%)] | D loss (A): 0.079770 | D loss (B): 0.092657 | G loss: 2.000914 | Consistency: 0.096675 |\n",
      "Training epoch: 106 [100/2000 (5%)] | D loss (A): 0.190813 | D loss (B): 0.091037 | G loss: 1.488427 | Consistency: 0.080181 |\n",
      "Training epoch: 106 [200/2000 (10%)] | D loss (A): 0.126435 | D loss (B): 0.033283 | G loss: 1.662453 | Consistency: 0.102226 |\n",
      "Training epoch: 106 [300/2000 (15%)] | D loss (A): 0.162273 | D loss (B): 0.203037 | G loss: 2.046046 | Consistency: 0.083469 |\n",
      "Training epoch: 106 [400/2000 (20%)] | D loss (A): 0.122451 | D loss (B): 0.174992 | G loss: 1.784600 | Consistency: 0.083920 |\n",
      "Training epoch: 106 [500/2000 (25%)] | D loss (A): 0.160713 | D loss (B): 0.092001 | G loss: 1.518276 | Consistency: 0.060346 |\n",
      "Training epoch: 106 [600/2000 (30%)] | D loss (A): 0.239999 | D loss (B): 0.085897 | G loss: 2.354404 | Consistency: 0.109842 |\n",
      "Training epoch: 106 [700/2000 (35%)] | D loss (A): 0.184827 | D loss (B): 0.110167 | G loss: 2.159297 | Consistency: 0.084038 |\n",
      "Training epoch: 106 [800/2000 (40%)] | D loss (A): 0.127917 | D loss (B): 0.113157 | G loss: 1.873260 | Consistency: 0.081616 |\n",
      "Training epoch: 106 [900/2000 (45%)] | D loss (A): 0.171533 | D loss (B): 0.047141 | G loss: 1.933360 | Consistency: 0.063242 |\n",
      "Training epoch: 106 [1000/2000 (50%)] | D loss (A): 0.093771 | D loss (B): 0.076113 | G loss: 2.294064 | Consistency: 0.113387 |\n",
      "Training epoch: 106 [1100/2000 (55%)] | D loss (A): 0.110538 | D loss (B): 0.151142 | G loss: 2.090392 | Consistency: 0.082321 |\n",
      "Training epoch: 106 [1200/2000 (60%)] | D loss (A): 0.131194 | D loss (B): 0.078870 | G loss: 1.973249 | Consistency: 0.089900 |\n",
      "Training epoch: 106 [1300/2000 (65%)] | D loss (A): 0.105372 | D loss (B): 0.157957 | G loss: 1.434766 | Consistency: 0.083982 |\n",
      "Training epoch: 106 [1400/2000 (70%)] | D loss (A): 0.101999 | D loss (B): 0.095908 | G loss: 2.059088 | Consistency: 0.099111 |\n",
      "Training epoch: 106 [1500/2000 (75%)] | D loss (A): 0.179345 | D loss (B): 0.206465 | G loss: 2.190283 | Consistency: 0.077542 |\n",
      "Training epoch: 106 [1600/2000 (80%)] | D loss (A): 0.113087 | D loss (B): 0.142332 | G loss: 2.158875 | Consistency: 0.089034 |\n",
      "Training epoch: 106 [1700/2000 (85%)] | D loss (A): 0.168860 | D loss (B): 0.261813 | G loss: 1.903897 | Consistency: 0.085936 |\n",
      "Training epoch: 106 [1800/2000 (90%)] | D loss (A): 0.204711 | D loss (B): 0.080615 | G loss: 1.598029 | Consistency: 0.083899 |\n",
      "Training epoch: 106 [1900/2000 (95%)] | D loss (A): 0.180373 | D loss (B): 0.142421 | G loss: 2.207220 | Consistency: 0.096963 |\n",
      "Training epoch: 107 [0/2000 (0%)] | D loss (A): 0.122778 | D loss (B): 0.145743 | G loss: 2.123257 | Consistency: 0.106109 |\n",
      "Training epoch: 107 [100/2000 (5%)] | D loss (A): 0.098217 | D loss (B): 0.188351 | G loss: 1.739277 | Consistency: 0.088965 |\n",
      "Training epoch: 107 [200/2000 (10%)] | D loss (A): 0.157985 | D loss (B): 0.113193 | G loss: 1.773863 | Consistency: 0.086387 |\n",
      "Training epoch: 107 [300/2000 (15%)] | D loss (A): 0.219353 | D loss (B): 0.131016 | G loss: 2.358311 | Consistency: 0.113962 |\n",
      "Training epoch: 107 [400/2000 (20%)] | D loss (A): 0.077891 | D loss (B): 0.076969 | G loss: 1.803560 | Consistency: 0.094090 |\n",
      "Training epoch: 107 [500/2000 (25%)] | D loss (A): 0.069319 | D loss (B): 0.042687 | G loss: 2.048162 | Consistency: 0.106855 |\n",
      "Training epoch: 107 [600/2000 (30%)] | D loss (A): 0.097326 | D loss (B): 0.099743 | G loss: 1.983188 | Consistency: 0.091742 |\n",
      "Training epoch: 107 [700/2000 (35%)] | D loss (A): 0.150357 | D loss (B): 0.164445 | G loss: 2.018392 | Consistency: 0.090818 |\n",
      "Training epoch: 107 [800/2000 (40%)] | D loss (A): 0.215876 | D loss (B): 0.080984 | G loss: 1.761374 | Consistency: 0.093552 |\n",
      "Training epoch: 107 [900/2000 (45%)] | D loss (A): 0.222303 | D loss (B): 0.065013 | G loss: 1.178781 | Consistency: 0.081357 |\n",
      "Training epoch: 107 [1000/2000 (50%)] | D loss (A): 0.062040 | D loss (B): 0.130163 | G loss: 1.570888 | Consistency: 0.084061 |\n",
      "Training epoch: 107 [1100/2000 (55%)] | D loss (A): 0.155486 | D loss (B): 0.122334 | G loss: 1.646761 | Consistency: 0.071652 |\n",
      "Training epoch: 107 [1200/2000 (60%)] | D loss (A): 0.152796 | D loss (B): 0.100746 | G loss: 2.314693 | Consistency: 0.084479 |\n",
      "Training epoch: 107 [1300/2000 (65%)] | D loss (A): 0.270842 | D loss (B): 0.130725 | G loss: 1.874239 | Consistency: 0.078109 |\n",
      "Training epoch: 107 [1400/2000 (70%)] | D loss (A): 0.178364 | D loss (B): 0.236186 | G loss: 1.815129 | Consistency: 0.063280 |\n",
      "Training epoch: 107 [1500/2000 (75%)] | D loss (A): 0.164210 | D loss (B): 0.083252 | G loss: 1.915622 | Consistency: 0.103424 |\n",
      "Training epoch: 107 [1600/2000 (80%)] | D loss (A): 0.088534 | D loss (B): 0.154737 | G loss: 1.983180 | Consistency: 0.109004 |\n",
      "Training epoch: 107 [1700/2000 (85%)] | D loss (A): 0.125607 | D loss (B): 0.201831 | G loss: 1.813208 | Consistency: 0.087272 |\n",
      "Training epoch: 107 [1800/2000 (90%)] | D loss (A): 0.134677 | D loss (B): 0.089831 | G loss: 2.180157 | Consistency: 0.117567 |\n",
      "Training epoch: 107 [1900/2000 (95%)] | D loss (A): 0.167253 | D loss (B): 0.118456 | G loss: 1.900193 | Consistency: 0.074490 |\n",
      "Training epoch: 108 [0/2000 (0%)] | D loss (A): 0.245741 | D loss (B): 0.049331 | G loss: 1.676530 | Consistency: 0.099022 |\n",
      "Training epoch: 108 [100/2000 (5%)] | D loss (A): 0.190679 | D loss (B): 0.072420 | G loss: 2.186230 | Consistency: 0.099780 |\n",
      "Training epoch: 108 [200/2000 (10%)] | D loss (A): 0.166573 | D loss (B): 0.093391 | G loss: 2.323891 | Consistency: 0.114404 |\n",
      "Training epoch: 108 [300/2000 (15%)] | D loss (A): 0.146399 | D loss (B): 0.066602 | G loss: 2.035523 | Consistency: 0.133124 |\n",
      "Training epoch: 108 [400/2000 (20%)] | D loss (A): 0.195606 | D loss (B): 0.106900 | G loss: 1.554401 | Consistency: 0.089154 |\n",
      "Training epoch: 108 [500/2000 (25%)] | D loss (A): 0.161208 | D loss (B): 0.228754 | G loss: 1.329418 | Consistency: 0.084337 |\n",
      "Training epoch: 108 [600/2000 (30%)] | D loss (A): 0.107407 | D loss (B): 0.171636 | G loss: 1.686382 | Consistency: 0.087846 |\n",
      "Training epoch: 108 [700/2000 (35%)] | D loss (A): 0.111896 | D loss (B): 0.112721 | G loss: 1.891234 | Consistency: 0.084710 |\n",
      "Training epoch: 108 [800/2000 (40%)] | D loss (A): 0.093995 | D loss (B): 0.040751 | G loss: 2.200670 | Consistency: 0.105701 |\n",
      "Training epoch: 108 [900/2000 (45%)] | D loss (A): 0.276069 | D loss (B): 0.170146 | G loss: 2.281698 | Consistency: 0.101009 |\n",
      "Training epoch: 108 [1000/2000 (50%)] | D loss (A): 0.154706 | D loss (B): 0.177438 | G loss: 1.903254 | Consistency: 0.091833 |\n",
      "Training epoch: 108 [1100/2000 (55%)] | D loss (A): 0.114415 | D loss (B): 0.187154 | G loss: 2.983665 | Consistency: 0.121659 |\n",
      "Training epoch: 108 [1200/2000 (60%)] | D loss (A): 0.199858 | D loss (B): 0.154001 | G loss: 2.027195 | Consistency: 0.084486 |\n",
      "Training epoch: 108 [1300/2000 (65%)] | D loss (A): 0.138022 | D loss (B): 0.156038 | G loss: 1.937471 | Consistency: 0.084845 |\n",
      "Training epoch: 108 [1400/2000 (70%)] | D loss (A): 0.139452 | D loss (B): 0.126133 | G loss: 2.390374 | Consistency: 0.102322 |\n",
      "Training epoch: 108 [1500/2000 (75%)] | D loss (A): 0.241903 | D loss (B): 0.154362 | G loss: 1.966124 | Consistency: 0.057558 |\n",
      "Training epoch: 108 [1600/2000 (80%)] | D loss (A): 0.153558 | D loss (B): 0.176864 | G loss: 1.526427 | Consistency: 0.072986 |\n",
      "Training epoch: 108 [1700/2000 (85%)] | D loss (A): 0.104567 | D loss (B): 0.031890 | G loss: 2.144613 | Consistency: 0.098142 |\n",
      "Training epoch: 108 [1800/2000 (90%)] | D loss (A): 0.167416 | D loss (B): 0.127083 | G loss: 2.287059 | Consistency: 0.097036 |\n",
      "Training epoch: 108 [1900/2000 (95%)] | D loss (A): 0.121279 | D loss (B): 0.180640 | G loss: 2.075233 | Consistency: 0.076917 |\n",
      "Training epoch: 109 [0/2000 (0%)] | D loss (A): 0.047398 | D loss (B): 0.189024 | G loss: 1.911300 | Consistency: 0.092265 |\n",
      "Training epoch: 109 [100/2000 (5%)] | D loss (A): 0.147882 | D loss (B): 0.096163 | G loss: 2.162362 | Consistency: 0.099905 |\n",
      "Training epoch: 109 [200/2000 (10%)] | D loss (A): 0.170682 | D loss (B): 0.114292 | G loss: 2.561282 | Consistency: 0.122271 |\n",
      "Training epoch: 109 [300/2000 (15%)] | D loss (A): 0.198036 | D loss (B): 0.094656 | G loss: 1.444839 | Consistency: 0.088313 |\n",
      "Training epoch: 109 [400/2000 (20%)] | D loss (A): 0.136132 | D loss (B): 0.054638 | G loss: 1.812028 | Consistency: 0.101705 |\n",
      "Training epoch: 109 [500/2000 (25%)] | D loss (A): 0.154328 | D loss (B): 0.143665 | G loss: 1.614632 | Consistency: 0.084039 |\n",
      "Training epoch: 109 [600/2000 (30%)] | D loss (A): 0.205610 | D loss (B): 0.081050 | G loss: 1.985906 | Consistency: 0.080664 |\n",
      "Training epoch: 109 [700/2000 (35%)] | D loss (A): 0.083730 | D loss (B): 0.045973 | G loss: 1.695302 | Consistency: 0.113359 |\n",
      "Training epoch: 109 [800/2000 (40%)] | D loss (A): 0.113612 | D loss (B): 0.076092 | G loss: 2.109306 | Consistency: 0.100707 |\n",
      "Training epoch: 109 [900/2000 (45%)] | D loss (A): 0.154106 | D loss (B): 0.086649 | G loss: 1.559628 | Consistency: 0.107299 |\n",
      "Training epoch: 109 [1000/2000 (50%)] | D loss (A): 0.167055 | D loss (B): 0.086458 | G loss: 1.760574 | Consistency: 0.086368 |\n",
      "Training epoch: 109 [1100/2000 (55%)] | D loss (A): 0.069566 | D loss (B): 0.061937 | G loss: 2.158147 | Consistency: 0.099138 |\n",
      "Training epoch: 109 [1200/2000 (60%)] | D loss (A): 0.157103 | D loss (B): 0.109408 | G loss: 1.780770 | Consistency: 0.092806 |\n",
      "Training epoch: 109 [1300/2000 (65%)] | D loss (A): 0.327377 | D loss (B): 0.161727 | G loss: 1.812770 | Consistency: 0.081947 |\n",
      "Training epoch: 109 [1400/2000 (70%)] | D loss (A): 0.123367 | D loss (B): 0.049131 | G loss: 1.617724 | Consistency: 0.083518 |\n",
      "Training epoch: 109 [1500/2000 (75%)] | D loss (A): 0.142160 | D loss (B): 0.199463 | G loss: 2.170969 | Consistency: 0.090542 |\n",
      "Training epoch: 109 [1600/2000 (80%)] | D loss (A): 0.230751 | D loss (B): 0.227312 | G loss: 1.616055 | Consistency: 0.071355 |\n",
      "Training epoch: 109 [1700/2000 (85%)] | D loss (A): 0.122979 | D loss (B): 0.226214 | G loss: 1.397323 | Consistency: 0.074602 |\n",
      "Training epoch: 109 [1800/2000 (90%)] | D loss (A): 0.123127 | D loss (B): 0.187711 | G loss: 1.321726 | Consistency: 0.075465 |\n",
      "Training epoch: 109 [1900/2000 (95%)] | D loss (A): 0.213228 | D loss (B): 0.212828 | G loss: 2.159313 | Consistency: 0.094989 |\n",
      "Training epoch: 110 [0/2000 (0%)] | D loss (A): 0.174948 | D loss (B): 0.151603 | G loss: 2.411501 | Consistency: 0.101419 |\n",
      "Training epoch: 110 [100/2000 (5%)] | D loss (A): 0.161970 | D loss (B): 0.112174 | G loss: 2.081970 | Consistency: 0.088447 |\n",
      "Training epoch: 110 [200/2000 (10%)] | D loss (A): 0.421061 | D loss (B): 0.123719 | G loss: 1.627513 | Consistency: 0.074887 |\n",
      "Training epoch: 110 [300/2000 (15%)] | D loss (A): 0.281155 | D loss (B): 0.080805 | G loss: 1.556043 | Consistency: 0.067987 |\n",
      "Training epoch: 110 [400/2000 (20%)] | D loss (A): 0.170973 | D loss (B): 0.203727 | G loss: 1.489612 | Consistency: 0.088001 |\n",
      "Training epoch: 110 [500/2000 (25%)] | D loss (A): 0.262154 | D loss (B): 0.075693 | G loss: 1.798731 | Consistency: 0.089807 |\n",
      "Training epoch: 110 [600/2000 (30%)] | D loss (A): 0.146394 | D loss (B): 0.160170 | G loss: 1.507049 | Consistency: 0.061537 |\n",
      "Training epoch: 110 [700/2000 (35%)] | D loss (A): 0.157084 | D loss (B): 0.170120 | G loss: 1.506122 | Consistency: 0.081923 |\n",
      "Training epoch: 110 [800/2000 (40%)] | D loss (A): 0.229010 | D loss (B): 0.061232 | G loss: 2.167022 | Consistency: 0.111300 |\n",
      "Training epoch: 110 [900/2000 (45%)] | D loss (A): 0.199926 | D loss (B): 0.129697 | G loss: 1.657560 | Consistency: 0.079362 |\n",
      "Training epoch: 110 [1000/2000 (50%)] | D loss (A): 0.316488 | D loss (B): 0.185951 | G loss: 1.697754 | Consistency: 0.095584 |\n",
      "Training epoch: 110 [1100/2000 (55%)] | D loss (A): 0.229312 | D loss (B): 0.208442 | G loss: 1.406398 | Consistency: 0.077119 |\n",
      "Training epoch: 110 [1200/2000 (60%)] | D loss (A): 0.272296 | D loss (B): 0.144279 | G loss: 2.058410 | Consistency: 0.114349 |\n",
      "Training epoch: 110 [1300/2000 (65%)] | D loss (A): 0.287307 | D loss (B): 0.053009 | G loss: 1.687864 | Consistency: 0.094736 |\n",
      "Training epoch: 110 [1400/2000 (70%)] | D loss (A): 0.238908 | D loss (B): 0.111893 | G loss: 1.750469 | Consistency: 0.085944 |\n",
      "Training epoch: 110 [1500/2000 (75%)] | D loss (A): 0.170546 | D loss (B): 0.120675 | G loss: 1.163472 | Consistency: 0.078445 |\n",
      "Training epoch: 110 [1600/2000 (80%)] | D loss (A): 0.202961 | D loss (B): 0.224438 | G loss: 1.690328 | Consistency: 0.087058 |\n",
      "Training epoch: 110 [1700/2000 (85%)] | D loss (A): 0.236417 | D loss (B): 0.060103 | G loss: 2.071118 | Consistency: 0.095560 |\n",
      "Training epoch: 110 [1800/2000 (90%)] | D loss (A): 0.194475 | D loss (B): 0.228855 | G loss: 1.485697 | Consistency: 0.086555 |\n",
      "Training epoch: 110 [1900/2000 (95%)] | D loss (A): 0.221409 | D loss (B): 0.204864 | G loss: 1.417947 | Consistency: 0.074499 |\n",
      "Training epoch: 111 [0/2000 (0%)] | D loss (A): 0.207984 | D loss (B): 0.200623 | G loss: 1.847785 | Consistency: 0.079867 |\n",
      "Training epoch: 111 [100/2000 (5%)] | D loss (A): 0.242962 | D loss (B): 0.151541 | G loss: 1.303762 | Consistency: 0.075281 |\n",
      "Training epoch: 111 [200/2000 (10%)] | D loss (A): 0.067982 | D loss (B): 0.169581 | G loss: 1.735084 | Consistency: 0.087878 |\n",
      "Training epoch: 111 [300/2000 (15%)] | D loss (A): 0.205033 | D loss (B): 0.070058 | G loss: 2.206681 | Consistency: 0.084666 |\n",
      "Training epoch: 111 [400/2000 (20%)] | D loss (A): 0.219807 | D loss (B): 0.126482 | G loss: 1.746744 | Consistency: 0.082272 |\n",
      "Training epoch: 111 [500/2000 (25%)] | D loss (A): 0.042646 | D loss (B): 0.194945 | G loss: 1.420967 | Consistency: 0.079320 |\n",
      "Training epoch: 111 [600/2000 (30%)] | D loss (A): 0.204546 | D loss (B): 0.227160 | G loss: 2.148276 | Consistency: 0.105018 |\n",
      "Training epoch: 111 [700/2000 (35%)] | D loss (A): 0.188672 | D loss (B): 0.135398 | G loss: 2.127312 | Consistency: 0.088395 |\n",
      "Training epoch: 111 [800/2000 (40%)] | D loss (A): 0.145887 | D loss (B): 0.057526 | G loss: 2.171153 | Consistency: 0.111990 |\n",
      "Training epoch: 111 [900/2000 (45%)] | D loss (A): 0.153127 | D loss (B): 0.134633 | G loss: 1.952982 | Consistency: 0.085579 |\n",
      "Training epoch: 111 [1000/2000 (50%)] | D loss (A): 0.160818 | D loss (B): 0.235958 | G loss: 1.691517 | Consistency: 0.084418 |\n",
      "Training epoch: 111 [1100/2000 (55%)] | D loss (A): 0.200449 | D loss (B): 0.141569 | G loss: 1.608236 | Consistency: 0.088469 |\n",
      "Training epoch: 111 [1200/2000 (60%)] | D loss (A): 0.147876 | D loss (B): 0.193768 | G loss: 1.683563 | Consistency: 0.080509 |\n",
      "Training epoch: 111 [1300/2000 (65%)] | D loss (A): 0.124903 | D loss (B): 0.153945 | G loss: 1.515385 | Consistency: 0.077726 |\n",
      "Training epoch: 111 [1400/2000 (70%)] | D loss (A): 0.195195 | D loss (B): 0.070146 | G loss: 2.201221 | Consistency: 0.089305 |\n",
      "Training epoch: 111 [1500/2000 (75%)] | D loss (A): 0.304485 | D loss (B): 0.076660 | G loss: 1.656336 | Consistency: 0.077101 |\n",
      "Training epoch: 111 [1600/2000 (80%)] | D loss (A): 0.200432 | D loss (B): 0.186765 | G loss: 1.637163 | Consistency: 0.066509 |\n",
      "Training epoch: 111 [1700/2000 (85%)] | D loss (A): 0.142057 | D loss (B): 0.059132 | G loss: 2.330856 | Consistency: 0.110926 |\n",
      "Training epoch: 111 [1800/2000 (90%)] | D loss (A): 0.156528 | D loss (B): 0.146060 | G loss: 1.737808 | Consistency: 0.081812 |\n",
      "Training epoch: 111 [1900/2000 (95%)] | D loss (A): 0.142983 | D loss (B): 0.103181 | G loss: 2.639693 | Consistency: 0.114410 |\n",
      "Training epoch: 112 [0/2000 (0%)] | D loss (A): 0.124443 | D loss (B): 0.087677 | G loss: 2.158324 | Consistency: 0.092574 |\n",
      "Training epoch: 112 [100/2000 (5%)] | D loss (A): 0.159657 | D loss (B): 0.078304 | G loss: 2.103634 | Consistency: 0.105727 |\n",
      "Training epoch: 112 [200/2000 (10%)] | D loss (A): 0.129256 | D loss (B): 0.030205 | G loss: 1.711666 | Consistency: 0.069812 |\n",
      "Training epoch: 112 [300/2000 (15%)] | D loss (A): 0.064567 | D loss (B): 0.098729 | G loss: 1.408222 | Consistency: 0.069832 |\n",
      "Training epoch: 112 [400/2000 (20%)] | D loss (A): 0.283459 | D loss (B): 0.060147 | G loss: 2.286829 | Consistency: 0.109161 |\n",
      "Training epoch: 112 [500/2000 (25%)] | D loss (A): 0.103995 | D loss (B): 0.120264 | G loss: 2.684796 | Consistency: 0.110376 |\n",
      "Training epoch: 112 [600/2000 (30%)] | D loss (A): 0.162059 | D loss (B): 0.090861 | G loss: 1.618072 | Consistency: 0.065409 |\n",
      "Training epoch: 112 [700/2000 (35%)] | D loss (A): 0.096951 | D loss (B): 0.113105 | G loss: 1.963130 | Consistency: 0.077334 |\n",
      "Training epoch: 112 [800/2000 (40%)] | D loss (A): 0.131192 | D loss (B): 0.152737 | G loss: 1.926756 | Consistency: 0.094704 |\n",
      "Training epoch: 112 [900/2000 (45%)] | D loss (A): 0.151505 | D loss (B): 0.137077 | G loss: 1.825524 | Consistency: 0.079151 |\n",
      "Training epoch: 112 [1000/2000 (50%)] | D loss (A): 0.095704 | D loss (B): 0.084827 | G loss: 1.481282 | Consistency: 0.074447 |\n",
      "Training epoch: 112 [1100/2000 (55%)] | D loss (A): 0.108591 | D loss (B): 0.150911 | G loss: 2.116498 | Consistency: 0.087285 |\n",
      "Training epoch: 112 [1200/2000 (60%)] | D loss (A): 0.147737 | D loss (B): 0.129401 | G loss: 1.804386 | Consistency: 0.071966 |\n",
      "Training epoch: 112 [1300/2000 (65%)] | D loss (A): 0.145884 | D loss (B): 0.143830 | G loss: 2.157128 | Consistency: 0.104099 |\n",
      "Training epoch: 112 [1400/2000 (70%)] | D loss (A): 0.176439 | D loss (B): 0.048317 | G loss: 2.112407 | Consistency: 0.119115 |\n",
      "Training epoch: 112 [1500/2000 (75%)] | D loss (A): 0.064545 | D loss (B): 0.069458 | G loss: 2.177025 | Consistency: 0.088563 |\n",
      "Training epoch: 112 [1600/2000 (80%)] | D loss (A): 0.126642 | D loss (B): 0.175092 | G loss: 1.025162 | Consistency: 0.061201 |\n",
      "Training epoch: 112 [1700/2000 (85%)] | D loss (A): 0.169596 | D loss (B): 0.189807 | G loss: 1.806239 | Consistency: 0.085064 |\n",
      "Training epoch: 112 [1800/2000 (90%)] | D loss (A): 0.096303 | D loss (B): 0.060132 | G loss: 1.692518 | Consistency: 0.085351 |\n",
      "Training epoch: 112 [1900/2000 (95%)] | D loss (A): 0.147861 | D loss (B): 0.201107 | G loss: 1.924584 | Consistency: 0.071108 |\n",
      "Training epoch: 113 [0/2000 (0%)] | D loss (A): 0.137342 | D loss (B): 0.056064 | G loss: 2.189565 | Consistency: 0.090575 |\n",
      "Training epoch: 113 [100/2000 (5%)] | D loss (A): 0.146669 | D loss (B): 0.063593 | G loss: 1.783601 | Consistency: 0.089101 |\n",
      "Training epoch: 113 [200/2000 (10%)] | D loss (A): 0.091157 | D loss (B): 0.101934 | G loss: 2.544827 | Consistency: 0.113564 |\n",
      "Training epoch: 113 [300/2000 (15%)] | D loss (A): 0.074050 | D loss (B): 0.155251 | G loss: 1.526502 | Consistency: 0.103459 |\n",
      "Training epoch: 113 [400/2000 (20%)] | D loss (A): 0.113258 | D loss (B): 0.073276 | G loss: 1.310949 | Consistency: 0.076971 |\n",
      "Training epoch: 113 [500/2000 (25%)] | D loss (A): 0.109169 | D loss (B): 0.130788 | G loss: 2.387807 | Consistency: 0.083427 |\n",
      "Training epoch: 113 [600/2000 (30%)] | D loss (A): 0.255917 | D loss (B): 0.209886 | G loss: 1.607756 | Consistency: 0.080637 |\n",
      "Training epoch: 113 [700/2000 (35%)] | D loss (A): 0.058981 | D loss (B): 0.138536 | G loss: 2.154110 | Consistency: 0.114536 |\n",
      "Training epoch: 113 [800/2000 (40%)] | D loss (A): 0.263934 | D loss (B): 0.080334 | G loss: 2.362690 | Consistency: 0.107579 |\n",
      "Training epoch: 113 [900/2000 (45%)] | D loss (A): 0.160876 | D loss (B): 0.171464 | G loss: 2.117221 | Consistency: 0.087092 |\n",
      "Training epoch: 113 [1000/2000 (50%)] | D loss (A): 0.283380 | D loss (B): 0.083812 | G loss: 1.464419 | Consistency: 0.085187 |\n",
      "Training epoch: 113 [1100/2000 (55%)] | D loss (A): 0.156840 | D loss (B): 0.109616 | G loss: 1.860101 | Consistency: 0.095587 |\n",
      "Training epoch: 113 [1200/2000 (60%)] | D loss (A): 0.120560 | D loss (B): 0.101631 | G loss: 1.745973 | Consistency: 0.079917 |\n",
      "Training epoch: 113 [1300/2000 (65%)] | D loss (A): 0.117980 | D loss (B): 0.126135 | G loss: 1.894288 | Consistency: 0.076130 |\n",
      "Training epoch: 113 [1400/2000 (70%)] | D loss (A): 0.086726 | D loss (B): 0.133763 | G loss: 1.500886 | Consistency: 0.079722 |\n",
      "Training epoch: 113 [1500/2000 (75%)] | D loss (A): 0.179793 | D loss (B): 0.291571 | G loss: 2.200762 | Consistency: 0.097167 |\n",
      "Training epoch: 113 [1600/2000 (80%)] | D loss (A): 0.304002 | D loss (B): 0.131819 | G loss: 2.226505 | Consistency: 0.091145 |\n",
      "Training epoch: 113 [1700/2000 (85%)] | D loss (A): 0.201430 | D loss (B): 0.147397 | G loss: 1.754168 | Consistency: 0.083210 |\n",
      "Training epoch: 113 [1800/2000 (90%)] | D loss (A): 0.240056 | D loss (B): 0.210898 | G loss: 1.606294 | Consistency: 0.071225 |\n",
      "Training epoch: 113 [1900/2000 (95%)] | D loss (A): 0.240123 | D loss (B): 0.084750 | G loss: 2.417651 | Consistency: 0.106035 |\n",
      "Training epoch: 114 [0/2000 (0%)] | D loss (A): 0.169518 | D loss (B): 0.137747 | G loss: 2.156260 | Consistency: 0.081657 |\n",
      "Training epoch: 114 [100/2000 (5%)] | D loss (A): 0.097166 | D loss (B): 0.239399 | G loss: 1.929521 | Consistency: 0.074594 |\n",
      "Training epoch: 114 [200/2000 (10%)] | D loss (A): 0.251397 | D loss (B): 0.137488 | G loss: 1.850809 | Consistency: 0.068087 |\n",
      "Training epoch: 114 [300/2000 (15%)] | D loss (A): 0.097939 | D loss (B): 0.144011 | G loss: 1.817030 | Consistency: 0.081557 |\n",
      "Training epoch: 114 [400/2000 (20%)] | D loss (A): 0.205451 | D loss (B): 0.223558 | G loss: 1.697955 | Consistency: 0.084553 |\n",
      "Training epoch: 114 [500/2000 (25%)] | D loss (A): 0.228668 | D loss (B): 0.251237 | G loss: 2.451085 | Consistency: 0.116071 |\n",
      "Training epoch: 114 [600/2000 (30%)] | D loss (A): 0.057644 | D loss (B): 0.081777 | G loss: 2.195814 | Consistency: 0.102697 |\n",
      "Training epoch: 114 [700/2000 (35%)] | D loss (A): 0.104740 | D loss (B): 0.174644 | G loss: 1.574887 | Consistency: 0.069841 |\n",
      "Training epoch: 114 [800/2000 (40%)] | D loss (A): 0.095656 | D loss (B): 0.111903 | G loss: 1.587712 | Consistency: 0.067375 |\n",
      "Training epoch: 114 [900/2000 (45%)] | D loss (A): 0.165494 | D loss (B): 0.081272 | G loss: 1.667500 | Consistency: 0.089991 |\n",
      "Training epoch: 114 [1000/2000 (50%)] | D loss (A): 0.089910 | D loss (B): 0.174290 | G loss: 1.876119 | Consistency: 0.085065 |\n",
      "Training epoch: 114 [1100/2000 (55%)] | D loss (A): 0.182237 | D loss (B): 0.041562 | G loss: 1.692555 | Consistency: 0.093813 |\n",
      "Training epoch: 114 [1200/2000 (60%)] | D loss (A): 0.097675 | D loss (B): 0.068995 | G loss: 1.129011 | Consistency: 0.067409 |\n",
      "Training epoch: 114 [1300/2000 (65%)] | D loss (A): 0.172818 | D loss (B): 0.135880 | G loss: 1.966245 | Consistency: 0.077134 |\n",
      "Training epoch: 114 [1400/2000 (70%)] | D loss (A): 0.239898 | D loss (B): 0.150442 | G loss: 1.641586 | Consistency: 0.074234 |\n",
      "Training epoch: 114 [1500/2000 (75%)] | D loss (A): 0.192388 | D loss (B): 0.142753 | G loss: 1.998513 | Consistency: 0.084121 |\n",
      "Training epoch: 114 [1600/2000 (80%)] | D loss (A): 0.164964 | D loss (B): 0.051389 | G loss: 1.782373 | Consistency: 0.096754 |\n",
      "Training epoch: 114 [1700/2000 (85%)] | D loss (A): 0.138833 | D loss (B): 0.131540 | G loss: 1.562871 | Consistency: 0.091883 |\n",
      "Training epoch: 114 [1800/2000 (90%)] | D loss (A): 0.105192 | D loss (B): 0.113074 | G loss: 1.616053 | Consistency: 0.086402 |\n",
      "Training epoch: 114 [1900/2000 (95%)] | D loss (A): 0.076868 | D loss (B): 0.086299 | G loss: 2.106070 | Consistency: 0.112663 |\n",
      "Training epoch: 115 [0/2000 (0%)] | D loss (A): 0.078839 | D loss (B): 0.138277 | G loss: 2.229978 | Consistency: 0.102272 |\n",
      "Training epoch: 115 [100/2000 (5%)] | D loss (A): 0.178090 | D loss (B): 0.155689 | G loss: 2.614123 | Consistency: 0.096269 |\n",
      "Training epoch: 115 [200/2000 (10%)] | D loss (A): 0.086396 | D loss (B): 0.181058 | G loss: 1.413939 | Consistency: 0.105830 |\n",
      "Training epoch: 115 [300/2000 (15%)] | D loss (A): 0.213481 | D loss (B): 0.229887 | G loss: 1.781086 | Consistency: 0.113450 |\n",
      "Training epoch: 115 [400/2000 (20%)] | D loss (A): 0.177706 | D loss (B): 0.060971 | G loss: 1.862494 | Consistency: 0.098741 |\n",
      "Training epoch: 115 [500/2000 (25%)] | D loss (A): 0.138107 | D loss (B): 0.036987 | G loss: 1.829035 | Consistency: 0.103320 |\n",
      "Training epoch: 115 [600/2000 (30%)] | D loss (A): 0.095769 | D loss (B): 0.182141 | G loss: 1.974603 | Consistency: 0.082231 |\n",
      "Training epoch: 115 [700/2000 (35%)] | D loss (A): 0.113570 | D loss (B): 0.231459 | G loss: 1.583613 | Consistency: 0.100269 |\n",
      "Training epoch: 115 [800/2000 (40%)] | D loss (A): 0.206610 | D loss (B): 0.100507 | G loss: 1.862961 | Consistency: 0.114972 |\n",
      "Training epoch: 115 [900/2000 (45%)] | D loss (A): 0.082745 | D loss (B): 0.217578 | G loss: 1.839638 | Consistency: 0.105653 |\n",
      "Training epoch: 115 [1000/2000 (50%)] | D loss (A): 0.212574 | D loss (B): 0.125697 | G loss: 1.177218 | Consistency: 0.068302 |\n",
      "Training epoch: 115 [1100/2000 (55%)] | D loss (A): 0.124698 | D loss (B): 0.083245 | G loss: 1.309419 | Consistency: 0.076808 |\n",
      "Training epoch: 115 [1200/2000 (60%)] | D loss (A): 0.148166 | D loss (B): 0.178849 | G loss: 1.367525 | Consistency: 0.084177 |\n",
      "Training epoch: 115 [1300/2000 (65%)] | D loss (A): 0.136811 | D loss (B): 0.200633 | G loss: 2.120249 | Consistency: 0.098206 |\n",
      "Training epoch: 115 [1400/2000 (70%)] | D loss (A): 0.182514 | D loss (B): 0.125426 | G loss: 1.952883 | Consistency: 0.092399 |\n",
      "Training epoch: 115 [1500/2000 (75%)] | D loss (A): 0.187047 | D loss (B): 0.103409 | G loss: 2.135178 | Consistency: 0.091806 |\n",
      "Training epoch: 115 [1600/2000 (80%)] | D loss (A): 0.155965 | D loss (B): 0.089342 | G loss: 2.277540 | Consistency: 0.088502 |\n",
      "Training epoch: 115 [1700/2000 (85%)] | D loss (A): 0.112622 | D loss (B): 0.199079 | G loss: 1.590844 | Consistency: 0.079935 |\n",
      "Training epoch: 115 [1800/2000 (90%)] | D loss (A): 0.119924 | D loss (B): 0.123615 | G loss: 1.296639 | Consistency: 0.086514 |\n",
      "Training epoch: 115 [1900/2000 (95%)] | D loss (A): 0.036794 | D loss (B): 0.275865 | G loss: 1.744369 | Consistency: 0.089997 |\n",
      "Training epoch: 116 [0/2000 (0%)] | D loss (A): 0.168919 | D loss (B): 0.172849 | G loss: 2.071979 | Consistency: 0.094184 |\n",
      "Training epoch: 116 [100/2000 (5%)] | D loss (A): 0.192423 | D loss (B): 0.089240 | G loss: 1.773350 | Consistency: 0.081168 |\n",
      "Training epoch: 116 [200/2000 (10%)] | D loss (A): 0.141494 | D loss (B): 0.075789 | G loss: 1.489905 | Consistency: 0.065041 |\n",
      "Training epoch: 116 [300/2000 (15%)] | D loss (A): 0.139550 | D loss (B): 0.070183 | G loss: 1.461989 | Consistency: 0.087288 |\n",
      "Training epoch: 116 [400/2000 (20%)] | D loss (A): 0.190647 | D loss (B): 0.163625 | G loss: 2.161855 | Consistency: 0.069852 |\n",
      "Training epoch: 116 [500/2000 (25%)] | D loss (A): 0.060411 | D loss (B): 0.092334 | G loss: 1.419542 | Consistency: 0.107751 |\n",
      "Training epoch: 116 [600/2000 (30%)] | D loss (A): 0.092041 | D loss (B): 0.107530 | G loss: 2.050238 | Consistency: 0.100037 |\n",
      "Training epoch: 116 [700/2000 (35%)] | D loss (A): 0.132170 | D loss (B): 0.179025 | G loss: 2.160327 | Consistency: 0.069397 |\n",
      "Training epoch: 116 [800/2000 (40%)] | D loss (A): 0.087500 | D loss (B): 0.166141 | G loss: 1.747250 | Consistency: 0.095093 |\n",
      "Training epoch: 116 [900/2000 (45%)] | D loss (A): 0.058286 | D loss (B): 0.204268 | G loss: 1.567363 | Consistency: 0.087425 |\n",
      "Training epoch: 116 [1000/2000 (50%)] | D loss (A): 0.089978 | D loss (B): 0.086225 | G loss: 2.477972 | Consistency: 0.096490 |\n",
      "Training epoch: 116 [1100/2000 (55%)] | D loss (A): 0.184858 | D loss (B): 0.184461 | G loss: 2.178045 | Consistency: 0.089401 |\n",
      "Training epoch: 116 [1200/2000 (60%)] | D loss (A): 0.110868 | D loss (B): 0.111995 | G loss: 1.821030 | Consistency: 0.071530 |\n",
      "Training epoch: 116 [1300/2000 (65%)] | D loss (A): 0.129882 | D loss (B): 0.153162 | G loss: 1.872750 | Consistency: 0.105240 |\n",
      "Training epoch: 116 [1400/2000 (70%)] | D loss (A): 0.229104 | D loss (B): 0.095081 | G loss: 1.931825 | Consistency: 0.082548 |\n",
      "Training epoch: 116 [1500/2000 (75%)] | D loss (A): 0.264178 | D loss (B): 0.045198 | G loss: 1.481108 | Consistency: 0.096878 |\n",
      "Training epoch: 116 [1600/2000 (80%)] | D loss (A): 0.116723 | D loss (B): 0.150686 | G loss: 2.409992 | Consistency: 0.099688 |\n",
      "Training epoch: 116 [1700/2000 (85%)] | D loss (A): 0.163590 | D loss (B): 0.152638 | G loss: 2.126224 | Consistency: 0.099873 |\n",
      "Training epoch: 116 [1800/2000 (90%)] | D loss (A): 0.163430 | D loss (B): 0.044517 | G loss: 1.438815 | Consistency: 0.087168 |\n",
      "Training epoch: 116 [1900/2000 (95%)] | D loss (A): 0.071876 | D loss (B): 0.094365 | G loss: 1.421923 | Consistency: 0.101222 |\n",
      "Training epoch: 117 [0/2000 (0%)] | D loss (A): 0.179125 | D loss (B): 0.107839 | G loss: 1.564390 | Consistency: 0.087082 |\n",
      "Training epoch: 117 [100/2000 (5%)] | D loss (A): 0.155497 | D loss (B): 0.139655 | G loss: 2.104265 | Consistency: 0.093613 |\n",
      "Training epoch: 117 [200/2000 (10%)] | D loss (A): 0.306898 | D loss (B): 0.190882 | G loss: 2.465005 | Consistency: 0.104554 |\n",
      "Training epoch: 117 [300/2000 (15%)] | D loss (A): 0.135255 | D loss (B): 0.101720 | G loss: 2.325716 | Consistency: 0.092468 |\n",
      "Training epoch: 117 [400/2000 (20%)] | D loss (A): 0.163316 | D loss (B): 0.101572 | G loss: 1.695855 | Consistency: 0.074714 |\n",
      "Training epoch: 117 [500/2000 (25%)] | D loss (A): 0.154339 | D loss (B): 0.218229 | G loss: 1.662257 | Consistency: 0.085144 |\n",
      "Training epoch: 117 [600/2000 (30%)] | D loss (A): 0.104215 | D loss (B): 0.113096 | G loss: 1.749194 | Consistency: 0.077819 |\n",
      "Training epoch: 117 [700/2000 (35%)] | D loss (A): 0.097599 | D loss (B): 0.329073 | G loss: 1.983791 | Consistency: 0.112848 |\n",
      "Training epoch: 117 [800/2000 (40%)] | D loss (A): 0.112764 | D loss (B): 0.151548 | G loss: 2.228121 | Consistency: 0.089486 |\n",
      "Training epoch: 117 [900/2000 (45%)] | D loss (A): 0.108646 | D loss (B): 0.098114 | G loss: 2.085486 | Consistency: 0.098423 |\n",
      "Training epoch: 117 [1000/2000 (50%)] | D loss (A): 0.174190 | D loss (B): 0.072427 | G loss: 1.997350 | Consistency: 0.104617 |\n",
      "Training epoch: 117 [1100/2000 (55%)] | D loss (A): 0.103792 | D loss (B): 0.077400 | G loss: 1.895747 | Consistency: 0.087937 |\n",
      "Training epoch: 117 [1200/2000 (60%)] | D loss (A): 0.199442 | D loss (B): 0.130401 | G loss: 1.689351 | Consistency: 0.076727 |\n",
      "Training epoch: 117 [1300/2000 (65%)] | D loss (A): 0.154734 | D loss (B): 0.068962 | G loss: 1.615981 | Consistency: 0.073538 |\n",
      "Training epoch: 117 [1400/2000 (70%)] | D loss (A): 0.239308 | D loss (B): 0.119238 | G loss: 1.745194 | Consistency: 0.074198 |\n",
      "Training epoch: 117 [1500/2000 (75%)] | D loss (A): 0.222934 | D loss (B): 0.186092 | G loss: 1.846916 | Consistency: 0.068903 |\n",
      "Training epoch: 117 [1600/2000 (80%)] | D loss (A): 0.149534 | D loss (B): 0.132206 | G loss: 1.772150 | Consistency: 0.080473 |\n",
      "Training epoch: 117 [1700/2000 (85%)] | D loss (A): 0.095692 | D loss (B): 0.109834 | G loss: 1.072145 | Consistency: 0.066343 |\n",
      "Training epoch: 117 [1800/2000 (90%)] | D loss (A): 0.060708 | D loss (B): 0.087726 | G loss: 2.211764 | Consistency: 0.101448 |\n",
      "Training epoch: 117 [1900/2000 (95%)] | D loss (A): 0.153413 | D loss (B): 0.184884 | G loss: 1.630276 | Consistency: 0.058254 |\n",
      "Training epoch: 118 [0/2000 (0%)] | D loss (A): 0.319157 | D loss (B): 0.201678 | G loss: 1.904403 | Consistency: 0.078840 |\n",
      "Training epoch: 118 [100/2000 (5%)] | D loss (A): 0.243079 | D loss (B): 0.192953 | G loss: 2.348263 | Consistency: 0.104356 |\n",
      "Training epoch: 118 [200/2000 (10%)] | D loss (A): 0.159395 | D loss (B): 0.133567 | G loss: 1.641114 | Consistency: 0.070061 |\n",
      "Training epoch: 118 [300/2000 (15%)] | D loss (A): 0.082891 | D loss (B): 0.134033 | G loss: 2.896493 | Consistency: 0.113096 |\n",
      "Training epoch: 118 [400/2000 (20%)] | D loss (A): 0.077731 | D loss (B): 0.087026 | G loss: 1.703034 | Consistency: 0.104367 |\n",
      "Training epoch: 118 [500/2000 (25%)] | D loss (A): 0.057758 | D loss (B): 0.123589 | G loss: 1.714665 | Consistency: 0.085594 |\n",
      "Training epoch: 118 [600/2000 (30%)] | D loss (A): 0.106088 | D loss (B): 0.125873 | G loss: 2.356642 | Consistency: 0.104507 |\n",
      "Training epoch: 118 [700/2000 (35%)] | D loss (A): 0.227107 | D loss (B): 0.103907 | G loss: 2.189440 | Consistency: 0.103018 |\n",
      "Training epoch: 118 [800/2000 (40%)] | D loss (A): 0.213338 | D loss (B): 0.060274 | G loss: 1.778036 | Consistency: 0.071436 |\n",
      "Training epoch: 118 [900/2000 (45%)] | D loss (A): 0.213085 | D loss (B): 0.164082 | G loss: 1.992434 | Consistency: 0.080289 |\n",
      "Training epoch: 118 [1000/2000 (50%)] | D loss (A): 0.105156 | D loss (B): 0.320696 | G loss: 1.631758 | Consistency: 0.077867 |\n",
      "Training epoch: 118 [1100/2000 (55%)] | D loss (A): 0.177436 | D loss (B): 0.099219 | G loss: 1.517308 | Consistency: 0.086845 |\n",
      "Training epoch: 118 [1200/2000 (60%)] | D loss (A): 0.147835 | D loss (B): 0.122597 | G loss: 1.592512 | Consistency: 0.083848 |\n",
      "Training epoch: 118 [1300/2000 (65%)] | D loss (A): 0.230321 | D loss (B): 0.133402 | G loss: 1.912713 | Consistency: 0.081412 |\n",
      "Training epoch: 118 [1400/2000 (70%)] | D loss (A): 0.198715 | D loss (B): 0.064391 | G loss: 1.784127 | Consistency: 0.100998 |\n",
      "Training epoch: 118 [1500/2000 (75%)] | D loss (A): 0.099934 | D loss (B): 0.074697 | G loss: 1.885481 | Consistency: 0.104157 |\n",
      "Training epoch: 118 [1600/2000 (80%)] | D loss (A): 0.372062 | D loss (B): 0.120144 | G loss: 2.228590 | Consistency: 0.089359 |\n",
      "Training epoch: 118 [1700/2000 (85%)] | D loss (A): 0.140714 | D loss (B): 0.178665 | G loss: 2.348784 | Consistency: 0.089114 |\n",
      "Training epoch: 118 [1800/2000 (90%)] | D loss (A): 0.129049 | D loss (B): 0.059944 | G loss: 1.323671 | Consistency: 0.069288 |\n",
      "Training epoch: 118 [1900/2000 (95%)] | D loss (A): 0.117231 | D loss (B): 0.158509 | G loss: 2.242607 | Consistency: 0.093076 |\n",
      "Training epoch: 119 [0/2000 (0%)] | D loss (A): 0.184285 | D loss (B): 0.077847 | G loss: 1.882686 | Consistency: 0.095948 |\n",
      "Training epoch: 119 [100/2000 (5%)] | D loss (A): 0.216597 | D loss (B): 0.191855 | G loss: 1.668523 | Consistency: 0.063356 |\n",
      "Training epoch: 119 [200/2000 (10%)] | D loss (A): 0.279785 | D loss (B): 0.182052 | G loss: 2.145442 | Consistency: 0.103280 |\n",
      "Training epoch: 119 [300/2000 (15%)] | D loss (A): 0.176613 | D loss (B): 0.138487 | G loss: 1.204788 | Consistency: 0.056749 |\n",
      "Training epoch: 119 [400/2000 (20%)] | D loss (A): 0.144564 | D loss (B): 0.065396 | G loss: 2.158254 | Consistency: 0.113308 |\n",
      "Training epoch: 119 [500/2000 (25%)] | D loss (A): 0.207384 | D loss (B): 0.078943 | G loss: 2.167561 | Consistency: 0.099738 |\n",
      "Training epoch: 119 [600/2000 (30%)] | D loss (A): 0.179399 | D loss (B): 0.080588 | G loss: 1.505300 | Consistency: 0.090305 |\n",
      "Training epoch: 119 [700/2000 (35%)] | D loss (A): 0.232568 | D loss (B): 0.099460 | G loss: 2.139309 | Consistency: 0.084605 |\n",
      "Training epoch: 119 [800/2000 (40%)] | D loss (A): 0.172236 | D loss (B): 0.104933 | G loss: 1.325254 | Consistency: 0.075871 |\n",
      "Training epoch: 119 [900/2000 (45%)] | D loss (A): 0.117532 | D loss (B): 0.081487 | G loss: 2.386856 | Consistency: 0.110055 |\n",
      "Training epoch: 119 [1000/2000 (50%)] | D loss (A): 0.092115 | D loss (B): 0.085997 | G loss: 1.820724 | Consistency: 0.084379 |\n",
      "Training epoch: 119 [1100/2000 (55%)] | D loss (A): 0.258377 | D loss (B): 0.192948 | G loss: 2.217290 | Consistency: 0.110937 |\n",
      "Training epoch: 119 [1200/2000 (60%)] | D loss (A): 0.116974 | D loss (B): 0.123223 | G loss: 1.619618 | Consistency: 0.088004 |\n",
      "Training epoch: 119 [1300/2000 (65%)] | D loss (A): 0.076722 | D loss (B): 0.103079 | G loss: 1.615990 | Consistency: 0.110705 |\n",
      "Training epoch: 119 [1400/2000 (70%)] | D loss (A): 0.141772 | D loss (B): 0.237862 | G loss: 2.126278 | Consistency: 0.086026 |\n",
      "Training epoch: 119 [1500/2000 (75%)] | D loss (A): 0.106455 | D loss (B): 0.072482 | G loss: 2.808375 | Consistency: 0.120563 |\n",
      "Training epoch: 119 [1600/2000 (80%)] | D loss (A): 0.162635 | D loss (B): 0.116345 | G loss: 2.193241 | Consistency: 0.078028 |\n",
      "Training epoch: 119 [1700/2000 (85%)] | D loss (A): 0.153671 | D loss (B): 0.082611 | G loss: 2.440201 | Consistency: 0.099965 |\n",
      "Training epoch: 119 [1800/2000 (90%)] | D loss (A): 0.183581 | D loss (B): 0.150418 | G loss: 1.954548 | Consistency: 0.099663 |\n",
      "Training epoch: 119 [1900/2000 (95%)] | D loss (A): 0.117702 | D loss (B): 0.058990 | G loss: 2.191443 | Consistency: 0.085588 |\n",
      "Training epoch: 120 [0/2000 (0%)] | D loss (A): 0.219479 | D loss (B): 0.152252 | G loss: 1.801190 | Consistency: 0.077464 |\n",
      "Training epoch: 120 [100/2000 (5%)] | D loss (A): 0.109504 | D loss (B): 0.099341 | G loss: 1.447048 | Consistency: 0.083534 |\n",
      "Training epoch: 120 [200/2000 (10%)] | D loss (A): 0.224320 | D loss (B): 0.105933 | G loss: 2.213104 | Consistency: 0.092954 |\n",
      "Training epoch: 120 [300/2000 (15%)] | D loss (A): 0.125860 | D loss (B): 0.126522 | G loss: 2.636798 | Consistency: 0.117668 |\n",
      "Training epoch: 120 [400/2000 (20%)] | D loss (A): 0.258131 | D loss (B): 0.079947 | G loss: 2.247755 | Consistency: 0.104484 |\n",
      "Training epoch: 120 [500/2000 (25%)] | D loss (A): 0.167641 | D loss (B): 0.104730 | G loss: 1.953053 | Consistency: 0.112711 |\n",
      "Training epoch: 120 [600/2000 (30%)] | D loss (A): 0.143668 | D loss (B): 0.182979 | G loss: 1.815840 | Consistency: 0.084485 |\n",
      "Training epoch: 120 [700/2000 (35%)] | D loss (A): 0.173641 | D loss (B): 0.094335 | G loss: 2.317519 | Consistency: 0.104489 |\n",
      "Training epoch: 120 [800/2000 (40%)] | D loss (A): 0.121181 | D loss (B): 0.156932 | G loss: 2.145951 | Consistency: 0.110011 |\n",
      "Training epoch: 120 [900/2000 (45%)] | D loss (A): 0.158614 | D loss (B): 0.263272 | G loss: 2.328487 | Consistency: 0.099765 |\n",
      "Training epoch: 120 [1000/2000 (50%)] | D loss (A): 0.265213 | D loss (B): 0.091808 | G loss: 1.889856 | Consistency: 0.080616 |\n",
      "Training epoch: 120 [1100/2000 (55%)] | D loss (A): 0.254458 | D loss (B): 0.083765 | G loss: 2.425880 | Consistency: 0.094623 |\n",
      "Training epoch: 120 [1200/2000 (60%)] | D loss (A): 0.180870 | D loss (B): 0.170262 | G loss: 1.940389 | Consistency: 0.081290 |\n",
      "Training epoch: 120 [1300/2000 (65%)] | D loss (A): 0.215348 | D loss (B): 0.098514 | G loss: 1.938883 | Consistency: 0.075644 |\n",
      "Training epoch: 120 [1400/2000 (70%)] | D loss (A): 0.127512 | D loss (B): 0.077128 | G loss: 1.464676 | Consistency: 0.070538 |\n",
      "Training epoch: 120 [1500/2000 (75%)] | D loss (A): 0.035881 | D loss (B): 0.172813 | G loss: 2.555951 | Consistency: 0.142098 |\n",
      "Training epoch: 120 [1600/2000 (80%)] | D loss (A): 0.033644 | D loss (B): 0.123528 | G loss: 2.265990 | Consistency: 0.105436 |\n",
      "Training epoch: 120 [1700/2000 (85%)] | D loss (A): 0.148411 | D loss (B): 0.178750 | G loss: 1.563477 | Consistency: 0.078817 |\n",
      "Training epoch: 120 [1800/2000 (90%)] | D loss (A): 0.053815 | D loss (B): 0.227631 | G loss: 1.872146 | Consistency: 0.095094 |\n",
      "Training epoch: 120 [1900/2000 (95%)] | D loss (A): 0.184610 | D loss (B): 0.219944 | G loss: 1.617148 | Consistency: 0.077219 |\n",
      "Training epoch: 121 [0/2000 (0%)] | D loss (A): 0.191792 | D loss (B): 0.174388 | G loss: 1.962195 | Consistency: 0.081402 |\n",
      "Training epoch: 121 [100/2000 (5%)] | D loss (A): 0.111921 | D loss (B): 0.136010 | G loss: 2.030456 | Consistency: 0.104559 |\n",
      "Training epoch: 121 [200/2000 (10%)] | D loss (A): 0.187870 | D loss (B): 0.160369 | G loss: 2.451832 | Consistency: 0.112355 |\n",
      "Training epoch: 121 [300/2000 (15%)] | D loss (A): 0.168289 | D loss (B): 0.148708 | G loss: 1.862625 | Consistency: 0.082096 |\n",
      "Training epoch: 121 [400/2000 (20%)] | D loss (A): 0.180685 | D loss (B): 0.176622 | G loss: 2.159939 | Consistency: 0.079831 |\n",
      "Training epoch: 121 [500/2000 (25%)] | D loss (A): 0.196722 | D loss (B): 0.256655 | G loss: 2.246275 | Consistency: 0.093280 |\n",
      "Training epoch: 121 [600/2000 (30%)] | D loss (A): 0.143031 | D loss (B): 0.087489 | G loss: 1.863120 | Consistency: 0.070052 |\n",
      "Training epoch: 121 [700/2000 (35%)] | D loss (A): 0.197408 | D loss (B): 0.047565 | G loss: 1.993136 | Consistency: 0.101875 |\n",
      "Training epoch: 121 [800/2000 (40%)] | D loss (A): 0.120799 | D loss (B): 0.194861 | G loss: 1.394073 | Consistency: 0.072277 |\n",
      "Training epoch: 121 [900/2000 (45%)] | D loss (A): 0.132272 | D loss (B): 0.052554 | G loss: 1.991976 | Consistency: 0.099200 |\n",
      "Training epoch: 121 [1000/2000 (50%)] | D loss (A): 0.115384 | D loss (B): 0.083135 | G loss: 1.905383 | Consistency: 0.085745 |\n",
      "Training epoch: 121 [1100/2000 (55%)] | D loss (A): 0.241758 | D loss (B): 0.200834 | G loss: 1.650506 | Consistency: 0.077916 |\n",
      "Training epoch: 121 [1200/2000 (60%)] | D loss (A): 0.087183 | D loss (B): 0.164912 | G loss: 2.289022 | Consistency: 0.081596 |\n",
      "Training epoch: 121 [1300/2000 (65%)] | D loss (A): 0.181765 | D loss (B): 0.214251 | G loss: 2.613797 | Consistency: 0.101664 |\n",
      "Training epoch: 121 [1400/2000 (70%)] | D loss (A): 0.195740 | D loss (B): 0.088622 | G loss: 1.993159 | Consistency: 0.097124 |\n",
      "Training epoch: 121 [1500/2000 (75%)] | D loss (A): 0.173881 | D loss (B): 0.064386 | G loss: 1.942577 | Consistency: 0.102286 |\n",
      "Training epoch: 121 [1600/2000 (80%)] | D loss (A): 0.136297 | D loss (B): 0.122535 | G loss: 2.501090 | Consistency: 0.096237 |\n",
      "Training epoch: 121 [1700/2000 (85%)] | D loss (A): 0.137014 | D loss (B): 0.138857 | G loss: 2.151832 | Consistency: 0.079414 |\n",
      "Training epoch: 121 [1800/2000 (90%)] | D loss (A): 0.169838 | D loss (B): 0.080604 | G loss: 2.197115 | Consistency: 0.098106 |\n",
      "Training epoch: 121 [1900/2000 (95%)] | D loss (A): 0.213106 | D loss (B): 0.124131 | G loss: 1.668218 | Consistency: 0.070867 |\n",
      "Training epoch: 122 [0/2000 (0%)] | D loss (A): 0.146643 | D loss (B): 0.173970 | G loss: 2.213900 | Consistency: 0.103302 |\n",
      "Training epoch: 122 [100/2000 (5%)] | D loss (A): 0.177105 | D loss (B): 0.072646 | G loss: 1.584343 | Consistency: 0.092502 |\n",
      "Training epoch: 122 [200/2000 (10%)] | D loss (A): 0.098904 | D loss (B): 0.046674 | G loss: 1.906537 | Consistency: 0.101857 |\n",
      "Training epoch: 122 [300/2000 (15%)] | D loss (A): 0.153596 | D loss (B): 0.144710 | G loss: 2.361604 | Consistency: 0.106434 |\n",
      "Training epoch: 122 [400/2000 (20%)] | D loss (A): 0.118831 | D loss (B): 0.118786 | G loss: 2.393969 | Consistency: 0.090847 |\n",
      "Training epoch: 122 [500/2000 (25%)] | D loss (A): 0.160467 | D loss (B): 0.114022 | G loss: 2.272878 | Consistency: 0.103564 |\n",
      "Training epoch: 122 [600/2000 (30%)] | D loss (A): 0.201861 | D loss (B): 0.132380 | G loss: 2.131964 | Consistency: 0.090698 |\n",
      "Training epoch: 122 [700/2000 (35%)] | D loss (A): 0.148090 | D loss (B): 0.216583 | G loss: 2.293230 | Consistency: 0.093114 |\n",
      "Training epoch: 122 [800/2000 (40%)] | D loss (A): 0.125701 | D loss (B): 0.235125 | G loss: 1.713870 | Consistency: 0.081013 |\n",
      "Training epoch: 122 [900/2000 (45%)] | D loss (A): 0.119766 | D loss (B): 0.116586 | G loss: 2.045800 | Consistency: 0.086363 |\n",
      "Training epoch: 122 [1000/2000 (50%)] | D loss (A): 0.118489 | D loss (B): 0.126150 | G loss: 1.688197 | Consistency: 0.077291 |\n",
      "Training epoch: 122 [1100/2000 (55%)] | D loss (A): 0.207889 | D loss (B): 0.165194 | G loss: 1.602836 | Consistency: 0.070461 |\n",
      "Training epoch: 122 [1200/2000 (60%)] | D loss (A): 0.132089 | D loss (B): 0.153092 | G loss: 1.967268 | Consistency: 0.086311 |\n",
      "Training epoch: 122 [1300/2000 (65%)] | D loss (A): 0.233915 | D loss (B): 0.051571 | G loss: 1.953261 | Consistency: 0.095024 |\n",
      "Training epoch: 122 [1400/2000 (70%)] | D loss (A): 0.168429 | D loss (B): 0.130886 | G loss: 1.770417 | Consistency: 0.075717 |\n",
      "Training epoch: 122 [1500/2000 (75%)] | D loss (A): 0.180607 | D loss (B): 0.070251 | G loss: 1.635525 | Consistency: 0.066777 |\n",
      "Training epoch: 122 [1600/2000 (80%)] | D loss (A): 0.123420 | D loss (B): 0.040661 | G loss: 1.912075 | Consistency: 0.094949 |\n",
      "Training epoch: 122 [1700/2000 (85%)] | D loss (A): 0.111981 | D loss (B): 0.089416 | G loss: 2.156253 | Consistency: 0.112483 |\n",
      "Training epoch: 122 [1800/2000 (90%)] | D loss (A): 0.075527 | D loss (B): 0.182911 | G loss: 2.382346 | Consistency: 0.087430 |\n",
      "Training epoch: 122 [1900/2000 (95%)] | D loss (A): 0.097660 | D loss (B): 0.109350 | G loss: 2.367809 | Consistency: 0.067546 |\n",
      "Training epoch: 123 [0/2000 (0%)] | D loss (A): 0.118658 | D loss (B): 0.107722 | G loss: 1.449604 | Consistency: 0.071276 |\n",
      "Training epoch: 123 [100/2000 (5%)] | D loss (A): 0.151016 | D loss (B): 0.231181 | G loss: 1.917275 | Consistency: 0.077517 |\n",
      "Training epoch: 123 [200/2000 (10%)] | D loss (A): 0.057668 | D loss (B): 0.208754 | G loss: 2.045568 | Consistency: 0.089153 |\n",
      "Training epoch: 123 [300/2000 (15%)] | D loss (A): 0.209769 | D loss (B): 0.253455 | G loss: 1.587623 | Consistency: 0.078975 |\n",
      "Training epoch: 123 [400/2000 (20%)] | D loss (A): 0.161317 | D loss (B): 0.095746 | G loss: 2.031628 | Consistency: 0.099651 |\n",
      "Training epoch: 123 [500/2000 (25%)] | D loss (A): 0.112356 | D loss (B): 0.087527 | G loss: 1.713418 | Consistency: 0.082044 |\n",
      "Training epoch: 123 [600/2000 (30%)] | D loss (A): 0.131954 | D loss (B): 0.109370 | G loss: 2.065148 | Consistency: 0.095235 |\n",
      "Training epoch: 123 [700/2000 (35%)] | D loss (A): 0.196526 | D loss (B): 0.113705 | G loss: 2.005084 | Consistency: 0.072848 |\n",
      "Training epoch: 123 [800/2000 (40%)] | D loss (A): 0.202981 | D loss (B): 0.174450 | G loss: 1.605123 | Consistency: 0.096405 |\n",
      "Training epoch: 123 [900/2000 (45%)] | D loss (A): 0.050338 | D loss (B): 0.139895 | G loss: 1.516912 | Consistency: 0.080784 |\n",
      "Training epoch: 123 [1000/2000 (50%)] | D loss (A): 0.108849 | D loss (B): 0.095294 | G loss: 2.026089 | Consistency: 0.081886 |\n",
      "Training epoch: 123 [1100/2000 (55%)] | D loss (A): 0.117074 | D loss (B): 0.104453 | G loss: 1.402174 | Consistency: 0.073000 |\n",
      "Training epoch: 123 [1200/2000 (60%)] | D loss (A): 0.148448 | D loss (B): 0.089677 | G loss: 1.751836 | Consistency: 0.073753 |\n",
      "Training epoch: 123 [1300/2000 (65%)] | D loss (A): 0.171054 | D loss (B): 0.137891 | G loss: 1.996486 | Consistency: 0.084303 |\n",
      "Training epoch: 123 [1400/2000 (70%)] | D loss (A): 0.047699 | D loss (B): 0.101223 | G loss: 2.092067 | Consistency: 0.123403 |\n",
      "Training epoch: 123 [1500/2000 (75%)] | D loss (A): 0.228544 | D loss (B): 0.138064 | G loss: 1.836326 | Consistency: 0.070707 |\n",
      "Training epoch: 123 [1600/2000 (80%)] | D loss (A): 0.190560 | D loss (B): 0.126509 | G loss: 1.820978 | Consistency: 0.063865 |\n",
      "Training epoch: 123 [1700/2000 (85%)] | D loss (A): 0.108945 | D loss (B): 0.118896 | G loss: 2.083421 | Consistency: 0.101803 |\n",
      "Training epoch: 123 [1800/2000 (90%)] | D loss (A): 0.134080 | D loss (B): 0.079190 | G loss: 1.826348 | Consistency: 0.098821 |\n",
      "Training epoch: 123 [1900/2000 (95%)] | D loss (A): 0.159998 | D loss (B): 0.109807 | G loss: 1.751835 | Consistency: 0.082036 |\n",
      "Training epoch: 124 [0/2000 (0%)] | D loss (A): 0.154357 | D loss (B): 0.103786 | G loss: 2.418610 | Consistency: 0.101769 |\n",
      "Training epoch: 124 [100/2000 (5%)] | D loss (A): 0.139005 | D loss (B): 0.218044 | G loss: 1.761736 | Consistency: 0.081815 |\n",
      "Training epoch: 124 [200/2000 (10%)] | D loss (A): 0.076926 | D loss (B): 0.125556 | G loss: 1.300223 | Consistency: 0.073965 |\n",
      "Training epoch: 124 [300/2000 (15%)] | D loss (A): 0.152842 | D loss (B): 0.140939 | G loss: 2.633526 | Consistency: 0.119248 |\n",
      "Training epoch: 124 [400/2000 (20%)] | D loss (A): 0.090415 | D loss (B): 0.041537 | G loss: 2.271056 | Consistency: 0.109862 |\n",
      "Training epoch: 124 [500/2000 (25%)] | D loss (A): 0.132293 | D loss (B): 0.063936 | G loss: 2.261537 | Consistency: 0.107557 |\n",
      "Training epoch: 124 [600/2000 (30%)] | D loss (A): 0.293573 | D loss (B): 0.263177 | G loss: 1.782749 | Consistency: 0.094103 |\n",
      "Training epoch: 124 [700/2000 (35%)] | D loss (A): 0.143360 | D loss (B): 0.039340 | G loss: 1.722832 | Consistency: 0.102718 |\n",
      "Training epoch: 124 [800/2000 (40%)] | D loss (A): 0.054157 | D loss (B): 0.130306 | G loss: 1.651942 | Consistency: 0.089344 |\n",
      "Training epoch: 124 [900/2000 (45%)] | D loss (A): 0.109086 | D loss (B): 0.054380 | G loss: 1.643915 | Consistency: 0.093552 |\n",
      "Training epoch: 124 [1000/2000 (50%)] | D loss (A): 0.287333 | D loss (B): 0.142203 | G loss: 1.350625 | Consistency: 0.077134 |\n",
      "Training epoch: 124 [1100/2000 (55%)] | D loss (A): 0.190163 | D loss (B): 0.123409 | G loss: 1.770226 | Consistency: 0.085805 |\n",
      "Training epoch: 124 [1200/2000 (60%)] | D loss (A): 0.175640 | D loss (B): 0.210322 | G loss: 1.449580 | Consistency: 0.072912 |\n",
      "Training epoch: 124 [1300/2000 (65%)] | D loss (A): 0.249365 | D loss (B): 0.081306 | G loss: 1.382884 | Consistency: 0.073103 |\n",
      "Training epoch: 124 [1400/2000 (70%)] | D loss (A): 0.185592 | D loss (B): 0.169478 | G loss: 1.541174 | Consistency: 0.061885 |\n",
      "Training epoch: 124 [1500/2000 (75%)] | D loss (A): 0.215787 | D loss (B): 0.200254 | G loss: 1.548614 | Consistency: 0.077548 |\n",
      "Training epoch: 124 [1600/2000 (80%)] | D loss (A): 0.116936 | D loss (B): 0.083531 | G loss: 1.575725 | Consistency: 0.076380 |\n",
      "Training epoch: 124 [1700/2000 (85%)] | D loss (A): 0.074304 | D loss (B): 0.133558 | G loss: 1.542606 | Consistency: 0.059531 |\n",
      "Training epoch: 124 [1800/2000 (90%)] | D loss (A): 0.237432 | D loss (B): 0.114354 | G loss: 1.927039 | Consistency: 0.110136 |\n",
      "Training epoch: 124 [1900/2000 (95%)] | D loss (A): 0.212789 | D loss (B): 0.057963 | G loss: 1.843656 | Consistency: 0.080367 |\n",
      "Training epoch: 125 [0/2000 (0%)] | D loss (A): 0.188710 | D loss (B): 0.094240 | G loss: 1.524433 | Consistency: 0.073737 |\n",
      "Training epoch: 125 [100/2000 (5%)] | D loss (A): 0.151217 | D loss (B): 0.063942 | G loss: 2.425009 | Consistency: 0.111544 |\n",
      "Training epoch: 125 [200/2000 (10%)] | D loss (A): 0.148446 | D loss (B): 0.098295 | G loss: 1.904628 | Consistency: 0.083861 |\n",
      "Training epoch: 125 [300/2000 (15%)] | D loss (A): 0.049491 | D loss (B): 0.210305 | G loss: 2.041861 | Consistency: 0.088122 |\n",
      "Training epoch: 125 [400/2000 (20%)] | D loss (A): 0.102421 | D loss (B): 0.181224 | G loss: 2.053650 | Consistency: 0.086332 |\n",
      "Training epoch: 125 [500/2000 (25%)] | D loss (A): 0.139145 | D loss (B): 0.170129 | G loss: 1.487252 | Consistency: 0.076723 |\n",
      "Training epoch: 125 [600/2000 (30%)] | D loss (A): 0.163429 | D loss (B): 0.055506 | G loss: 1.982746 | Consistency: 0.104138 |\n",
      "Training epoch: 125 [700/2000 (35%)] | D loss (A): 0.078452 | D loss (B): 0.117601 | G loss: 1.523203 | Consistency: 0.095527 |\n",
      "Training epoch: 125 [800/2000 (40%)] | D loss (A): 0.164081 | D loss (B): 0.111361 | G loss: 2.300463 | Consistency: 0.096475 |\n",
      "Training epoch: 125 [900/2000 (45%)] | D loss (A): 0.125463 | D loss (B): 0.182724 | G loss: 1.323655 | Consistency: 0.071588 |\n",
      "Training epoch: 125 [1000/2000 (50%)] | D loss (A): 0.134068 | D loss (B): 0.084632 | G loss: 2.031085 | Consistency: 0.080925 |\n",
      "Training epoch: 125 [1100/2000 (55%)] | D loss (A): 0.102264 | D loss (B): 0.263306 | G loss: 2.032161 | Consistency: 0.098525 |\n",
      "Training epoch: 125 [1200/2000 (60%)] | D loss (A): 0.145170 | D loss (B): 0.168577 | G loss: 1.989125 | Consistency: 0.078866 |\n",
      "Training epoch: 125 [1300/2000 (65%)] | D loss (A): 0.240839 | D loss (B): 0.071566 | G loss: 1.353742 | Consistency: 0.080033 |\n",
      "Training epoch: 125 [1400/2000 (70%)] | D loss (A): 0.090350 | D loss (B): 0.119160 | G loss: 1.871264 | Consistency: 0.077625 |\n",
      "Training epoch: 125 [1500/2000 (75%)] | D loss (A): 0.100077 | D loss (B): 0.123059 | G loss: 1.906361 | Consistency: 0.091839 |\n",
      "Training epoch: 125 [1600/2000 (80%)] | D loss (A): 0.207506 | D loss (B): 0.121765 | G loss: 1.303588 | Consistency: 0.061593 |\n",
      "Training epoch: 125 [1700/2000 (85%)] | D loss (A): 0.093521 | D loss (B): 0.082108 | G loss: 1.780250 | Consistency: 0.083959 |\n",
      "Training epoch: 125 [1800/2000 (90%)] | D loss (A): 0.119265 | D loss (B): 0.191538 | G loss: 2.241855 | Consistency: 0.107704 |\n",
      "Training epoch: 125 [1900/2000 (95%)] | D loss (A): 0.173107 | D loss (B): 0.125692 | G loss: 1.667833 | Consistency: 0.081548 |\n",
      "Training epoch: 126 [0/2000 (0%)] | D loss (A): 0.085454 | D loss (B): 0.157740 | G loss: 1.732782 | Consistency: 0.086111 |\n",
      "Training epoch: 126 [100/2000 (5%)] | D loss (A): 0.293320 | D loss (B): 0.148916 | G loss: 1.335938 | Consistency: 0.069699 |\n",
      "Training epoch: 126 [200/2000 (10%)] | D loss (A): 0.096624 | D loss (B): 0.091166 | G loss: 1.056636 | Consistency: 0.058466 |\n",
      "Training epoch: 126 [300/2000 (15%)] | D loss (A): 0.148996 | D loss (B): 0.181545 | G loss: 1.886570 | Consistency: 0.085686 |\n",
      "Training epoch: 126 [400/2000 (20%)] | D loss (A): 0.147864 | D loss (B): 0.183870 | G loss: 1.787024 | Consistency: 0.089760 |\n",
      "Training epoch: 126 [500/2000 (25%)] | D loss (A): 0.188929 | D loss (B): 0.131292 | G loss: 2.203684 | Consistency: 0.111746 |\n",
      "Training epoch: 126 [600/2000 (30%)] | D loss (A): 0.072950 | D loss (B): 0.187033 | G loss: 2.024867 | Consistency: 0.099289 |\n",
      "Training epoch: 126 [700/2000 (35%)] | D loss (A): 0.142215 | D loss (B): 0.122854 | G loss: 2.172805 | Consistency: 0.085767 |\n",
      "Training epoch: 126 [800/2000 (40%)] | D loss (A): 0.123414 | D loss (B): 0.193394 | G loss: 1.990854 | Consistency: 0.092375 |\n",
      "Training epoch: 126 [900/2000 (45%)] | D loss (A): 0.084004 | D loss (B): 0.070100 | G loss: 2.418952 | Consistency: 0.080378 |\n",
      "Training epoch: 126 [1000/2000 (50%)] | D loss (A): 0.189821 | D loss (B): 0.137775 | G loss: 2.175945 | Consistency: 0.094068 |\n",
      "Training epoch: 126 [1100/2000 (55%)] | D loss (A): 0.108306 | D loss (B): 0.234875 | G loss: 2.009858 | Consistency: 0.090459 |\n",
      "Training epoch: 126 [1200/2000 (60%)] | D loss (A): 0.147041 | D loss (B): 0.091570 | G loss: 2.522521 | Consistency: 0.113862 |\n",
      "Training epoch: 126 [1300/2000 (65%)] | D loss (A): 0.062168 | D loss (B): 0.071743 | G loss: 3.057095 | Consistency: 0.139245 |\n",
      "Training epoch: 126 [1400/2000 (70%)] | D loss (A): 0.100763 | D loss (B): 0.109590 | G loss: 2.327874 | Consistency: 0.101684 |\n",
      "Training epoch: 126 [1500/2000 (75%)] | D loss (A): 0.043925 | D loss (B): 0.112719 | G loss: 1.795098 | Consistency: 0.090557 |\n",
      "Training epoch: 126 [1600/2000 (80%)] | D loss (A): 0.086394 | D loss (B): 0.167761 | G loss: 2.242640 | Consistency: 0.103455 |\n",
      "Training epoch: 126 [1700/2000 (85%)] | D loss (A): 0.131937 | D loss (B): 0.082646 | G loss: 1.942135 | Consistency: 0.090585 |\n",
      "Training epoch: 126 [1800/2000 (90%)] | D loss (A): 0.079322 | D loss (B): 0.153465 | G loss: 2.118276 | Consistency: 0.095132 |\n",
      "Training epoch: 126 [1900/2000 (95%)] | D loss (A): 0.161221 | D loss (B): 0.060479 | G loss: 2.399666 | Consistency: 0.099296 |\n",
      "Training epoch: 127 [0/2000 (0%)] | D loss (A): 0.096201 | D loss (B): 0.230782 | G loss: 1.936316 | Consistency: 0.086550 |\n",
      "Training epoch: 127 [100/2000 (5%)] | D loss (A): 0.151777 | D loss (B): 0.193550 | G loss: 1.764619 | Consistency: 0.075415 |\n",
      "Training epoch: 127 [200/2000 (10%)] | D loss (A): 0.115596 | D loss (B): 0.138904 | G loss: 1.682958 | Consistency: 0.086518 |\n",
      "Training epoch: 127 [300/2000 (15%)] | D loss (A): 0.109908 | D loss (B): 0.114633 | G loss: 2.163547 | Consistency: 0.083673 |\n",
      "Training epoch: 127 [400/2000 (20%)] | D loss (A): 0.071600 | D loss (B): 0.146376 | G loss: 1.974698 | Consistency: 0.064339 |\n",
      "Training epoch: 127 [500/2000 (25%)] | D loss (A): 0.093845 | D loss (B): 0.118699 | G loss: 2.213930 | Consistency: 0.075338 |\n",
      "Training epoch: 127 [600/2000 (30%)] | D loss (A): 0.084963 | D loss (B): 0.128345 | G loss: 2.247577 | Consistency: 0.097826 |\n",
      "Training epoch: 127 [700/2000 (35%)] | D loss (A): 0.154508 | D loss (B): 0.098417 | G loss: 1.990736 | Consistency: 0.064409 |\n",
      "Training epoch: 127 [800/2000 (40%)] | D loss (A): 0.130424 | D loss (B): 0.102603 | G loss: 1.775910 | Consistency: 0.091222 |\n",
      "Training epoch: 127 [900/2000 (45%)] | D loss (A): 0.129738 | D loss (B): 0.086806 | G loss: 2.008754 | Consistency: 0.089267 |\n",
      "Training epoch: 127 [1000/2000 (50%)] | D loss (A): 0.197603 | D loss (B): 0.194982 | G loss: 1.793714 | Consistency: 0.076511 |\n",
      "Training epoch: 127 [1100/2000 (55%)] | D loss (A): 0.130397 | D loss (B): 0.234818 | G loss: 1.934569 | Consistency: 0.096889 |\n",
      "Training epoch: 127 [1200/2000 (60%)] | D loss (A): 0.047102 | D loss (B): 0.169918 | G loss: 2.283295 | Consistency: 0.100137 |\n",
      "Training epoch: 127 [1300/2000 (65%)] | D loss (A): 0.208282 | D loss (B): 0.140132 | G loss: 1.583426 | Consistency: 0.070871 |\n",
      "Training epoch: 127 [1400/2000 (70%)] | D loss (A): 0.104370 | D loss (B): 0.169039 | G loss: 1.784831 | Consistency: 0.065835 |\n",
      "Training epoch: 127 [1500/2000 (75%)] | D loss (A): 0.071482 | D loss (B): 0.159594 | G loss: 2.008685 | Consistency: 0.087999 |\n",
      "Training epoch: 127 [1600/2000 (80%)] | D loss (A): 0.085994 | D loss (B): 0.091370 | G loss: 2.801124 | Consistency: 0.115366 |\n",
      "Training epoch: 127 [1700/2000 (85%)] | D loss (A): 0.269626 | D loss (B): 0.053535 | G loss: 2.166959 | Consistency: 0.109342 |\n",
      "Training epoch: 127 [1800/2000 (90%)] | D loss (A): 0.166586 | D loss (B): 0.058694 | G loss: 1.533146 | Consistency: 0.074749 |\n",
      "Training epoch: 127 [1900/2000 (95%)] | D loss (A): 0.161352 | D loss (B): 0.189281 | G loss: 2.131004 | Consistency: 0.084265 |\n",
      "Training epoch: 128 [0/2000 (0%)] | D loss (A): 0.141149 | D loss (B): 0.044347 | G loss: 1.924902 | Consistency: 0.093851 |\n",
      "Training epoch: 128 [100/2000 (5%)] | D loss (A): 0.092811 | D loss (B): 0.068942 | G loss: 1.769649 | Consistency: 0.102289 |\n",
      "Training epoch: 128 [200/2000 (10%)] | D loss (A): 0.120321 | D loss (B): 0.132195 | G loss: 2.425510 | Consistency: 0.092169 |\n",
      "Training epoch: 128 [300/2000 (15%)] | D loss (A): 0.151714 | D loss (B): 0.191630 | G loss: 1.328880 | Consistency: 0.069746 |\n",
      "Training epoch: 128 [400/2000 (20%)] | D loss (A): 0.163045 | D loss (B): 0.118182 | G loss: 2.137809 | Consistency: 0.078069 |\n",
      "Training epoch: 128 [500/2000 (25%)] | D loss (A): 0.202269 | D loss (B): 0.116594 | G loss: 2.288621 | Consistency: 0.104117 |\n",
      "Training epoch: 128 [600/2000 (30%)] | D loss (A): 0.083336 | D loss (B): 0.259234 | G loss: 1.725120 | Consistency: 0.083158 |\n",
      "Training epoch: 128 [700/2000 (35%)] | D loss (A): 0.329493 | D loss (B): 0.093476 | G loss: 2.067630 | Consistency: 0.084280 |\n",
      "Training epoch: 128 [800/2000 (40%)] | D loss (A): 0.176410 | D loss (B): 0.127059 | G loss: 2.131256 | Consistency: 0.093581 |\n",
      "Training epoch: 128 [900/2000 (45%)] | D loss (A): 0.151340 | D loss (B): 0.266837 | G loss: 1.421242 | Consistency: 0.074666 |\n",
      "Training epoch: 128 [1000/2000 (50%)] | D loss (A): 0.139351 | D loss (B): 0.083703 | G loss: 1.815816 | Consistency: 0.077800 |\n",
      "Training epoch: 128 [1100/2000 (55%)] | D loss (A): 0.164505 | D loss (B): 0.072378 | G loss: 2.284120 | Consistency: 0.093989 |\n",
      "Training epoch: 128 [1200/2000 (60%)] | D loss (A): 0.143637 | D loss (B): 0.125882 | G loss: 2.431875 | Consistency: 0.105732 |\n",
      "Training epoch: 128 [1300/2000 (65%)] | D loss (A): 0.087099 | D loss (B): 0.075459 | G loss: 2.303678 | Consistency: 0.087442 |\n",
      "Training epoch: 128 [1400/2000 (70%)] | D loss (A): 0.175783 | D loss (B): 0.042694 | G loss: 1.804774 | Consistency: 0.118446 |\n",
      "Training epoch: 128 [1500/2000 (75%)] | D loss (A): 0.131337 | D loss (B): 0.124820 | G loss: 2.491265 | Consistency: 0.100023 |\n",
      "Training epoch: 128 [1600/2000 (80%)] | D loss (A): 0.182660 | D loss (B): 0.079942 | G loss: 2.008391 | Consistency: 0.100536 |\n",
      "Training epoch: 128 [1700/2000 (85%)] | D loss (A): 0.232816 | D loss (B): 0.107684 | G loss: 1.959752 | Consistency: 0.067356 |\n",
      "Training epoch: 128 [1800/2000 (90%)] | D loss (A): 0.203273 | D loss (B): 0.187227 | G loss: 2.159526 | Consistency: 0.102046 |\n",
      "Training epoch: 128 [1900/2000 (95%)] | D loss (A): 0.109862 | D loss (B): 0.221302 | G loss: 2.195743 | Consistency: 0.084044 |\n",
      "Training epoch: 129 [0/2000 (0%)] | D loss (A): 0.132128 | D loss (B): 0.145407 | G loss: 1.906435 | Consistency: 0.081860 |\n",
      "Training epoch: 129 [100/2000 (5%)] | D loss (A): 0.131182 | D loss (B): 0.209468 | G loss: 2.262027 | Consistency: 0.091882 |\n",
      "Training epoch: 129 [200/2000 (10%)] | D loss (A): 0.255393 | D loss (B): 0.064052 | G loss: 2.755205 | Consistency: 0.125887 |\n",
      "Training epoch: 129 [300/2000 (15%)] | D loss (A): 0.108370 | D loss (B): 0.110800 | G loss: 1.536597 | Consistency: 0.086955 |\n",
      "Training epoch: 129 [400/2000 (20%)] | D loss (A): 0.106562 | D loss (B): 0.146091 | G loss: 1.265551 | Consistency: 0.080339 |\n",
      "Training epoch: 129 [500/2000 (25%)] | D loss (A): 0.165238 | D loss (B): 0.084593 | G loss: 1.747308 | Consistency: 0.103616 |\n",
      "Training epoch: 129 [600/2000 (30%)] | D loss (A): 0.100296 | D loss (B): 0.216213 | G loss: 2.245312 | Consistency: 0.099547 |\n",
      "Training epoch: 129 [700/2000 (35%)] | D loss (A): 0.193401 | D loss (B): 0.130414 | G loss: 2.036383 | Consistency: 0.097721 |\n"
     ]
    }
   ],
   "source": [
    "%run CycleGAN_main.py --gpu 0 --datapath /root/work/Datasets/Day2Night --batch_size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 67, 195, 451, 963, 1475, 1987, 2499, 3011, 4035, 5059, 6083, 7107, 7619, 7875, 8003]\n",
      "Training epoch: 1 [0/4000 (0%)] | D loss (A): 0.513233 | G loss: 59.035141 | L1: 0.587197 |\n",
      "Training epoch: 1 [100/4000 (2%)] | D loss (A): 0.003873 | G loss: 83.298630 | L1: 0.823885 |\n",
      "Training epoch: 1 [200/4000 (5%)] | D loss (A): 0.110476 | G loss: 74.665268 | L1: 0.737647 |\n",
      "Training epoch: 1 [300/4000 (8%)] | D loss (A): 0.009502 | G loss: 78.830086 | L1: 0.779862 |\n",
      "Training epoch: 1 [400/4000 (10%)] | D loss (A): 0.000697 | G loss: 74.127495 | L1: 0.731611 |\n",
      "Training epoch: 1 [500/4000 (12%)] | D loss (A): 0.006447 | G loss: 52.879242 | L1: 0.519542 |\n",
      "Training epoch: 1 [600/4000 (15%)] | D loss (A): 0.011663 | G loss: 56.338776 | L1: 0.554834 |\n",
      "Training epoch: 1 [700/4000 (18%)] | D loss (A): 0.001091 | G loss: 56.283722 | L1: 0.553257 |\n",
      "Training epoch: 1 [800/4000 (20%)] | D loss (A): 0.000602 | G loss: 73.237839 | L1: 0.722746 |\n",
      "Training epoch: 1 [900/4000 (22%)] | D loss (A): 0.001286 | G loss: 30.474527 | L1: 0.295150 |\n",
      "Training epoch: 1 [1000/4000 (25%)] | D loss (A): 0.003568 | G loss: 65.105789 | L1: 0.641286 |\n",
      "Training epoch: 1 [1100/4000 (28%)] | D loss (A): 0.000576 | G loss: 64.660591 | L1: 0.636917 |\n",
      "Training epoch: 1 [1200/4000 (30%)] | D loss (A): 0.003103 | G loss: 46.884537 | L1: 0.459138 |\n",
      "Training epoch: 1 [1300/4000 (32%)] | D loss (A): 0.000425 | G loss: 46.312225 | L1: 0.453380 |\n",
      "Training epoch: 1 [1400/4000 (35%)] | D loss (A): 0.000363 | G loss: 62.050175 | L1: 0.610815 |\n",
      "Training epoch: 1 [1500/4000 (38%)] | D loss (A): 0.000302 | G loss: 41.044125 | L1: 0.400620 |\n",
      "Training epoch: 1 [1600/4000 (40%)] | D loss (A): 0.000253 | G loss: 25.590443 | L1: 0.246105 |\n",
      "Training epoch: 1 [1700/4000 (42%)] | D loss (A): 0.001373 | G loss: 16.734930 | L1: 0.157820 |\n",
      "Training epoch: 1 [1800/4000 (45%)] | D loss (A): 0.000148 | G loss: 65.098602 | L1: 0.641098 |\n",
      "Training epoch: 1 [1900/4000 (48%)] | D loss (A): 0.000049 | G loss: 77.742104 | L1: 0.767528 |\n",
      "Training epoch: 1 [2000/4000 (50%)] | D loss (A): 0.000050 | G loss: 57.543137 | L1: 0.565517 |\n",
      "Training epoch: 1 [2100/4000 (52%)] | D loss (A): 0.001426 | G loss: 51.008644 | L1: 0.500669 |\n",
      "Training epoch: 1 [2200/4000 (55%)] | D loss (A): 0.002465 | G loss: 62.280277 | L1: 0.613273 |\n",
      "Training epoch: 1 [2300/4000 (58%)] | D loss (A): 0.000701 | G loss: 61.708599 | L1: 0.607195 |\n",
      "Training epoch: 1 [2400/4000 (60%)] | D loss (A): 0.000449 | G loss: 38.683617 | L1: 0.377083 |\n",
      "Training epoch: 1 [2500/4000 (62%)] | D loss (A): 0.004439 | G loss: 26.005165 | L1: 0.250524 |\n",
      "Training epoch: 1 [2600/4000 (65%)] | D loss (A): 0.001225 | G loss: 72.835503 | L1: 0.718728 |\n",
      "Training epoch: 1 [2700/4000 (68%)] | D loss (A): 0.002409 | G loss: 65.492676 | L1: 0.645124 |\n",
      "Training epoch: 1 [2800/4000 (70%)] | D loss (A): 0.000618 | G loss: 43.000175 | L1: 0.420157 |\n",
      "Training epoch: 1 [2900/4000 (72%)] | D loss (A): 0.245337 | G loss: 57.133850 | L1: 0.561445 |\n",
      "Training epoch: 1 [3000/4000 (75%)] | D loss (A): 0.000430 | G loss: 55.440727 | L1: 0.544518 |\n",
      "Training epoch: 1 [3100/4000 (78%)] | D loss (A): 0.002341 | G loss: 53.793148 | L1: 0.528633 |\n",
      "Training epoch: 1 [3200/4000 (80%)] | D loss (A): 0.009836 | G loss: 58.017284 | L1: 0.570435 |\n",
      "Training epoch: 1 [3300/4000 (82%)] | D loss (A): 0.120571 | G loss: 43.428150 | L1: 0.427598 |\n",
      "Training epoch: 1 [3400/4000 (85%)] | D loss (A): 0.000095 | G loss: 51.833946 | L1: 0.508467 |\n",
      "Training epoch: 1 [3500/4000 (88%)] | D loss (A): 0.000064 | G loss: 60.086594 | L1: 0.590976 |\n",
      "Training epoch: 1 [3600/4000 (90%)] | D loss (A): 0.061982 | G loss: 81.168808 | L1: 0.801808 |\n",
      "Training epoch: 1 [3700/4000 (92%)] | D loss (A): 0.019285 | G loss: 44.022091 | L1: 0.432407 |\n",
      "Training epoch: 1 [3800/4000 (95%)] | D loss (A): 0.000745 | G loss: 49.619312 | L1: 0.486464 |\n",
      "Training epoch: 1 [3900/4000 (98%)] | D loss (A): 0.000134 | G loss: 63.987110 | L1: 0.629943 |\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/work/Generative-Adversarial-Networks/LFSpix2pix/LFSpix2pix_main.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/Generative-Adversarial-Networks/LFSpix2pix/LFSpix2pix_main.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_lr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmodel_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/Generative-Adversarial-Networks/LFSpix2pix/LFSpix2pix_main.py\u001b[0m in \u001b[0;36mimage_save\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mtest_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mtest_imgA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0mtest_imgB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mtest_tgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2769\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2770\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2771\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D'"
     ]
    }
   ],
   "source": [
    "%run LFSpix2pix_main.py --gpu 0 --batch_size 1 --train_path Data/day2night_pair.txt --test_path Data/day2night_testpair.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/root/work/Datasets/Day2Night/testA/.ipynb_checkpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2a03265a2495>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mdataA_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataA_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitemA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mdataB_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataB_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitemB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mimgA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataA_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mimgB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataB_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mimgA_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresize_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2769\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2770\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2771\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/root/work/Datasets/Day2Night/testA/.ipynb_checkpoints'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from CycleGAN_models import Generator\n",
    "\n",
    "model_path_a2b = 'result/G_a2b'\n",
    "model_path_b2a = 'result/G_b2a'\n",
    "G_a2b = Generator(n_down=2, n_up=2, n_res=9, in_features=3).cuda()\n",
    "G_a2b.load_state_dict(torch.load(model_path_a2b))\n",
    "G_a2b.eval()\n",
    "G_b2a = Generator(n_down=2, n_up=2, n_res=9, in_features=3).cuda()\n",
    "G_b2a.load_state_dict(torch.load(model_path_b2a))\n",
    "G_b2a.eval()\n",
    "\n",
    "resize_img = transforms.Resize((256, 512))\n",
    "to_tensor = transforms.ToTensor()\n",
    "mean, std = [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]\n",
    "normalize = transforms.Normalize(mean=mean, std=std)\n",
    "mean_ = torch.tensor(mean, dtype=torch.float32)[None,:,None,None]\n",
    "std_ = torch.tensor(std, dtype=torch.float32)[None,:,None,None]\n",
    "dataA_dir = '/root/work/Datasets/Day2Night/testA'\n",
    "dataB_dir = '/root/work/Datasets/Day2Night/testB'\n",
    "data_pix2pix_pair_AB = 'pix2pix_pair_AB_test'\n",
    "data_pix2pix_pair_BA = 'pix2pix_pair_BA_test'\n",
    "os.makedirs(data_pix2pix_pair_AB, exist_ok=True)\n",
    "os.makedirs(data_pix2pix_pair_BA, exist_ok=True)\n",
    "dataA_list = os.listdir(dataA_dir)\n",
    "dataB_list = os.listdir(dataB_dir)\n",
    "\n",
    "for idx, (itemA, itemB) in enumerate(zip(dataA_list, dataB_list)):\n",
    "    dataA_path = os.path.join(dataA_dir, itemA)\n",
    "    dataB_path = os.path.join(dataB_dir, itemB) \n",
    "    imgA = Image.open(dataA_path)\n",
    "    imgB = Image.open(dataB_path)\n",
    "    imgA_tensor = normalize(to_tensor(resize_img(imgA)))[None,:,:,:].cuda()\n",
    "    imgB_tensor = normalize(to_tensor(resize_img(imgB)))[None,:,:,:].cuda()\n",
    "    with torch.no_grad():\n",
    "        fakeB = G_a2b(imgA_tensor)\n",
    "        fakeA = G_b2a(imgB_tensor)\n",
    "        fakeB_ = (fakeB.data.cpu() * std_) + mean_\n",
    "        fakeA_ = (fakeA.data.cpu() * std_) + mean_\n",
    "        #print(fakeA.shape)\n",
    "    imgA_f = Image.fromarray((fakeA_ * 256.).clamp(min=0, max=255).squeeze().numpy().transpose(1,2,0).astype(np.uint8))\n",
    "    imgB_f = Image.fromarray((fakeB_ * 256.).clamp(min=0, max=255).squeeze().data.cpu().numpy().transpose(1,2,0).astype(np.uint8))\n",
    "    imgA.resize((512, 256)).save(os.path.join(data_pix2pix_pair_AB, 'img{:0>6}_real.jpg'.format(idx)))\n",
    "    imgB_f.save(os.path.join(data_pix2pix_pair_AB, 'img{:0>6}_fake.jpg'.format(idx)))\n",
    "    \n",
    "    imgB.resize((512, 256)).save(os.path.join(data_pix2pix_pair_BA, 'img{:0>6}_real.jpg'.format(idx)))\n",
    "    imgA_f.save(os.path.join(data_pix2pix_pair_BA, 'img{:0>6}_fake.jpg'.format(idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "txtpath = 'Data/night2day_testpair.txt'\n",
    "if os.path.isdir(txtpath):\n",
    "    os.remove(txtpath)\n",
    "dirpath = 'Data/pix2pix_pair_BA_test'\n",
    "itemlist = os.listdir(dirpath)\n",
    "for idx in range(len(itemlist) // 2):\n",
    "    real_path = os.path.join(dirpath, 'img{:0>6}_real.jpg'.format(idx))\n",
    "    fake_path = os.path.join(dirpath, 'img{:0>6}_fake.jpg'.format(idx))\n",
    "    \n",
    "    with open(txtpath, 'a') as f:\n",
    "        f.write(real_path + ' ' + real_path + ' ' + '0' + '\\n')\n",
    "        f.write(real_path + ' ' + fake_path + ' ' + '1' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "with open(txtpath, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "random.shuffle(lines)\n",
    "torch.tensor(int(lines[0].split()[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/root/work/Datasets/Day2Night/trainA/.ipynb_checkpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9d193a91b7d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremovedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataA_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataA_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.6/os.py\u001b[0m in \u001b[0;36mremovedirs\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \"\"\"\n\u001b[0;32m--> 238\u001b[0;31m     \u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtail\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/work/Datasets/Day2Night/trainA/.ipynb_checkpoints'"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "os.removedirs(os.path.join(dataA_dir, sorted(dataA_list)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Image00001.jpg',\n",
       " 'Image00002.jpg',\n",
       " 'Image00003.jpg',\n",
       " 'Image00004.jpg',\n",
       " 'Image00005.jpg',\n",
       " 'Image00006.jpg',\n",
       " 'Image00007.jpg',\n",
       " 'Image00008.jpg',\n",
       " 'Image00009.jpg',\n",
       " 'Image00011.jpg',\n",
       " 'Image00012.jpg',\n",
       " 'Image00013.jpg',\n",
       " 'Image00014.jpg',\n",
       " 'Image00015.jpg',\n",
       " 'Image00017.jpg',\n",
       " 'Image00018.jpg',\n",
       " 'Image00019.jpg',\n",
       " 'Image00020.jpg',\n",
       " 'Image00021.jpg',\n",
       " 'Image00022.jpg',\n",
       " 'Image00023.jpg',\n",
       " 'Image00024.jpg',\n",
       " 'Image00025.jpg',\n",
       " 'Image00026.jpg',\n",
       " 'Image00028.jpg',\n",
       " 'Image00029.jpg',\n",
       " 'Image00030.jpg',\n",
       " 'Image00031.jpg',\n",
       " 'Image00032.jpg',\n",
       " 'Image00033.jpg',\n",
       " 'Image00034.jpg',\n",
       " 'Image00035.jpg',\n",
       " 'Image00037.jpg',\n",
       " 'Image00038.jpg',\n",
       " 'Image00039.jpg',\n",
       " 'Image00040.jpg',\n",
       " 'Image00041.jpg',\n",
       " 'Image00042.jpg',\n",
       " 'Image00043.jpg',\n",
       " 'Image00044.jpg',\n",
       " 'Image00045.jpg',\n",
       " 'Image00046.jpg',\n",
       " 'Image00047.jpg',\n",
       " 'Image00048.jpg',\n",
       " 'Image00049.jpg',\n",
       " 'Image00050.jpg',\n",
       " 'Image00051.jpg',\n",
       " 'Image00052.jpg',\n",
       " 'Image00053.jpg',\n",
       " 'Image00054.jpg',\n",
       " 'Image00055.jpg',\n",
       " 'Image00056.jpg',\n",
       " 'Image00058.jpg',\n",
       " 'Image00059.jpg',\n",
       " 'Image00060.jpg',\n",
       " 'Image00061.jpg',\n",
       " 'Image00062.jpg',\n",
       " 'Image00063.jpg',\n",
       " 'Image00064.jpg',\n",
       " 'Image00065.jpg',\n",
       " 'Image00066.jpg',\n",
       " 'Image00067.jpg',\n",
       " 'Image00068.jpg',\n",
       " 'Image00070.jpg',\n",
       " 'Image00071.jpg',\n",
       " 'Image00072.jpg',\n",
       " 'Image00073.jpg',\n",
       " 'Image00074.jpg',\n",
       " 'Image00075.jpg',\n",
       " 'Image00076.jpg',\n",
       " 'Image00077.jpg',\n",
       " 'Image00078.jpg',\n",
       " 'Image00079.jpg',\n",
       " 'Image00081.jpg',\n",
       " 'Image00082.jpg',\n",
       " 'Image00084.jpg',\n",
       " 'Image00085.jpg',\n",
       " 'Image00086.jpg',\n",
       " 'Image00088.jpg',\n",
       " 'Image00090.jpg',\n",
       " 'Image00091.jpg',\n",
       " 'Image00092.jpg',\n",
       " 'Image00093.jpg',\n",
       " 'Image00094.jpg',\n",
       " 'Image00095.jpg',\n",
       " 'Image00096.jpg',\n",
       " 'Image00098.jpg',\n",
       " 'Image00099.jpg',\n",
       " 'Image00100.jpg',\n",
       " 'Image00101.jpg',\n",
       " 'Image00102.jpg',\n",
       " 'Image00103.jpg',\n",
       " 'Image00104.jpg',\n",
       " 'Image00105.jpg',\n",
       " 'Image00106.jpg',\n",
       " 'Image00107.jpg',\n",
       " 'Image00108.jpg',\n",
       " 'Image00109.jpg',\n",
       " 'Image00110.jpg',\n",
       " 'Image00111.jpg',\n",
       " 'Image00112.jpg',\n",
       " 'Image00113.jpg',\n",
       " 'Image00114.jpg',\n",
       " 'Image00115.jpg',\n",
       " 'Image00116.jpg',\n",
       " 'Image00117.jpg',\n",
       " 'Image00118.jpg',\n",
       " 'Image00119.jpg',\n",
       " 'Image00121.jpg',\n",
       " 'Image00122.jpg',\n",
       " 'Image00123.jpg',\n",
       " 'Image00124.jpg',\n",
       " 'Image00126.jpg',\n",
       " 'Image00127.jpg',\n",
       " 'Image00128.jpg',\n",
       " 'Image00129.jpg',\n",
       " 'Image00130.jpg',\n",
       " 'Image00131.jpg',\n",
       " 'Image00132.jpg',\n",
       " 'Image00133.jpg',\n",
       " 'Image00134.jpg',\n",
       " 'Image00135.jpg',\n",
       " 'Image00136.jpg',\n",
       " 'Image00137.jpg',\n",
       " 'Image00138.jpg',\n",
       " 'Image00139.jpg',\n",
       " 'Image00141.jpg',\n",
       " 'Image00142.jpg',\n",
       " 'Image00143.jpg',\n",
       " 'Image00144.jpg',\n",
       " 'Image00145.jpg',\n",
       " 'Image00146.jpg',\n",
       " 'Image00148.jpg',\n",
       " 'Image00149.jpg',\n",
       " 'Image00150.jpg',\n",
       " 'Image00151.jpg',\n",
       " 'Image00152.jpg',\n",
       " 'Image00153.jpg',\n",
       " 'Image00154.jpg',\n",
       " 'Image00155.jpg',\n",
       " 'Image00156.jpg',\n",
       " 'Image00157.jpg',\n",
       " 'Image00158.jpg',\n",
       " 'Image00159.jpg',\n",
       " 'Image00160.jpg',\n",
       " 'Image00161.jpg',\n",
       " 'Image00162.jpg',\n",
       " 'Image00163.jpg',\n",
       " 'Image00164.jpg',\n",
       " 'Image00165.jpg',\n",
       " 'Image00166.jpg',\n",
       " 'Image00167.jpg',\n",
       " 'Image00168.jpg',\n",
       " 'Image00170.jpg',\n",
       " 'Image00171.jpg',\n",
       " 'Image00172.jpg',\n",
       " 'Image00173.jpg',\n",
       " 'Image00174.jpg',\n",
       " 'Image00175.jpg',\n",
       " 'Image00176.jpg',\n",
       " 'Image00177.jpg',\n",
       " 'Image00178.jpg',\n",
       " 'Image00179.jpg',\n",
       " 'Image00180.jpg',\n",
       " 'Image00181.jpg',\n",
       " 'Image00182.jpg',\n",
       " 'Image00183.jpg',\n",
       " 'Image00184.jpg',\n",
       " 'Image00185.jpg',\n",
       " 'Image00186.jpg',\n",
       " 'Image00187.jpg',\n",
       " 'Image00188.jpg',\n",
       " 'Image00189.jpg',\n",
       " 'Image00190.jpg',\n",
       " 'Image00191.jpg',\n",
       " 'Image00192.jpg',\n",
       " 'Image00193.jpg',\n",
       " 'Image00194.jpg',\n",
       " 'Image00195.jpg',\n",
       " 'Image00196.jpg',\n",
       " 'Image00197.jpg',\n",
       " 'Image00198.jpg',\n",
       " 'Image00200.jpg',\n",
       " 'Image00201.jpg',\n",
       " 'Image00202.jpg',\n",
       " 'Image00203.jpg',\n",
       " 'Image00204.jpg',\n",
       " 'Image00205.jpg',\n",
       " 'Image00207.jpg',\n",
       " 'Image00208.jpg',\n",
       " 'Image00209.jpg',\n",
       " 'Image00210.jpg',\n",
       " 'Image00211.jpg',\n",
       " 'Image00212.jpg',\n",
       " 'Image00213.jpg',\n",
       " 'Image00214.jpg',\n",
       " 'Image00215.jpg',\n",
       " 'Image00216.jpg',\n",
       " 'Image00217.jpg',\n",
       " 'Image00218.jpg',\n",
       " 'Image00219.jpg',\n",
       " 'Image00220.jpg',\n",
       " 'Image00221.jpg',\n",
       " 'Image00222.jpg',\n",
       " 'Image00223.jpg',\n",
       " 'Image00224.jpg',\n",
       " 'Image00225.jpg',\n",
       " 'Image00226.jpg',\n",
       " 'Image00227.jpg',\n",
       " 'Image00228.jpg',\n",
       " 'Image00230.jpg',\n",
       " 'Image00232.jpg',\n",
       " 'Image00233.jpg',\n",
       " 'Image00234.jpg',\n",
       " 'Image00235.jpg',\n",
       " 'Image00237.jpg',\n",
       " 'Image00238.jpg',\n",
       " 'Image00239.jpg',\n",
       " 'Image00240.jpg',\n",
       " 'Image00241.jpg',\n",
       " 'Image00242.jpg',\n",
       " 'Image00243.jpg',\n",
       " 'Image00244.jpg',\n",
       " 'Image00245.jpg',\n",
       " 'Image00246.jpg',\n",
       " 'Image00247.jpg',\n",
       " 'Image00248.jpg',\n",
       " 'Image00249.jpg',\n",
       " 'Image00250.jpg',\n",
       " 'Image00251.jpg',\n",
       " 'Image00252.jpg',\n",
       " 'Image00253.jpg',\n",
       " 'Image00254.jpg',\n",
       " 'Image00256.jpg',\n",
       " 'Image00257.jpg',\n",
       " 'Image00258.jpg',\n",
       " 'Image00259.jpg',\n",
       " 'Image00260.jpg',\n",
       " 'Image00261.jpg',\n",
       " 'Image00262.jpg',\n",
       " 'Image00263.jpg',\n",
       " 'Image00264.jpg',\n",
       " 'Image00265.jpg',\n",
       " 'Image00266.jpg',\n",
       " 'Image00267.jpg',\n",
       " 'Image00268.jpg',\n",
       " 'Image00269.jpg',\n",
       " 'Image00270.jpg',\n",
       " 'Image00271.jpg',\n",
       " 'Image00272.jpg',\n",
       " 'Image00273.jpg',\n",
       " 'Image00274.jpg',\n",
       " 'Image00275.jpg',\n",
       " 'Image00276.jpg',\n",
       " 'Image00277.jpg',\n",
       " 'Image00278.jpg',\n",
       " 'Image00279.jpg',\n",
       " 'Image00280.jpg',\n",
       " 'Image00281.jpg',\n",
       " 'Image00282.jpg',\n",
       " 'Image00283.jpg',\n",
       " 'Image00284.jpg',\n",
       " 'Image00285.jpg',\n",
       " 'Image00286.jpg',\n",
       " 'Image00288.jpg',\n",
       " 'Image00289.jpg',\n",
       " 'Image00290.jpg',\n",
       " 'Image00291.jpg',\n",
       " 'Image00292.jpg',\n",
       " 'Image00293.jpg',\n",
       " 'Image00294.jpg',\n",
       " 'Image00295.jpg',\n",
       " 'Image00296.jpg',\n",
       " 'Image00297.jpg',\n",
       " 'Image00298.jpg',\n",
       " 'Image00299.jpg',\n",
       " 'Image00300.jpg',\n",
       " 'Image00301.jpg',\n",
       " 'Image00302.jpg',\n",
       " 'Image00303.jpg',\n",
       " 'Image00304.jpg',\n",
       " 'Image00305.jpg',\n",
       " 'Image00306.jpg',\n",
       " 'Image00307.jpg',\n",
       " 'Image00308.jpg',\n",
       " 'Image00309.jpg',\n",
       " 'Image00310.jpg',\n",
       " 'Image00311.jpg',\n",
       " 'Image00312.jpg',\n",
       " 'Image00313.jpg',\n",
       " 'Image00314.jpg',\n",
       " 'Image00315.jpg',\n",
       " 'Image00316.jpg',\n",
       " 'Image00317.jpg',\n",
       " 'Image00318.jpg',\n",
       " 'Image00319.jpg',\n",
       " 'Image00320.jpg',\n",
       " 'Image00321.jpg',\n",
       " 'Image00322.jpg',\n",
       " 'Image00323.jpg',\n",
       " 'Image00324.jpg',\n",
       " 'Image00326.jpg',\n",
       " 'Image00327.jpg',\n",
       " 'Image00328.jpg',\n",
       " 'Image00330.jpg',\n",
       " 'Image00331.jpg',\n",
       " 'Image00332.jpg',\n",
       " 'Image00333.jpg',\n",
       " 'Image00334.jpg',\n",
       " 'Image00335.jpg',\n",
       " 'Image00336.jpg',\n",
       " 'Image00337.jpg',\n",
       " 'Image00338.jpg',\n",
       " 'Image00339.jpg',\n",
       " 'Image00340.jpg',\n",
       " 'Image00341.jpg',\n",
       " 'Image00342.jpg',\n",
       " 'Image00343.jpg',\n",
       " 'Image00344.jpg',\n",
       " 'Image00345.jpg',\n",
       " 'Image00346.jpg',\n",
       " 'Image00347.jpg',\n",
       " 'Image00348.jpg',\n",
       " 'Image00349.jpg',\n",
       " 'Image00350.jpg',\n",
       " 'Image00352.jpg',\n",
       " 'Image00353.jpg',\n",
       " 'Image00354.jpg',\n",
       " 'Image00355.jpg',\n",
       " 'Image00356.jpg',\n",
       " 'Image00357.jpg',\n",
       " 'Image00358.jpg',\n",
       " 'Image00359.jpg',\n",
       " 'Image00360.jpg',\n",
       " 'Image00361.jpg',\n",
       " 'Image00362.jpg',\n",
       " 'Image00363.jpg',\n",
       " 'Image00364.jpg',\n",
       " 'Image00365.jpg',\n",
       " 'Image00366.jpg',\n",
       " 'Image00367.jpg',\n",
       " 'Image00368.jpg',\n",
       " 'Image00369.jpg',\n",
       " 'Image00370.jpg',\n",
       " 'Image00371.jpg',\n",
       " 'Image00372.jpg',\n",
       " 'Image00373.jpg',\n",
       " 'Image00374.jpg',\n",
       " 'Image00375.jpg',\n",
       " 'Image00376.jpg',\n",
       " 'Image00377.jpg',\n",
       " 'Image00378.jpg',\n",
       " 'Image00379.jpg',\n",
       " 'Image00380.jpg',\n",
       " 'Image00381.jpg',\n",
       " 'Image00382.jpg',\n",
       " 'Image00383.jpg',\n",
       " 'Image00384.jpg',\n",
       " 'Image00385.jpg',\n",
       " 'Image00386.jpg',\n",
       " 'Image00387.jpg',\n",
       " 'Image00388.jpg',\n",
       " 'Image00389.jpg',\n",
       " 'Image00390.jpg',\n",
       " 'Image00391.jpg',\n",
       " 'Image00392.jpg',\n",
       " 'Image00393.jpg',\n",
       " 'Image00394.jpg',\n",
       " 'Image00395.jpg',\n",
       " 'Image00396.jpg',\n",
       " 'Image00397.jpg',\n",
       " 'Image00398.jpg',\n",
       " 'Image00399.jpg',\n",
       " 'Image00400.jpg',\n",
       " 'Image00401.jpg',\n",
       " 'Image00402.jpg',\n",
       " 'Image00403.jpg',\n",
       " 'Image00404.jpg',\n",
       " 'Image00405.jpg',\n",
       " 'Image00406.jpg',\n",
       " 'Image00407.jpg',\n",
       " 'Image00408.jpg',\n",
       " 'Image00409.jpg',\n",
       " 'Image00410.jpg',\n",
       " 'Image00411.jpg',\n",
       " 'Image00412.jpg',\n",
       " 'Image00413.jpg',\n",
       " 'Image00414.jpg',\n",
       " 'Image00415.jpg',\n",
       " 'Image00416.jpg',\n",
       " 'Image00417.jpg',\n",
       " 'Image00418.jpg',\n",
       " 'Image00419.jpg',\n",
       " 'Image00420.jpg',\n",
       " 'Image00421.jpg',\n",
       " 'Image00422.jpg',\n",
       " 'Image00423.jpg',\n",
       " 'Image00424.jpg',\n",
       " 'Image00426.jpg',\n",
       " 'Image00427.jpg',\n",
       " 'Image00428.jpg',\n",
       " 'Image00429.jpg',\n",
       " 'Image00430.jpg',\n",
       " 'Image00431.jpg',\n",
       " 'Image00432.jpg',\n",
       " 'Image00433.jpg',\n",
       " 'Image00434.jpg',\n",
       " 'Image00435.jpg',\n",
       " 'Image00436.jpg',\n",
       " 'Image00437.jpg',\n",
       " 'Image00438.jpg',\n",
       " 'Image00439.jpg',\n",
       " 'Image00440.jpg',\n",
       " 'Image00441.jpg',\n",
       " 'Image00442.jpg',\n",
       " 'Image00443.jpg',\n",
       " 'Image00444.jpg',\n",
       " 'Image00445.jpg',\n",
       " 'Image00446.jpg',\n",
       " 'Image00447.jpg',\n",
       " 'Image00448.jpg',\n",
       " 'Image00449.jpg',\n",
       " 'Image00450.jpg',\n",
       " 'Image00452.jpg',\n",
       " 'Image00454.jpg',\n",
       " 'Image00455.jpg',\n",
       " 'Image00456.jpg',\n",
       " 'Image00457.jpg',\n",
       " 'Image00459.jpg',\n",
       " 'Image00460.jpg',\n",
       " 'Image00461.jpg',\n",
       " 'Image00462.jpg',\n",
       " 'Image00463.jpg',\n",
       " 'Image00464.jpg',\n",
       " 'Image00465.jpg',\n",
       " 'Image00466.jpg',\n",
       " 'Image00467.jpg',\n",
       " 'Image00468.jpg',\n",
       " 'Image00470.jpg',\n",
       " 'Image00471.jpg',\n",
       " 'Image00472.jpg',\n",
       " 'Image00474.jpg',\n",
       " 'Image00475.jpg',\n",
       " 'Image00476.jpg',\n",
       " 'Image00477.jpg',\n",
       " 'Image00478.jpg',\n",
       " 'Image00479.jpg',\n",
       " 'Image00481.jpg',\n",
       " 'Image00482.jpg',\n",
       " 'Image00483.jpg',\n",
       " 'Image00484.jpg',\n",
       " 'Image00485.jpg',\n",
       " 'Image00486.jpg',\n",
       " 'Image00487.jpg',\n",
       " 'Image00488.jpg',\n",
       " 'Image00489.jpg',\n",
       " 'Image00490.jpg',\n",
       " 'Image00491.jpg',\n",
       " 'Image00492.jpg',\n",
       " 'Image00493.jpg',\n",
       " 'Image00494.jpg',\n",
       " 'Image00495.jpg',\n",
       " 'Image00496.jpg',\n",
       " 'Image00498.jpg',\n",
       " 'Image00499.jpg',\n",
       " 'Image00500.jpg',\n",
       " 'Image00501.jpg',\n",
       " 'Image00502.jpg',\n",
       " 'Image00504.jpg',\n",
       " 'Image00506.jpg',\n",
       " 'Image00508.jpg',\n",
       " 'Image00509.jpg',\n",
       " 'Image00510.jpg',\n",
       " 'Image00511.jpg',\n",
       " 'Image00513.jpg',\n",
       " 'Image00514.jpg',\n",
       " 'Image00515.jpg',\n",
       " 'Image00516.jpg',\n",
       " 'Image00517.jpg',\n",
       " 'Image00518.jpg',\n",
       " 'Image00519.jpg',\n",
       " 'Image00520.jpg',\n",
       " 'Image00521.jpg',\n",
       " 'Image00522.jpg',\n",
       " 'Image00523.jpg',\n",
       " 'Image00524.jpg',\n",
       " 'Image00525.jpg',\n",
       " 'Image00526.jpg',\n",
       " 'Image00527.jpg',\n",
       " 'Image00528.jpg',\n",
       " 'Image00529.jpg',\n",
       " 'Image00530.jpg',\n",
       " 'Image00531.jpg',\n",
       " 'Image00532.jpg',\n",
       " 'Image00533.jpg',\n",
       " 'Image00534.jpg',\n",
       " 'Image00535.jpg',\n",
       " 'Image00536.jpg',\n",
       " 'Image00537.jpg',\n",
       " 'Image00538.jpg',\n",
       " 'Image00539.jpg',\n",
       " 'Image00540.jpg',\n",
       " 'Image00541.jpg',\n",
       " 'Image00542.jpg',\n",
       " 'Image00543.jpg',\n",
       " 'Image00544.jpg',\n",
       " 'Image00545.jpg',\n",
       " 'Image00546.jpg',\n",
       " 'Image00547.jpg',\n",
       " 'Image00548.jpg',\n",
       " 'Image00549.jpg',\n",
       " 'Image00550.jpg',\n",
       " 'Image00551.jpg',\n",
       " 'Image00552.jpg',\n",
       " 'Image00553.jpg',\n",
       " 'Image00554.jpg',\n",
       " 'Image00555.jpg',\n",
       " 'Image00556.jpg',\n",
       " 'Image00557.jpg',\n",
       " 'Image00559.jpg',\n",
       " 'Image00560.jpg',\n",
       " 'Image00561.jpg',\n",
       " 'Image00562.jpg',\n",
       " 'Image00563.jpg',\n",
       " 'Image00564.jpg',\n",
       " 'Image00565.jpg',\n",
       " 'Image00566.jpg',\n",
       " 'Image00568.jpg',\n",
       " 'Image00569.jpg',\n",
       " 'Image00570.jpg',\n",
       " 'Image00571.jpg',\n",
       " 'Image00572.jpg',\n",
       " 'Image00573.jpg',\n",
       " 'Image00574.jpg',\n",
       " 'Image00575.jpg',\n",
       " 'Image00576.jpg',\n",
       " 'Image00577.jpg',\n",
       " 'Image00578.jpg',\n",
       " 'Image00579.jpg',\n",
       " 'Image00580.jpg',\n",
       " 'Image00581.jpg',\n",
       " 'Image00583.jpg',\n",
       " 'Image00584.jpg',\n",
       " 'Image00585.jpg',\n",
       " 'Image00586.jpg',\n",
       " 'Image00587.jpg',\n",
       " 'Image00588.jpg',\n",
       " 'Image00589.jpg',\n",
       " 'Image00591.jpg',\n",
       " 'Image00592.jpg',\n",
       " 'Image00594.jpg',\n",
       " 'Image00595.jpg',\n",
       " 'Image00596.jpg',\n",
       " 'Image00597.jpg',\n",
       " 'Image00599.jpg',\n",
       " 'Image00600.jpg',\n",
       " 'Image00601.jpg',\n",
       " 'Image00602.jpg',\n",
       " 'Image00603.jpg',\n",
       " 'Image00604.jpg',\n",
       " 'Image00605.jpg',\n",
       " 'Image00606.jpg',\n",
       " 'Image00607.jpg',\n",
       " 'Image00608.jpg',\n",
       " 'Image00609.jpg',\n",
       " 'Image00610.jpg',\n",
       " 'Image00611.jpg',\n",
       " 'Image00613.jpg',\n",
       " 'Image00614.jpg',\n",
       " 'Image00615.jpg',\n",
       " 'Image00616.jpg',\n",
       " 'Image00617.jpg',\n",
       " 'Image00618.jpg',\n",
       " 'Image00619.jpg',\n",
       " 'Image00620.jpg',\n",
       " 'Image00621.jpg',\n",
       " 'Image00623.jpg',\n",
       " 'Image00624.jpg',\n",
       " 'Image00625.jpg',\n",
       " 'Image00626.jpg',\n",
       " 'Image00627.jpg',\n",
       " 'Image00629.jpg',\n",
       " 'Image00630.jpg',\n",
       " 'Image00631.jpg',\n",
       " 'Image00632.jpg',\n",
       " 'Image00633.jpg',\n",
       " 'Image00634.jpg',\n",
       " 'Image00635.jpg',\n",
       " 'Image00636.jpg',\n",
       " 'Image00637.jpg',\n",
       " 'Image00638.jpg',\n",
       " 'Image00639.jpg',\n",
       " 'Image00640.jpg',\n",
       " 'Image00641.jpg',\n",
       " 'Image00642.jpg',\n",
       " 'Image00643.jpg',\n",
       " 'Image00644.jpg',\n",
       " 'Image00645.jpg',\n",
       " 'Image00646.jpg',\n",
       " 'Image00648.jpg',\n",
       " 'Image00649.jpg',\n",
       " 'Image00650.jpg',\n",
       " 'Image00651.jpg',\n",
       " 'Image00652.jpg',\n",
       " 'Image00653.jpg',\n",
       " 'Image00654.jpg',\n",
       " 'Image00655.jpg',\n",
       " 'Image00656.jpg',\n",
       " 'Image00657.jpg',\n",
       " 'Image00658.jpg',\n",
       " 'Image00659.jpg',\n",
       " 'Image00660.jpg',\n",
       " 'Image00661.jpg',\n",
       " 'Image00662.jpg',\n",
       " 'Image00663.jpg',\n",
       " 'Image00664.jpg',\n",
       " 'Image00665.jpg',\n",
       " 'Image00666.jpg',\n",
       " 'Image00667.jpg',\n",
       " 'Image00668.jpg',\n",
       " 'Image00669.jpg',\n",
       " 'Image00670.jpg',\n",
       " 'Image00671.jpg',\n",
       " 'Image00672.jpg',\n",
       " 'Image00673.jpg',\n",
       " 'Image00674.jpg',\n",
       " 'Image00675.jpg',\n",
       " 'Image00676.jpg',\n",
       " 'Image00677.jpg',\n",
       " 'Image00678.jpg',\n",
       " 'Image00679.jpg',\n",
       " 'Image00680.jpg',\n",
       " 'Image00681.jpg',\n",
       " 'Image00682.jpg',\n",
       " 'Image00683.jpg',\n",
       " 'Image00684.jpg',\n",
       " 'Image00685.jpg',\n",
       " 'Image00686.jpg',\n",
       " 'Image00687.jpg',\n",
       " 'Image00688.jpg',\n",
       " 'Image00689.jpg',\n",
       " 'Image00690.jpg',\n",
       " 'Image00691.jpg',\n",
       " 'Image00692.jpg',\n",
       " 'Image00693.jpg',\n",
       " 'Image00694.jpg',\n",
       " 'Image00695.jpg',\n",
       " 'Image00696.jpg',\n",
       " 'Image00698.jpg',\n",
       " 'Image00699.jpg',\n",
       " 'Image00700.jpg',\n",
       " 'Image00701.jpg',\n",
       " 'Image00702.jpg',\n",
       " 'Image00703.jpg',\n",
       " 'Image00706.jpg',\n",
       " 'Image00707.jpg',\n",
       " 'Image00709.jpg',\n",
       " 'Image00711.jpg',\n",
       " 'Image00712.jpg',\n",
       " 'Image00713.jpg',\n",
       " 'Image00714.jpg',\n",
       " 'Image00715.jpg',\n",
       " 'Image00716.jpg',\n",
       " 'Image00717.jpg',\n",
       " 'Image00718.jpg',\n",
       " 'Image00719.jpg',\n",
       " 'Image00720.jpg',\n",
       " 'Image00721.jpg',\n",
       " 'Image00722.jpg',\n",
       " 'Image00723.jpg',\n",
       " 'Image00724.jpg',\n",
       " 'Image00725.jpg',\n",
       " 'Image00726.jpg',\n",
       " 'Image00727.jpg',\n",
       " 'Image00728.jpg',\n",
       " 'Image00729.jpg',\n",
       " 'Image00730.jpg',\n",
       " 'Image00731.jpg',\n",
       " 'Image00733.jpg',\n",
       " 'Image00734.jpg',\n",
       " 'Image00735.jpg',\n",
       " 'Image00737.jpg',\n",
       " 'Image00738.jpg',\n",
       " 'Image00739.jpg',\n",
       " 'Image00740.jpg',\n",
       " 'Image00741.jpg',\n",
       " 'Image00742.jpg',\n",
       " 'Image00743.jpg',\n",
       " 'Image00744.jpg',\n",
       " 'Image00745.jpg',\n",
       " 'Image00746.jpg',\n",
       " 'Image00747.jpg',\n",
       " 'Image00748.jpg',\n",
       " 'Image00749.jpg',\n",
       " 'Image00750.jpg',\n",
       " 'Image00751.jpg',\n",
       " 'Image00752.jpg',\n",
       " 'Image00753.jpg',\n",
       " 'Image00754.jpg',\n",
       " 'Image00755.jpg',\n",
       " 'Image00756.jpg',\n",
       " 'Image00757.jpg',\n",
       " 'Image00758.jpg',\n",
       " 'Image00759.jpg',\n",
       " 'Image00760.jpg',\n",
       " 'Image00761.jpg',\n",
       " 'Image00762.jpg',\n",
       " 'Image00763.jpg',\n",
       " 'Image00764.jpg',\n",
       " 'Image00765.jpg',\n",
       " 'Image00766.jpg',\n",
       " 'Image00767.jpg',\n",
       " 'Image00768.jpg',\n",
       " 'Image00769.jpg',\n",
       " 'Image00770.jpg',\n",
       " 'Image00771.jpg',\n",
       " 'Image00772.jpg',\n",
       " 'Image00773.jpg',\n",
       " 'Image00774.jpg',\n",
       " 'Image00775.jpg',\n",
       " 'Image00776.jpg',\n",
       " 'Image00777.jpg',\n",
       " 'Image00778.jpg',\n",
       " 'Image00780.jpg',\n",
       " 'Image00781.jpg',\n",
       " 'Image00782.jpg',\n",
       " 'Image00783.jpg',\n",
       " 'Image00784.jpg',\n",
       " 'Image00785.jpg',\n",
       " 'Image00787.jpg',\n",
       " 'Image00788.jpg',\n",
       " 'Image00789.jpg',\n",
       " 'Image00790.jpg',\n",
       " 'Image00791.jpg',\n",
       " 'Image00792.jpg',\n",
       " 'Image00793.jpg',\n",
       " 'Image00794.jpg',\n",
       " 'Image00795.jpg',\n",
       " 'Image00796.jpg',\n",
       " 'Image00798.jpg',\n",
       " 'Image00799.jpg',\n",
       " 'Image00800.jpg',\n",
       " 'Image00801.jpg',\n",
       " 'Image00802.jpg',\n",
       " 'Image00803.jpg',\n",
       " 'Image00804.jpg',\n",
       " 'Image00805.jpg',\n",
       " 'Image00807.jpg',\n",
       " 'Image00808.jpg',\n",
       " 'Image00809.jpg',\n",
       " 'Image00810.jpg',\n",
       " 'Image00811.jpg',\n",
       " 'Image00812.jpg',\n",
       " 'Image00813.jpg',\n",
       " 'Image00814.jpg',\n",
       " 'Image00815.jpg',\n",
       " 'Image00816.jpg',\n",
       " 'Image00817.jpg',\n",
       " 'Image00818.jpg',\n",
       " 'Image00819.jpg',\n",
       " 'Image00820.jpg',\n",
       " 'Image00821.jpg',\n",
       " 'Image00822.jpg',\n",
       " 'Image00823.jpg',\n",
       " 'Image00824.jpg',\n",
       " 'Image00825.jpg',\n",
       " 'Image00826.jpg',\n",
       " 'Image00827.jpg',\n",
       " 'Image00828.jpg',\n",
       " 'Image00829.jpg',\n",
       " 'Image00830.jpg',\n",
       " 'Image00831.jpg',\n",
       " 'Image00832.jpg',\n",
       " 'Image00833.jpg',\n",
       " 'Image00834.jpg',\n",
       " 'Image00836.jpg',\n",
       " 'Image00837.jpg',\n",
       " 'Image00838.jpg',\n",
       " 'Image00839.jpg',\n",
       " 'Image00840.jpg',\n",
       " 'Image00841.jpg',\n",
       " 'Image00842.jpg',\n",
       " 'Image00843.jpg',\n",
       " 'Image00844.jpg',\n",
       " 'Image00845.jpg',\n",
       " 'Image00846.jpg',\n",
       " 'Image00847.jpg',\n",
       " 'Image00848.jpg',\n",
       " 'Image00849.jpg',\n",
       " 'Image00851.jpg',\n",
       " 'Image00852.jpg',\n",
       " 'Image00853.jpg',\n",
       " 'Image00854.jpg',\n",
       " 'Image00855.jpg',\n",
       " 'Image00856.jpg',\n",
       " 'Image00857.jpg',\n",
       " 'Image00858.jpg',\n",
       " 'Image00860.jpg',\n",
       " 'Image00861.jpg',\n",
       " 'Image00862.jpg',\n",
       " 'Image00863.jpg',\n",
       " 'Image00864.jpg',\n",
       " 'Image00865.jpg',\n",
       " 'Image00866.jpg',\n",
       " 'Image00867.jpg',\n",
       " 'Image00868.jpg',\n",
       " 'Image00869.jpg',\n",
       " 'Image00870.jpg',\n",
       " 'Image00872.jpg',\n",
       " 'Image00873.jpg',\n",
       " 'Image00874.jpg',\n",
       " 'Image00875.jpg',\n",
       " 'Image00876.jpg',\n",
       " 'Image00877.jpg',\n",
       " 'Image00878.jpg',\n",
       " 'Image00879.jpg',\n",
       " 'Image00880.jpg',\n",
       " 'Image00881.jpg',\n",
       " 'Image00882.jpg',\n",
       " 'Image00883.jpg',\n",
       " 'Image00886.jpg',\n",
       " 'Image00887.jpg',\n",
       " 'Image00888.jpg',\n",
       " 'Image00889.jpg',\n",
       " 'Image00890.jpg',\n",
       " 'Image00891.jpg',\n",
       " 'Image00892.jpg',\n",
       " 'Image00893.jpg',\n",
       " 'Image00894.jpg',\n",
       " 'Image00895.jpg',\n",
       " 'Image00896.jpg',\n",
       " 'Image00897.jpg',\n",
       " 'Image00898.jpg',\n",
       " 'Image00899.jpg',\n",
       " 'Image00901.jpg',\n",
       " 'Image00902.jpg',\n",
       " 'Image00903.jpg',\n",
       " 'Image00904.jpg',\n",
       " 'Image00905.jpg',\n",
       " 'Image00906.jpg',\n",
       " 'Image00907.jpg',\n",
       " 'Image00908.jpg',\n",
       " 'Image00909.jpg',\n",
       " 'Image00910.jpg',\n",
       " 'Image00911.jpg',\n",
       " 'Image00912.jpg',\n",
       " 'Image00913.jpg',\n",
       " 'Image00914.jpg',\n",
       " 'Image00915.jpg',\n",
       " 'Image00916.jpg',\n",
       " 'Image00917.jpg',\n",
       " 'Image00918.jpg',\n",
       " 'Image00919.jpg',\n",
       " 'Image00920.jpg',\n",
       " 'Image00921.jpg',\n",
       " 'Image00922.jpg',\n",
       " 'Image00923.jpg',\n",
       " 'Image00924.jpg',\n",
       " 'Image00925.jpg',\n",
       " 'Image00926.jpg',\n",
       " 'Image00927.jpg',\n",
       " 'Image00928.jpg',\n",
       " 'Image00929.jpg',\n",
       " 'Image00930.jpg',\n",
       " 'Image00931.jpg',\n",
       " 'Image00932.jpg',\n",
       " 'Image00933.jpg',\n",
       " 'Image00934.jpg',\n",
       " 'Image00935.jpg',\n",
       " 'Image00936.jpg',\n",
       " 'Image00937.jpg',\n",
       " 'Image00938.jpg',\n",
       " 'Image00939.jpg',\n",
       " 'Image00940.jpg',\n",
       " 'Image00942.jpg',\n",
       " 'Image00943.jpg',\n",
       " 'Image00944.jpg',\n",
       " 'Image00945.jpg',\n",
       " 'Image00946.jpg',\n",
       " 'Image00947.jpg',\n",
       " 'Image00948.jpg',\n",
       " 'Image00949.jpg',\n",
       " 'Image00950.jpg',\n",
       " 'Image00951.jpg',\n",
       " 'Image00952.jpg',\n",
       " 'Image00953.jpg',\n",
       " 'Image00955.jpg',\n",
       " 'Image00956.jpg',\n",
       " 'Image00957.jpg',\n",
       " 'Image00958.jpg',\n",
       " 'Image00959.jpg',\n",
       " 'Image00960.jpg',\n",
       " 'Image00961.jpg',\n",
       " 'Image00962.jpg',\n",
       " 'Image00963.jpg',\n",
       " 'Image00964.jpg',\n",
       " 'Image00965.jpg',\n",
       " 'Image00966.jpg',\n",
       " 'Image00967.jpg',\n",
       " 'Image00968.jpg',\n",
       " 'Image00969.jpg',\n",
       " 'Image00970.jpg',\n",
       " 'Image00971.jpg',\n",
       " 'Image00972.jpg',\n",
       " 'Image00973.jpg',\n",
       " 'Image00974.jpg',\n",
       " 'Image00975.jpg',\n",
       " 'Image00976.jpg',\n",
       " 'Image00977.jpg',\n",
       " 'Image00978.jpg',\n",
       " 'Image00979.jpg',\n",
       " 'Image00980.jpg',\n",
       " 'Image00981.jpg',\n",
       " 'Image00982.jpg',\n",
       " 'Image00983.jpg',\n",
       " 'Image00984.jpg',\n",
       " 'Image00985.jpg',\n",
       " 'Image00987.jpg',\n",
       " 'Image00988.jpg',\n",
       " 'Image00989.jpg',\n",
       " 'Image00990.jpg',\n",
       " 'Image00991.jpg',\n",
       " 'Image00992.jpg',\n",
       " 'Image00993.jpg',\n",
       " 'Image00994.jpg',\n",
       " 'Image00995.jpg',\n",
       " 'Image00996.jpg',\n",
       " 'Image00997.jpg',\n",
       " 'Image00998.jpg',\n",
       " 'Image00999.jpg',\n",
       " 'Image01000.jpg',\n",
       " 'Image01001.jpg',\n",
       " 'Image01002.jpg',\n",
       " 'Image01003.jpg',\n",
       " 'Image01004.jpg',\n",
       " 'Image01005.jpg',\n",
       " 'Image01007.jpg',\n",
       " 'Image01008.jpg',\n",
       " 'Image01009.jpg',\n",
       " 'Image01010.jpg',\n",
       " 'Image01011.jpg',\n",
       " 'Image01012.jpg',\n",
       " 'Image01013.jpg',\n",
       " 'Image01014.jpg',\n",
       " 'Image01015.jpg',\n",
       " 'Image01016.jpg',\n",
       " 'Image01017.jpg',\n",
       " 'Image01018.jpg',\n",
       " 'Image01019.jpg',\n",
       " 'Image01020.jpg',\n",
       " 'Image01021.jpg',\n",
       " 'Image01022.jpg',\n",
       " 'Image01023.jpg',\n",
       " 'Image01024.jpg',\n",
       " 'Image01025.jpg',\n",
       " 'Image01026.jpg',\n",
       " 'Image01027.jpg',\n",
       " 'Image01028.jpg',\n",
       " 'Image01029.jpg',\n",
       " 'Image01030.jpg',\n",
       " 'Image01031.jpg',\n",
       " 'Image01032.jpg',\n",
       " 'Image01033.jpg',\n",
       " 'Image01034.jpg',\n",
       " 'Image01035.jpg',\n",
       " 'Image01036.jpg',\n",
       " 'Image01037.jpg',\n",
       " 'Image01040.jpg',\n",
       " 'Image01041.jpg',\n",
       " 'Image01042.jpg',\n",
       " 'Image01043.jpg',\n",
       " 'Image01044.jpg',\n",
       " 'Image01046.jpg',\n",
       " 'Image01047.jpg',\n",
       " 'Image01048.jpg',\n",
       " 'Image01049.jpg',\n",
       " 'Image01050.jpg',\n",
       " 'Image01051.jpg',\n",
       " 'Image01052.jpg',\n",
       " 'Image01053.jpg',\n",
       " 'Image01054.jpg',\n",
       " 'Image01055.jpg',\n",
       " 'Image01056.jpg',\n",
       " 'Image01057.jpg',\n",
       " 'Image01058.jpg',\n",
       " 'Image01060.jpg',\n",
       " 'Image01061.jpg',\n",
       " 'Image01063.jpg',\n",
       " 'Image01064.jpg',\n",
       " 'Image01065.jpg',\n",
       " 'Image01066.jpg',\n",
       " 'Image01067.jpg',\n",
       " 'Image01068.jpg',\n",
       " 'Image01069.jpg',\n",
       " 'Image01070.jpg',\n",
       " 'Image01071.jpg',\n",
       " 'Image01072.jpg',\n",
       " 'Image01073.jpg',\n",
       " 'Image01074.jpg',\n",
       " 'Image01075.jpg',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(os.listdir(dataB_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
